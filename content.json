{"posts":[{"title":"复习前端知识 HTML&amp;CSS&amp;JavaScript","text":"学习目标： 掌握 HTML 基础知识与常用标签 掌握常用的 CSS 修饰页面的方法 掌握 JavaScript 实现页面功能 HTML12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788891)html语言是解释型语言，不是编译型浏览器是容错的2)html页面中由一对标签组成：&lt;html&gt;&lt;/html&gt;&lt;html&gt; 称之为 开始标签&lt;/html&gt;称之为 结束标签3)title 表示网页的标题4)可以在meta标签中设置编码方式5)&lt;br/&gt;表示换行 。br标签是一个单标签。单标签：开始标签和结束标签是同一个，斜杠放在单词后面6)p 表示段落标签7)img 标签图片标签 src属性表示图片文件的路径 width和height表示图片的大小 alt表示图片的提示8)路径的问题： 1. 相对路径 2. 绝对路径9)h1~h6 : 标题标签10)列表标签:- ol 有序列表 start 表示从*开始，type 显示的类型：A a I i 1(deafult)- ul 无序列表 type disc(default) , circle , square11) u 下划线 b 粗体 i 斜体12) 上标 sup 下标 sub13) HTML中的实体： 小于号 &amp;lt; 大于等于号 &amp;ge; 版权 &amp;copy;14) span 不换行的块标记，可以对这一块进行特殊的修饰处理15) a 表示超链接 href 链接的地址 target: _self 在本窗口打开 _blank 在一个新窗口打开 _parent 在父窗口打开 _top 在顶层窗口打开16) div 层17) 表格 table 行 tr 列 td 表头列 th table中有如下属性（虽然已经淘汰，但是最好了解一下） - border：表格边框的粗细 - width:表格的宽度 - cellspacing：单元格间距 - cellpadding：单元格填充 tr中有一个属性： align -&gt; center , left , right rowspan : 行合并 colspan : 列合并18) 表单 form action:可以实现点击跳转的功能 method:post、get、put、delete 19) input type=&quot;text&quot; 表示文本框 ， 其中 name属性必须要指定，否则这个文本框的数据将来是不会发送给服务器的 input type=&quot;password&quot; 表示密码框 input type=&quot;radio&quot; 表示单选按钮。需要注意的是，name属性值保持一致，这样才会有互斥的效果;可以通过checked属性设置默认选中的项 input type=&quot;checkbox&quot; 表示复选框。name属性值建议保持一致，这样将来我们服务器端获取值的时候获取的是一个数组;可以通过checked属性设置默认选中的项 select 表示下拉列表。每一个选项是option，其中value属性是发送给服务器的值, selected表示默认选中的项 textarea 表示多行文本框（或者称之为文本域）,它的value值就是开始结束标签之间的内容 input type=&quot;submit&quot; 表示提交按钮 input type=&quot;reset&quot; 表示重置按钮 input type=&quot;button&quot; 表示普通按钮 frameset 表示页面框架 ， 这个标签已经淘汰，了解，不需要掌握frame表示框架中的具体页面引用总结：1.HTML是解释型的文本标记语言，不区分大小写2.html,head,title,meta,body,br,p,hr,div,table,form,u,i,b,sup,sub,&amp;nbsp;,span,ul,ol,li,tr,td,th,h1-h6,a,input,select,textarea,img2-1. html , head , title , meta , body , br , ul , ol , h1-h6 , a , img , &amp;nbsp;, p , div , span2-2. table tr , th , td 2-3. form(action='' , method='post') input type='text,pasword,radio,checkbox,submit,button,reset&quot; &lt;select&gt; , &lt;textarea&gt; CSS123456789101112131415161718192021222324252627282930&lt;style type=&quot;text/css&quot;&gt;/* 被style标签包围的范围是CSS环境，可以写CSS代码 *//* 标签样式表 */p{color:red;}/* 类样式 */.f20{font-size:20px;}&lt;/style&gt;&lt;!-- 引用外部的CSS样式表文件 --&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;css/demo01.css&quot;&gt;IE浏览器：实际尺寸 = widthchrome浏览器：实际尺寸= width+左右borderwidth+paddingCSS盒子模型：1.border 边框2.margin 间距3.padding 填充position: absolute -- 绝对定位 , 需要配合使用 left , top relative -- 相对定位 , 一般会和 float , margin , padding .... 一起使用float JavaScript12Javascript : 客户端的一个脚本语言js是一门弱类型的语言 , 变量的数据类型由后面赋的值的类型决定","link":"/2022/12/22/HTML/"},{"title":"A review of generics and list","text":"学习目标： 对集合相关易错知识进行复习 复习泛型相关知识 List:remove():There are two methods to remove an element from a list. remove by index –&gt; remove(int index) remove by content –&gt; remove(Object o) List deletes elements by moving the element after the target one index position, setting the last element to null and size-1; So it’s best to delete from large to small. Some mistakes:Error1: 12345for(int i = 0, len = list.size(); i &lt; len; i++){ if(list.get(i) == 1) { list.remove(i); } } 123Exception in thread &quot;main&quot; java.lang.IndexOutOfBoundsException: Index: 3, Size: 3 at java.util.ArrayList.RangeCheck(Unknown Source) at java.util.ArrayList.get(Unknown Source) The array is out of bounds. After deleting the element and not changing the corresponding index, it will not be found when iterating through the last one. So throw this exception. Error2: 1234567Iterator&lt;Integer&gt; iterator = list.iterator(); while(iterator.hasNext()){ int i = iterator.next(); if(i == 1){ list.remove(i); //错误,ConcurrentModificationException异常。 } } The modCount value of the list object is modified. The modCount value of the iterator is not modified, so it throw out this exception. The right method to remove an element from list:Method1: 1234567for(int i = 0, len = list.size(); i &lt; len; i++){ if(list.get(i) == 1){ list.remove(i); len--; i--; } } Method2: 1234567Iterator&lt;Integer&gt; iterator = list.iterator(); while(iterator.hasNext()){ int i = iterator.next(); if(i == 1){ iterator.remove(); //正确 } } Method3: 1234567int size = list.size();for(int i = size - 1; i &gt;= 0; i--){ String item = list.get(i); if(target.equals(item)){ list.remove(item); }} Method4: 123456CopyOnWriteArrayList&lt;String&gt; cowList = new CopyOnWriteArrayList&lt;String&gt;(list);for (String item : cowList) { if (item.equals(target)) { cowList.remove(item); }} Solved the list concurrency problem. Generics:Some details about generics 12345678910111213/** * 泛型的使用 * 1.jdk 5.0新增的特性 * * 2.在集合中使用泛型： * 总结： * ① 集合接口或集合类在jdk5.0时都修改为带泛型的结构。 * ② 在实例化集合类时，可以指明具体的泛型类型 * ③ 指明完以后，在集合类或接口中凡是定义类或接口时，内部结构（比如：方法、构造器、属性等）使用到类的泛型的位置，都指定为实例化的泛型类型。 * 比如：add(E e) ---&gt;实例化以后：add(Integer e) * ④ 注意点：泛型的类型必须是类，不能是基本数据类型。需要用到基本数据类型的位置，拿包装类替换 * ⑤ 如果实例化时，没有指明泛型的类型。默认类型为java.lang.Object类型。 */ Some notes of generics 123456789101112131. 泛型类可能有多个参数，此时应将多个参数一起放在尖括号内。比如：&lt;E1,E2,E3&gt;2. 泛型类的构造器如下：public GenericClass(){}。而下面是错误的：public GenericClass&lt;E&gt;(){}3. 实例化后，操作原来泛型位置的结构必须与指定的泛型类型一致。4. 泛型不同的引用不能相互赋值。 &gt;尽管在编译时ArrayList&lt;String&gt;和ArrayList&lt;Integer&gt;是两种类型，但是，在运行时只有一个ArrayList被加载到JVM中。5. 泛型如果不指定，将被擦除，泛型对应的类型均按照Object处理，但不等价于Object。经验：泛型要使用一路都用。要不用，一路都不要用。6. 如果泛型结构是一个接口或抽象类，则不可创建泛型类的对象。7. jdk1.7，泛型的简化操作：ArrayList&lt;Fruit&gt; flist = new ArrayList&lt;&gt;();8. 泛型的指定中不能使用基本数据类型，可以使用包装类替换。9. 在类/接口上声明的泛型，在本类或本接口中即代表某种类型，可以作为非静态属性的类型、非静态方法的参数类型、非静态方法的返回值类型。但在静态方法中不能使用类的泛型。10. 异常类不能是泛型的11. 不能使用new E[]。但是可以：E[] elements = (E[])new Object[capacity];参考：ArrayList源码中声明：Object[] elementData，而非泛型参数类型数组。 Extend of generics 123456789父类有泛型，子类可以选择保留泛型也可以选择指定泛型类型：&gt; 子类不保留父类的泛型：按需实现 &gt; 没有类型 擦除 &gt; 具体类型&gt; 子类保留父类的泛型：泛型子类 &gt; 全部保留 &gt; 部分保留结论：子类必须是“富二代”，子类除了指定或保留父类的泛型，还可以增加自己的泛型 The embodiment of generics in terms of inheritance Although class A is the parent of class B，but the relationship between G and G is not parent and child, they are paratactic. For example: 123List&lt;Object&gt; list1 = null; List&lt;String&gt; list2 = new ArrayList&lt;&gt;(); list1 = list 2; //Error Additional: If class A is parent of class B，A is parent of B. The use of wildcards wildcards: ? If class A is parent of class B, the relationship between G and G is not parent and child, their parent is: G&lt;?&gt; For example: 123456789public void test3(){ List&lt;Object&gt; list1 = null; List&lt;String&gt; list2 = null; List&lt;?&gt; list = null; list = list1; list = list2;} The use of conditional wildcards ? extends A: G&lt;? extends A&gt; can be parent of G and G, class B is child of class A ​ ? super A:​ G&lt;? super A&gt; can be parent of G and G , class B is parent of class A 12345678910111213141516List&lt;? extends Person&gt; list1 = null;List&lt;? super Person&gt; list2 = null;List&lt;Student&gt; list3 = new ArrayList&lt;Student&gt;();;List&lt;Person&gt; list4 = new ArrayList&lt;Person&gt;();;List&lt;Object&gt; list5 = new ArrayList&lt;Object&gt;();;//可以这么认为：? extends A 代表 ?为A的一个子类，也可以将extends类比于&lt;=;list1 = list3;list1 = list4;// list1 = list5; //error//可以这么认为：? super A 代表 ?为A的一个父类，也可以将super类比于&gt;=;// list2 = list3;//errorlist2 = list4;list2 = list4;","link":"/2022/11/19/GenericsAndList/"},{"title":"JavaWeb的复习","text":"学习目标： 复习 JavaWeb 相关知识 掌握前端重点知识内容 初步了解 JQuery 前言： 在这篇文章之中，主要描述自己认为的重要的知识点和易忘的知识点，可能有些片面或者不足，请多多指教。 HTML&amp;CSS标签： 标签的格式：&lt;标签名&gt;封装的数据&lt;/标签名&gt; 标签拥有自己的属性 基本属性：color=”red” 事件属性：onclick=”alert(‘Hello!’);” 标签的注意事项 标签不能交叉嵌套 标签必须要正确关闭 标签属性必须有值，属性值必须加引号 注释不能嵌套 常用的标签介绍：w3school 表格： 跨行跨列表格的创建 1234&lt;tr&gt; &lt;td colspan=&quot;2&quot;&gt;&lt;/td&gt;&lt;!--跨两列--&gt; &lt;td rowspan=&quot;2&quot;&gt;&lt;/td&gt;&lt;!--跨两行--&gt;&lt;/tr&gt; 表单： 123456789101112131415161718192021222324252627282930313233343536&lt;!--form 标签就是表单input type=text 是文件输入框 value 设置默认显示内容input type=password 是密码输入框 value 设置默认显示内容input type=radio 是单选框 name 属性可以对其进行分组 checked=&quot;checked&quot;表示默认选中input type=checkbox 是复选框 checked=&quot;checked&quot;表示默认选中input type=reset 是重置按钮 value 属性修改按钮上的文本input type=submit 是提交按钮 value 属性修改按钮上的文本input type=button 是按钮 value 属性修改按钮上的文本input type=file 是文件上传域input type=hidden 是隐藏域 当我们要发送某些信息，而这些信息，不需要用户参与，就可以使用隐藏域（提交的时候同时发送给服务器）select 标签是下拉列表框option 标签是下拉列表框中的选项 selected=&quot;selected&quot;设置默认选中textarea 表示多行文本输入框 （起始标签和结束标签中的内容是默认值）rows 属性设置可以显示几行的高度cols 属性设置每行可以显示几个字符宽度--&gt;&lt;!--一些表单提交的细节问题form 标签是表单标签action 属性设置提交的服务器地址method 属性设置提交的方式 GET(默认值)或 POST表单提交的时候，数据没有发送给服务器的三种情况：1、表单项没有 name 属性值2、单选、复选（下拉列表中的 option 标签）都需要添加 value 属性，以便发送给服务器3、表单项不在提交的 form 标签中GET 请求的特点是：1、浏览器地址栏中的地址是：action 属性[+?+请求参数]请求参数的格式是：name=value&amp;name=value2、不安全3、它有数据长度的限制POST 请求的特点是：1、浏览器地址栏中只有 action 属性值2、相对于 GET 请求要安全3、理论上没有数据长度的限制--&gt; CSS： CSS选择器分为以下几种： 标签名选择器，格式 123标签名{ 属性：值;} id 选择器 123#id 属性值{ 属性：值;} class选择器 123.class 属性值{ 属性：值;} 组合选择器 123选择器 1，选择器 2，选择器 n{ 属性：值;} JavaScriptJavaScript书写的两种方式： 在head标签或者body标签中，使用script标签来书写JavaScript代码即可 123&lt;script type=&quot;text/javascript&quot;&gt; &lt;!-- script 内容 --&gt;&lt;/script&gt; 书写单独的js文件，然后对js文件进行引入即可 1&lt;script type=&quot;text/javascript&quot; src=&quot;1.js&quot;&gt;&lt;/script&gt; 变量： 格式 12var i;var i = 10; 关系比较： ==：表示等于，做的是简单的字面值的比较 ===：表示全等于，除了比较简单的字面值，也会比较两个变量的类型 逻辑运算： &amp;&amp;、||、！ 运算法则 &amp;&amp; 且运算。有两种情况： 第一种：当表达式全为真的时候。返回最后一个表达式的值。 第二种：当表达式中，有一个为假的时候。返回第一个为假的表达式的值 || 或运算 第一种情况：当表达式全为假时，返回最后一个表达式的值 第二种情况：只要有一个表达式为真。就会把回第一个为真的表达式的值 &amp;&amp; 与运算 和 ||或运算有短路。短路就是说，当这个&amp;&amp;或||运算有结果了之后 。后面的表达式不再执行 数组： 格式 12var 数组名 = []; // 空数组var 数组名 = [1 , ’abc’ , true]; // 定义数组同时赋值元素 函数： 格式 方式一 123function 函数名(形参列表){ 函数体} 方式二 123var 函数名 = function(形参列表) { 函数体 } 在 JavaScript 语言中，如何定义带有返回值的函数？ 只需要在函数体内直接使用 return 语句返回值即可！ 注：在 Java 中函数允许重载。但是在 JS 中函数的重载会直接覆盖掉上一次的定义 隐形参数： 就是在 function 函数中不需要定义，但却可以直接用来获取所有参数的变量。我们管它叫隐形参数。 隐形参数特别像 java 基础的可变长参数一样。public void fun( Object … args ); 可变长参数其他是一个数组。那么 js 中的隐形参数也跟 java 的可变长参数一样，操作类似数组。 1234567function fun(a) { alert( arguments.length );//可看参数个数 alert( arguments[0] ); alert( arguments[1] ); alert( arguments[2] );}fun(1,&quot;haha&quot;,true); 自定义对象： 方式一： 定义的方式： 123var 变量名 = new Object(); // 对象实例（空对象）变量名.属性名 = 值; // 定义一个属性变量名.函数名 = function(){} // 定义一个函数 对象的访问： 1变量名.属性 / 函数名(); 举例： 123456var obj = new Object();obj.name = &quot;华仔&quot;;obj.age = 18;obj.fun = function () {alert(&quot;姓名：&quot; + this.name + &quot; , 年龄：&quot; + this.age);} 方式二： 定义的方式： 12345var 变量名 = { // 空对象 属性名：值, // 定义一个属性 属性名：值, // 定义一个属性 函数名：function(){} // 定义一个函数} 对象的访问： 1变量名.属性 / 函数名(); 举例说明： 1234567var obj = { name:&quot;国哥&quot;, age:18, fun : function () { alert(&quot;姓名：&quot; + this.name + &quot; , 年龄：&quot; + this.age); }}; ​ 事件： 事件是电脑输入设备与页面进行交互的响应。我们称之为事件。 常用的事件： onload 加载完成事件：页面加载完成之后，常用于做页面 js 代码初始化操作 onclick 单击事件：常用于按钮的点击响应操作。 onblur 失去焦点事件：常用用于输入框失去焦点后验证其输入内容是否合法。 onchange 内容发生改变事件：常用于下拉列表和输入框内容发生改变后操作 onsubmit 表单提交事件：常用于表单提交前，验证所有表单项是否合法。 事件的注册 就是告诉浏览器，当事件响应后要执行哪些操作代码，叫事件注册或事件绑定。 分为静态注册和动态注册两种： 静态注册事件：通过 html 标签的事件属性直接赋于事件响应后的代码，这种方式我们叫静态注册。 动态注册事件：是指先通过 js 代码得到标签的 dom 对象，然后再通过 dom 对象.事件名 = function(){} 这种形式赋于事件响应后的代码，叫动态注册。 动态注册基本步骤： 获取标签对象 标签对象.事件名 = fucntion(){} 123456789101112131415161718192021222324&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;Title&lt;/title&gt; &lt;script type=&quot;text/javascript&quot;&gt; // 静态注册失去焦点事件 function onblurFun() { // console 是控制台对象，是由 JavaScript 语言提供，专门用来向浏览器的控制器打印输出， 用于测试使用 // log() 是打印的方法 console.log(&quot;静态注册失去焦点事件&quot;); } // 动态注册 onblur 事件 window.onload = function () { //1 获取标签对象 var passwordObj = document.getElementById(&quot;password&quot;); // alert(passwordObj); //2 通过标签对象.事件名 = function(){}; passwordObj.onblur = function () { console.log(&quot;动态注册失去焦点事件&quot;); } }&lt;/script&gt;&lt;/head&gt; DOM模型： DOM 全称是 Document Object Model 文档对象模型 大白话，就是把文档中的标签，属性，文本，转换成为对象来管理。 Document 对象的理解： 第一点：Document它管理了所有的 HTML 文档内容。 第二点：document 它是一种树结构的文档。有层级关系。 第三点：它让我们把所有的标签都对象化 第四点：我们可以通过 document 访问所有的标签对象。 Document对象中的方法 **document.getElementById(elementId)**——通过标签的 id 属性查找标签 dom 对象，elementId 是标签的 id 属性值 **document.getElementsByName(elementName)**——通过标签的 name 属性查找标签 dom 对象，elementName 标签的 name 属性值 **document.getElementsByTagName(tagname)**——通过标签名查找标签 dom 对象。tagname 是标签名 **document.createElement( tagName)**——通过给定的标签名，创建一个标签对象。tagName 是要创建的标签名 ​ 注： document 对象的三个查询方法，如果有 id 属性，优先使用 getElementById 方法来进行查询 如果没有 id 属性，则优先使用 getElementsByName 方法来进行查询 如果 id 属性和 name 属性都没有最后再按标签名查 getElementsByTagName 以上三个方法，一定要在页面加载完成之后执行，才能查询到标签对象。 节点 childNodes 属性，获取当前节点的所有子节点 firstChild 属性，获取当前节点的第一个子节点 lastChild 属性，获取当前节点的最后一个子节点 parentNode 属性，获取当前节点的父节点 nextSibling 属性，获取当前节点的下一个节点 previousSibling 属性，获取当前节点的上一个节点 className 用于获取或设置标签的 class 属性值 innerHTML 属性，表示获取/设置起始标签和结束标签中的内容 innerText 属性，表示获取/设置起始标签和结束标签中的文本 JQuery 使用方式： 12345678910111213141516&lt;script type=&quot;text/javascript&quot; src=&quot;../script/jquery-1.7.2.js&quot;&gt;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot;&gt; // window.onload = function () { // var btnObj = document.getElementById(&quot;btnId&quot;); // // alert(btnObj);//[object HTMLButtonElement] ====&gt;&gt;&gt; dom 对象 // btnObj.onclick = function () { // alert(&quot;js 原生的单击事件&quot;); // } // } $(function () { // 表示页面加载完成 之后，相当 window.onload = function () {} var $btnObj = $(&quot;#btnId&quot;); // 表示按 id 查询标签对象 $btnObj.click(function () { // 绑定单击事件 alert(&quot;jQuery 的单击事件&quot;); }); });&lt;/script&gt; 注意：使用JQuery必须要引入JQuery库 JQuery核心函数 $ 是JQuery的核心函数，可以完成JQuery的很多功能 调用方式 $()，相当于 window.onload = function(){} 传入参数为 [ HTML 字符串 ] 时：会为我们创建这个 html 标签对象 传入参数为 [ 选择器字符串 ] 时： ​ $(“#id 属性值”)：id 选择器，根据 id 查询标签对象 ​ $(“标签名”)：标签名选择器，根据指定的标签名查询标签对象 ​ $(“.class 属性值”); 类型选择器，可以根据 class 属性查询标签对象 传入参数为 [ DOM 对象 ] 时：会把这个 dom 对象转换为 jQuery 对象 JQuery对象和DOM对象的区别 jQuery 对象本质上是 dom 对象的数组 + jQuery 提供的一系列功能函数。 JQuery对象和DOM对象的相互转换","link":"/2022/11/20/JavaWeb-review/"},{"title":"深入理解 Java 原理之 JVM","text":"本篇内容： 学习 JVM 相关理论基础以及底层实现 学习相关面试常见题目，掌握问答精髓 回顾当天所学知识，加深印象 JVM 基础经典问答 Java如何实现一次编译，到处运行？（Java如何做到平台无关性？） Java 首先将代码编译成为字节码文件(.class文件)，然后通过Java虚拟机对字节码文件进行解释执行。其实现一次编译到处运行主要是通过以下三个方面。 首先是Java虚拟机，Java之所以可以做到跨平台，是因为Java虚拟机充当了桥梁。他扮演了运行时Java程序与其下的硬件和操作系统之间的缓冲角色。我们可以理解为Java之所以可以做到跨平台，正是因为JVM是依赖平台的。 然后是字节码文件。因为 Java 字节码文件可以在任何平台创建，也可以被任何平台的Java虚拟机装载并执行，所以才有了Java的平台无关性。 最后是Java的语言规范保障了其跨平台运行的特点。例如Java保证了基本数据类型的平台一致性。 Java中所有的基本数据类型大小都是可以确定的吗？ boolean类型就无法确定。如果是单个boolean类型，长度为32bit；如果是boolean数组，则每个boolean值的长度为8bit。 Java是解释型语言还是编译型语言？ Java是半解释半编译型语言。 首先Java先编译成为字节码文件，也就是class文件，该文件无法被计算机直接执行，而是需要虚拟机来解释执行。 在虚拟机进行解释执行的过程中，如果JVM发现某个方法或者代码块运行频繁的时候，会将其看作”热点代码”，然后通过即使编译（JIT）将”热点代码”直接编译成机器码，随后直接执行机器码即可。 因此Java语言是半解释半编译型语言。正常的代码是进行解释执行的，JIT代码优化是通过编译执行的。 如何防止反编译？ 隔离Java程序 让用户接触不到你的Class文件 对Class文件进行加密 提高破解难度 代码混淆 将代码转换成功能上等价，但是难于阅读和理解的形式 解释一下JIT编译 首先Java先编译成为字节码文件，也就是class文件，该文件无法被计算机直接执行，而是需要虚拟机来解释执行。 所以，JVM中内置了解释器，在运行时对字节码进行解释翻译成机器码，然后再执行。解释器的执行方式是一边翻译，一边执行，因此执行效率很低。为了解决这样的低效问题，HotSpot引入了JIT技术 (Just-In-Time)。 有了JIT技术之后，JVM还是通过解释器进行解释执行。但是，当JVM发现某个方法或代码块运行时执行的特别频繁的时候，就会认为这是“热点代码”。然后JIT会把部分“热点代码”翻译成本地机器相关的机器码，并进行优化，然后再把翻译后的机器码缓存起来，以备下次使用。 如何判断一段代码是不是热点代码？ 判断一段代码是不是热点代码有两种方法： 基于采样的方式探测: 周期性检测各个线程的栈顶，发现某个方法经常出现在栈顶，就认为是热点方法。好处就是简单，缺点就是无法精确确认一个方法的热度。容易受线程阻塞或别的原因干扰热点探测。 基于计数器的热点探测。采用这种方法的虚拟机会为每个方法，甚至是代码块建立计数器，统计方法的执行次数，某个方法超过阀值就认为是热点方法，触发JIT编译. 在HotSpot虚拟机中使用的是第二种基于计数器的热点探测方法，因此它为每个方法准备了两个计数器: 方法调用计数器和回边计数器。 方法计数器：就是记录一个方法被调用次数的计数器 回边计数器：是记录方法中的for或者while的运行次数的计数器 JIT的其他优化有哪些？ 逃逸分析：当一个对象在方法中被定义后，它可能被外部方法所引用，例如作为调用参数传递到其他地方中，称为方法逃逸。进行逃逸分析可以进行以下优化： 同步省略。如果一个对象被发现只能从一个线程被访问到，那么对于这个对象的操作可以不考虑同步。 将堆分配转化为栈分配。如果一个对象没有逃逸到方法外的话，那么可以将对象进行栈分配。可以减少堆内存中对象的个数从而减少GC的次数。 分离对象或标量替换。如果经过逃逸分析，发现一个对象不会被外界访问的话，那么经过JIT优化，就会把这个对象拆解成若干个其中包含的成员变量来代替。这个过程就是标量替换。 逃逸分析目前已经被采用了吗？ 没有。其根本原因就是无法保证逃逸分析的性能消耗一定能高于他的消耗。虽然经过逃逸分析可以做标量替换、栈上分配、和锁消除。但是逃逸分析自身也是需要进行一系列复杂的分析的，这其实也是一个相对耗时的过程。举一个个极端的例子，就是经过逃逸分析之后，发现没有一个对象是不逃逸的。那这个逃逸分析的过程就白白浪费掉。 JIT 优化有哪些缺点？ 由于JIT优化是在运行期进行的，并且不是已进入代码就可以进行优化的，因为要判断哪些是热点代码。 因此在JIT优化之前，所有请求都需要解释执行，这个过程相对较慢。 有什么解决办法？ 提升JIT的优化效率 降低瞬间请求量，进行预热。在应用刚刚启动的时候，先分配一个较小的流量，一次来触发JIT优化，之后再提升流量。 为什么有了JIT还需要解释器？ 在当前模式下，在Java虚拟器启动时，解释器可以首先发挥作用，而不必等待即时编译器全部编译完成后再执行，这样可以省去许多不必要的编译时间。随着时间的推移，编译器发挥作用，把越来越多的代码编译成本地代码，获得更高的执行效率。 同时，解释执行在编译器进行激进优化不成立的时候，作为编译器的“逃生门”（后备方案）。 对JDK执行kill -9有什么影响？ kill -9 命令会立刻关闭 JVM 进程。但是kill -9的语意是强制关闭，会导致在JVM中执行的服务立刻关闭，来不及收尾。如导致RPC服务没有从注册中心取消注册导致服务不可用，如导致事务执行一半直接终止等等。 kill -9和kill -15有什么区别？ kill命令默认的信号就是15，当使用kill -15时，系统会发送一个SIGTERM的信号给对应的程序。当程序接收到该信号后，具体要如何处理是自己可以决定的。这时候，应用程序可以选择: 立即停止程序 释放响应资源后停止程序 忽略该信号，继续执行程序 因为kill -15信号只是通知对应的进程要进行”安全、干净的退出”，程序接到信号之后，退出前一般会进行些”准备工作”，如资源释放、临时文件清理等等，如果准备工作做完了，再进行程序的终止。但是，如果在”准备工作”进行过程中，遇到阻塞或者其他问题导致无法成功，那么应用程序可以选择忽略该终止信号。 这也就是为什么我们有的时候使用kill命令是没办法”杀死”应用的原因，因为默认的kill信号是 SIGTERM(15) ，而 SIGTERM(15) 的信号是可以被阻塞和忽略的。 和 kill -15 相比， ki11 -9更加强硬，系统会发出SIGKILL信号，他要求接收到该信号的程序应该立即结束运行，不能被阻塞或者忽略。 所以，相比于 ki11 -15 命令， ki11 -9 在执行时，应用程序是没有时间进行”准备工作”的，所以这通常会带来一些副作用，数据丢失或者终端无法恢复到正常状态等。 正常重启流程是怎样的？ 先将堆栈的文件dump下来 重启机器，如果重启失败，则采用kill -15命令 事后分析dump文件 JVM 运行时内存区域是怎样的？","link":"/2023/08/28/Java%E5%85%AB%E8%82%A1%E4%B9%8BJVM/"},{"title":"深入学习 Java 原理之基础篇","text":"本篇内容： 学习 Java SE 相关理论基础以及底层实现 学习相关面试常见题目，掌握问答精髓 回顾当天所学知识，加深印象 Java 基础问答 Java 和 C++ 主要区别有哪些？ C++ 是编译型语言，其特点是先将代码解释成为机器语言，然后执行机器码。其优点是效率高、执行速度快，缺点是对于解释器依赖性较高，跨平台性较差。 Java 是半解释半编译型语言，其特点是先将代码编译成字节码文件，然后利用 JVM 虚拟机将字节码文件进行解释运行。其优点是跨平台性较好，可以实现一次编译到处运行；缺点是执行效率低，执行速度慢。 如何理解面向对象和面向过程？ 面向过程指的是将问题分解为一个一个的步骤，每个步骤用函数进行实现，然后调用这些函数即可。 面向对象指的是将问题分解为一个一个的步骤，每个步骤都进行相应的抽象，形成对象，通过对对象的调用来解决问题。 面向对象的三大特征是什么？ 继承、封装、多态 封装指的是将事物的属性和方法捆绑在一起形成一个 Java 类。通过封装可以将类的内部细节隐藏起来，并且只暴露出对外部有意义的接口，可以有效防止外部调用对类内部数据的访问和修改。 继承指的是允许子类继承父类的属性和方法，并且在此基础上进行扩展与延申，增添新的属性和方法 多态指的是子类继承父类之后，可以通过重写的方式，使得各个子类与父类具有不同的实现，这也使得父类与各个子类在同一个属性或者方法中具有不同的含义。 面向对象的五大基本原则是什么？ 单一职责原则。每一个对象都负责一个单一的职责。 开放封闭原则。实体（类、函数、模块）应当对扩展开放，对修改关闭。 李氏替换原则。指的是子类能够替换其父类，也就是子类在不破坏程序逻辑的情况下，扩展其父类的功能。 接口隔离原则。接口应该被划分的更小、更具体，以便客户端只需实现它们所需要的接口方法。 依赖倒置原则。程序要依赖于抽象的接口，而不是其具体的实现。 为什么 Java 不支持多继承？ 因为多继承可能会导致菱形继承现象的出现。具体来说，菱形继承指的是当 B、C 同时继承类 A，而类 D 多继承，同时继承 B 和 C，那么当通过类 D 调用类 A 中的方法时，就会出现歧义。 补充一下，在 Java8 之前，接口中是不可以出现方法的实现的，所以一个类实现多个接口也不会出现问题。但是在 Java8 之后，接口中允许定义方法的实现。对于这个问题带来的可能的问题，给出的答案是，如果实现的多个接口中如果有相同的方法，那么要求这个类必须要重写这个方法。 接口和抽象类如何进行选择？ 二者的区别在于接口中只定义了一些方法，而不实现。接口适用于制定规范的时候，抽象类适用于复用的情况下，比较典型的就是模板方法。 一般在实际开发中，我们会首先将接口暴露给外部，然后在外部的业务中加以实现，但是如果在多个实现类中有可复用的代码，那么就在接口和实现类中间定义一个抽象类，将可复用的代码抽出到抽象类中。 如何理解 Java 中的多态？ 多态指的是同一个操作对不同的对象，有不同的解释，产生了不同的结果。多态的三个条件，有类的继承或者接口的实现，子类重写了父类中的方法，父类的引用指向子类的对象。多态是一种运行时状态。 重载是否属于多态的现象？ 我认为多态应该是一种运行时特性。在 Java 中，重写是多态的一种体现。不过也有人提出重载是一种静态多态的体现，并且这个问题在 StackOverFlow 等网站中都有着不同的讨论。但是我认为重载不属于多态。 重载指的是函数或者方法具有相同的名称，但是参数列表不同的情形，这样的同名不同参数的函数或者方法之间，互称为重载函数或者方法。（注意只有返回值不同的两个方法不属于重载）。 重写和重载的区别？ 重写指的是在子类中创建一个与父类中具有相同名称、参数列表和返回类型的方法，以覆盖父类中的方法实现 重载指的是在同一个类中创建多个具有相同名称但参数列表不同的方法，以提供不同的方法实现 重写遵循“运行时绑定”，也就是调用子类还是父类的方法是在运行期确定的。 重载遵循“编译时绑定”，即在编译时根据参数变量的类型判断应当调用哪个函数或方法。 Java中有了基本数据类型为什么还需要包装类？ Java 是一种面向对象的编程语言，很多地方需要的是对象而不是基本数据类型。比如在集合中无法将基本数据类型放进去，因为集合中要求的元素必须是 Object 类型。因此为了让基本数据类型也具有对象的特性，就出现了包装类型，相当于将基本类型包装起来，使得其具有对象的性质，并且为其添加了属性和方法，丰富了基本类型的操作。 基本数据类型和包装类的区别？ 包装类型默认值为 null，而基本数据类型默认值一般不为 null，如 int 类型的默认值为 0. 基本数据类型存放在栈上，而包装类型一般存放在堆上。 初始化的方式不同。包装类型需要 new 一个对象，而基本数据类型不需要。 自动拆箱和自动装箱的含义和举例 自动拆箱指的是将包装类型自动转换为基本数据类型。其使用场景有在对包装类型进行运算、比较的时候 自动装箱指的是将基本数据类型自动转换为包装类型。其使用场景有将基本数据类型添加到集合中的时候就会使用自动装箱 为什么不能使用浮点数来表示金额？ 不是所有的小数都可以使用二进制来加以表示。为了解决这个问题，引入了精度这个概念，也就是使用一个近似值来表示小数的方式。因此浮点数只是近似值而不是精确值，所以不能用来表示金额，否则会出现精度丢失。为了解决这个问题，Java 中提出了 BigDecimal 为什么在 BigDecimal 中不能使用 equals 方法做等值比较？ 因为在 BigDecimal 中的 equals 不仅要比较双方的值，而且要比较双方的精度是否相同，全部相同则返回 true，否则返回 false。所以在BigDecimal 中一般使用 compareTo 方法来进行等值比较。 BigDecimal(double) 和 BigDecimal(String) 有什么区别？ 使用 BigDecimal(double) 的方法来构造 BigDecimal 类型会发生精度丢失的情况，举例来说，对于 0.1 这样的无法用二进制来表示的数字来说，其使用 double 类型进行表示的时候得到的是近似值而不是真实值，所以损失了精度。然而使用 BigDecimal(String) 的方法得到的就是 String 的值。 为什么 Java 中对负数取绝对值不一定是正数？ 因为有可能会发生溢出 String、StringBuffer 和 StringBuilder 的区别？ String 是不可变的，而 StringBuffer 和 StringBuilder 是可变的，StringBuffer 是线程安全的，而 StringBuilder 是线程不安全的。（方法类似，只不过 StringBuffer 方法加入了 synchronized 进行声明） String 底层如何实现不可变性？那么 String 字符串的 + 操作如何实现的？ String 类是 final 类型的，并且其存储值的 char[] 也是 final 类型的。String 字符串的 + 操作实现原理是使用 StringBuilder 的 append 操作。 String 为什么设置成为不可变的？ 因为设置成为不可变的在缓存、安全性、线程安全、性能方面都有优势。 缓存。字符串是使用最广泛的数据结构，大量的字符串的创建非常消耗资源。因此 JVM 专门划分出字符串常量池来存储字符串。通过字符串常量池可以实现字符串的缓存，并且两个相同的字符串指向同一个字符串对象，从而节省内存资源。如果设置为可变的，那么当指向同一个字符串对象的其中一个发生改变的时候，会影响到其他指向这个字符串的内容。 字符串在Java应用程序中广泛用于存储敏感信息，如用户名、密码、连接ur1、网络连接等。JVM类加载器在加载类的时也广泛地使用它。因此，保护String类对于提升整个应用程序的安全性至关重要。当我们在程序中传递一个字符串的时候，如果这个字符串的内容是不可变的，那么我们就可以相信这个字符串中的内容。但是，如果是可变的，那么这个字符串内容就可能随时都被修改。那么这个字符串内容就完全不可信了。这样整个系统就没有安全性可言了。 线程安全。多个线程访问字符串的时候，它们不会被更改，因此不可变对于字符串来说保障了字符串对于多线程是安全的。 哈希缓存。由于字符串对象被广泛地用作数据结构，它们也被广泛地用于哈希实现，如HashMap、HashTable、 HashSet等。在对这些散列实现进行操作时，经常调用hashCode方法。不可变性保证了字符串的值不会改变。因此，hashCode方法在String类中被重写，以方便缓存，这样在第一次hashCode调用期间计算和缓存散列，并从那时起返回相同的值。 因为字符串不可变，所以可以用字符串池缓存，可以大大节省堆内存。而且还可以提前对hashcode进行缓存，更加高效。由于字符串是应用最广泛的数据结构，提高字符串的性能对提高整个应用程序的总体性能有相当大的影响。 String str = new String(“spy”)，一共创建了几个对象？ 如果之前在字符串常量池中创建过 spy 这个字符串的话，只需要在堆中创建 new 出来的对象。 如果是第一次执行，那么需要创建两个对象，一个是堆中创建 new 出来的对象，一个是字符串常量池中的字符串对象。 intern 方法具有什么作用？ 当一个 String 实例调用 intern() 方法的时候，Java 查找常量池中是否有想用 Unicode 的字符串常量，如果有，则返回其引用，如果没有，则在常量池中增加一个 Unicode 等于 str 的字符串并且返回其引用 intern() 有两个作用，一个是将字符串字面量放入常量池（如果池中没有的话），第二就是返回这个常量的引用 intern 方法什么时候使用？ 当编译期无法确定字符串，在运行期才确定字符串的时候，可以使用 intern 将字符串加入到字符串常量池中。举例来说，当字符串是由两个字符串变量相加得到的时候。 String 字符串是否有长度限制？ 有，编译期和运行期不一样。 编译期需要用 CONSTANT_Utf8_info 结构用于表示字符串常量的值，而这个结构是有长度限制，他的限制是65535。 运行期，String 的 length 参数是 int 类型的，那么也就是说，String 定义的时候，最大支持的长度就是 int 的最大范围值。根据Integer类的定义，java.lang.Integer#MAX VALUE 的最大值是2^31 - 1; RPC 接口返回类型使用基本数据类型还是包装类？ RPC 接口返回类型应该是包装类型。如果使用基本数据类型，那么当接口出现问题的时候，返回的值具有二义性。举例来说，如果返回类型为float，那么接口出现异常的情况下，可能会返回默认值也就是 0.0，在这种情况下，无法确定是真的返回了 0.0，还是说出错返回了0.0。如果使用包装类型，那么在接口异常的情况下返回的是 null，可以明确知道接口是否出现异常。因此使用包装类型可以减少歧义。 POJO 类型定义属性使用is+名称可以吗？ POJO 类中的任何布尔类型的变量，都不要加 is，否则部分框架解析会引起序列化错误反例: 定义为基本数据类型 boolean isSuccess; 的属性，它的方法也是 isSuccess()，RPC框架在反向解析的时候，“以为” 对应的属性名称是 success，导致属性获取不到，进而抛出异常。 介绍常见的字符编码？ 字符编码(Character encoding) 是一套法则，使用该法则能够对自然语言的字符的一个集合(如字母表或音)与其他东西的一个集合(如号码或电脉冲)进行配对。 常见的字符编码有 Unicode、UTF-8、UTF-16、GBK 等。 Unicode 是一套通用的字符集，包含了世界上大部分文字，但是并没有规定如何存储，因为如果规范存储的话，每个英文字母面前必有几个字节为0，对于存储来说是极大的浪费。UTF-8 是 Unicode 的一种实现，使用1-4字节进行存储。GBK 是解决中文在 UTF-8 中存储需要使用字节数较多造成的存储资源浪费而设计的，是中文字符编码。 介绍几个常见的语法糖 语法糖，指的是在计算机语言中添加的某种语法，这种语法对语言的功能并没有影响，但是更方便程序员使用。虽然Java中有很多语法糖，但是Java虚拟机并不支持这些语法糖，所以这些语法糖在编译阶段就会被还原成简单的基础语法结构，这样才能被虚拟机识别，这个过程就是解语法糖。Java虚拟机在编译过程中有一个重要的步骤就是调用desugar()，这个方法就是负责解语法糖的实现。 常见的语法糖有 switch支持枚举及字符串、泛型、条件编译、断言、可变参数、自动装箱/拆箱、枚举、内部类增强for循环、try-with-resources语句、lambda表达式等。 switch支持枚举及字符串。指的是当 switch 的判断条件使用的是字符串时，在编译阶段就将字符串换成hashcode值进行实现 泛型指的是所有泛型类的类型参数在编译的时候都会被擦除。（所以在重载的时候，泛型不同不代表参数列表不同；并且泛型类的所有静态变量时共享的） 自动装箱与拆箱。即基本数据类型与包装类型的自动转换 方法变长参数，指的是可变参数在使用的时候，会首先创建一个数组，数组的长度就是调用该方法传递的实参的个数，然后再把所有的参数值全部放到这个数组中，然后再把这个数组作为参数传递到被调用的方法中 枚举，指的是当我们使用 enmu 来定义一个枚举类型的时候，编译器会自动帮我们创建一个 final 类型的类继承 Enum 类。所以枚举类型不能被继承 内部类，内部类在编译之后会生成两个 .class 文件 条件编译，指的是在进行条件判断的时候，编译器直接将分支为 false 的代码块消除。 断言，断言底层就是 if 语句，如果断言结果为true，则什么都不做，程序继续执行，如果断言结果为false，则程序抛出AssertError来打断程序的执行 数值字面量。指的是数字中间的下划线会被省略 for-each，内部调用for循环和迭代器进行实现 try-with-resources语句，编译器帮助我们完成资源关闭等操作 Lambda 表达式是如何实现的？ lambda 表达式的实现实际上是依赖了底层部分 api，在编译阶段，编译器会将 lambda 表达式进行解糖，转换为对内部 api 的调用。 什么是泛型？泛型有什么好处？ 泛型允许在定义接口或者类的时候，使用类型参数。声明的类型参数在真正具体调用或者实现的时候才会使用具体的类型来替换。这种方式主要有两个好处： 提高代码的复用性。以 List 接口为例，使用泛型可以将 Integer 类型或者 String 类型放入 List 中，而不需要定义多个接口。 安全性。在没有泛型的情况下，可能需要频繁进行类型转换，这不仅增加了代码复杂性，还容易引入错误。使用泛型可以减少这种类型转换，提高代码的安全性。 泛型是如何实现的？ 泛型是通过类型擦除的方式实现的。即通过语法糖的形式，当Java文件从.java编译成为字节码文件的时候，将泛型擦除。例如List 在编译之后成为 List。Java的泛型只在编译器，JVM是感应不到泛型的。 类型擦除有什么缺点？ 泛型不可以重载 泛型类中的静态变量只有一份 泛型异常类不可以多次catch List、List&lt;?&gt;、List之间的区别 List 是一个未知类型的List，而List是一个可以存放任何类型数据的List。可以把List复制给List，但是不能把List赋值给List。 可以把任何带参数的类型传递给原始类型List，但却不能把List赋值给List，因为会产生编译错误 (不支持协变) 12List&lt;?&gt; list1 = new ArrayList&lt;String&gt;(); // 语法正确，通配符（Wildcard）类型List&lt;Object&gt; list2 = new ArrayList&lt;String&gt;(); // 编译错误，不支持协变 对数组协变和泛型非协变的理解 协变，可以理解为由于String是Object的子类，那么同样的String[]也是Object[]的子类。这种情况称之为数组协变。对于泛型来说，List和List一点关系都没有。 对于泛型非协变，可以举下面这个例子： 123List&lt;Object&gt; list = new List&lt;String&gt;;list.add(1); //如果允许协变，则可以添加String s = list.get(0);// 编译报错 追问：为什么泛型不允许协变，而数组允许协变呢? 原因有二: 因为数组设计之初没有泛型，为了兼容考虑,如 Arrays.equals(object[]，object[]) 方法，是时代无奈的产物 数组也属于对象，它记录了引用实际的类型，在放入数组的时候，如果类型不一样就会报错，而不是等到拿出 泛型中上下定界符extends和super有什么作用？ 表示类型的上界，表示参数化类型的可能是 T 或是 T的子类；表示类型下界，表示参数化类型是此类型的父类型，直全Object。 在使用限定通配符的时候，需要遵守PECS原则，即Producer Extends, Consumer Super; 上界生产，下界消费 如果要从集合中读取类型T的数据，并且不能写入，可以使用 ? extends 通配符，如果要从集合中写入类型T的数据，并且不需要读取，可以使用 ? super 通配符 如果既要存又要取，那么就不要使用任何通配符. SPI 和 API 有什么区别？ API 直接被应用开发人员使用，SPI 被框架扩展人员使用。 API 是一组定义了软件之间交互规则和约定的接口。提供方用来制定接口并且完成对接口的不同实现，调用方只需要调用即可。 SPI 是一种扩展机制，通常用于在应用程序中提供可插拔的实现。调用方可以选择使用提供方提供的内置来实现，也可以自己实现。 总而言之，API 用于定义调用接口，SPI 用于定义和提供可插拔的实现方式。 如何定义一个SPI？ SPI 的实现原理？ SPI 的应用场景 概括地说，适用于:调用者根据实际使用需要，启用、扩展、或者替换框架的实现策略。比较常见的例子有 数据库驱动加载接口实现类的加载 JDBC加载不同类型数据库的驱动 日志门面接口实现类加载 SLF4J加载不同提供商的日志实现类 Spring中大量使用了SPI，比如: 对servlet3.0规范对ServletContainerlnitializer的实现、自动类型转换TypeConversion SPI(Converter SPl、 Formatter SPI) Dubbo中也大量使用SPI的方式实现框架的扩展,不过它对Java提供的原生SPI做了封装，允许用户扩展实现Filter接口 什么是反射机制？ 反射机制指的是程序在运行过程中能够获得自身的信息，即在Java中，只要给定类的名字，就能通过反射获取类的所有属性和方法。Java的反射可以： 在运行时判断任意一个对象所属的类 在运行时判断任意一个类所具有的成员变量和方法 在运行时任意调用一个对象的方法 在运行时构造任意一个类的对象 反射的优点和缺点 反射的好处就是可以提升程序的灵活性和扩展性，比较容易在运行期干很多事情。 缺点主要有三个： 代码可读性低及可维护性 反射代码执行的性能低 反射破坏了封装性 为什么说反射机制比较慢？ 由于反射涉及动态解析的类型，因此不能执行某些Java虚拟机优化，如JIT优化。 在使用反射时，参数需要包装成Object 类型，但是真正方法执行的时候，又需要再拆包成真正的类型，这些动作不仅消耗时间，而且过程中也会产生很多对象，对象一多就容易导致GC也会导致应用变慢。 反射调用方法时会从方法数组中遍历查找，并且会检查可见性。这些动作都是耗时的. 不仅方法的可见性要做检查，参数也需要做很多额外的检查. 反射常用的场景有哪些？ 动态代理 JDBC的class.forName BeanUtils中属性值的拷贝 RPC框架 ORM框架 Spring的IOC/DI JAVA中创建对象的方式有哪些？ 使用 new 关键字 使用反射机制 使用Class类的newInstance()方法 使用Constructor类的newInstance()方法 使用clone方法 使用反序列化。当序列化或者反序列化一个对象的时候，JVM 会给我们创建一个单独的对象，其实反序列化也是基于反射实现的 使用方法句柄 使用Unsafe分配内存 Java的动态代理如何实现？ 在Java中，实现动态代理有两种方式: JDK动态代理: Java.lang.reflect 包中的Proxy类和InvocationHandler接口提供了生成动态代理类的能力。 Cglib动态代理: Cglib (Code Generation Library )是一个第三方代码生成类库，运行时在内存中动态生成个子类对象从而实现对目标对象功能的扩展。 两种动态代理方式有什么区别？ JDK的动态代理有一个限制，就是使用动态代理的对象必须实现一个或多个接口。如果想代理没有实现接口的类就可以使用CGLIB实现。 Cglib是一个强大的高性能的代码生成包，它可以在运行期扩展Java类与实现Java接口。它广泛的被许多AOP的框架使用，例如Spring AOP和dynaop，为他们提供方法的interception (拦截) Cglib包的底层是通过使用一个小而快的字节码处理框架ASM，来转换字节码并生成新的类。不鼓励直接使用ASM，因为它需要你对JVM内部结构包括class文件的格式和指令集都很熟悉。 所以，使用JDK动态代理的对象必须实现一个或多个接口;而使用cglib代理的对象则无需实现接口，达到代理类无侵入。 静态代理和动态代理的区别？ 最大的区别是静态代理是编译期确定的，动态代理是运行期确定的。 使用静态代理需要手写许多代码，这个过程浪费时间和精力，一旦需要代理的类中方法比较多，或者需要同时代理多个对象的时候，复杂度较大 反射是动态代理的实现方式之一 动态代理的用途？ Java的动态代理的最主要的用途就是应用在各种框架中。因为使用动态代理可以很方便的运行期生成代理类，通过代理类可以做很多事情，比如AOP，比如过滤器、拦截器等。 在我们平时使用的框架中，像servlet的filter、包括spring提供的aop以及struts2的拦截器都使用了动态代理功能。我们日常看到的mybatis分页插件，以及日志拦截、事务拦截、权限拦截这些几乎全部由动态代理的身影。 Spring AOP的实现方式 Spring AOP中的动态代理主要有两种方式，JDK动态代理和CGLIB动态代理 JDK动态代理通过反射来接收被代理的类，并且要求被代理的类必须实现一个接口。JDK动态代理的核心是InvocationHandler接口和Proxy类。如果目标类没有实现接口，那么Spring AOP会选择使用CGLIB来动态代理目标类 CGLIB (Code Generation Library) ，是一个代码生成的类库，可以在运行时动态的生成某个类的子类，注意CGLIB是通过继承的方式做的动态代理，因此如果某个类被标记为final，那么它是无法使用CGLIB做动态代理的 Java 注解的作用是什么？ Java 注解用于为Java源代码提供元数据。作为元数据，注解不直接影响代码的执行，而是提供了关于代码的附加信息，以便编译器、工具、框架能够在不影响原始代码结构的情况下进行处理。其作用主要有以下几个： 提供元数据信息：注解可以在代码中添加关于类、方法、字段等元素的附加信息。这些信息可以描述类的用途、方法的用途、字段的含义等。 编译时检查：注解可以用于在编译的时候进行静态检查。例如，Java中内置的@Override注解可以保证在重写父类的方法时没有拼写错误或者参数错误。 代码生成：某些框架和工具可以根据注解生成额外的代码。 配置和定制：注解可以用于配置框架、库或其他组建的行为，例如Spring框架中的注解可以用来只是哪些类可以被Spring容器管理 文档生成：注解可以用于生成文档，以便开发人员了解代码的用途和约束。 运行时处理：通过Java的反射机制，可以在运行时检查类、方法或者字段上的注解，并且根据注解的信息执行不同的逻辑。 元注解是什么？都有哪些？ 元注解就是定义其他注解的注解 元注解主要有四个，分别是： @Target：表示被修饰的注解可以用于哪些类型，方法、类还是字段 @Retention：表示被修饰的注解的生命周期，即注解在源代码、编译时还是运行时保留。（SOURCE CLASS RUNTIME）默认为编译 @Documented：表示被修饰的注解文本信息是否保存到javadoc中 @Inherited：表示被修饰的注解是否允许被继承，默认不允许 如何判断是否有注解？ 使用反射来获取字段、类、方法上是否有注解并且注解的值为多少。使用的方法时 getAnnotation。 Java中的序列化是什么？ 序列化是将对象转换为可传输格式的过程。是一种数据的持久化手段。一般广泛应用于网络传输，RMI和RPC等场景中。 补充RMI和RPC的区别：二者都是为了实现分布式系统中远程调用的技术。RMI 适用于 Java 环境中实现远程方法调用，而 RPC 技术更为通用，可以用于不同语言和环境之间的分布式通信。 序列化的原理是什么？ 在Java的序列化机制中，如果是String，枚举或者实现了Serializable接口的类，均可以通过Java的序列化机制，将类序列化为符合编码的数据流，然后通过InputStream和OutputStream将内存中的类持久化到硬盘或者网络中；同时，也可以通过反序列化机制将磁盘中的字节码再转换成内存中的类。 如果一个类想被序列化，需要实现Serializable接口。否则将抛出NotSerializableException异常。Serializable接门没有方法或字段，仅用于标识可序列化的语义。自定义类通过实现Serializable接口做标识，进而在 IO 中实现序列化和反序列化，具体的执行路径如下 1#writeObject -&gt;#writeObjectO(判断类是否是自定义类) -&gt; #writeOrdinaryObject(区分Serializable和Externalizable) -&gt; writeSerialData(序列化fields) -&gt; invokewriteObject(反射调用类自己的序列化策略) 其中，在invokeWriteObject的阶段，系统就会处理自定义类的序列化方案。这是因为，在序列化操作过程中会对类型进行检查，要求被序列化的类必须属于Enum、Array和Serializable类型其中的任何一种。 Serializable 和 Externalizable 有啥区别？ 类通过实现 java.io.Serializable 接口以启用其序列化功能。未实现此接口的类将无法使其任何状态序列化或反序列化。可序列化类的所有子类型本身都是可序列化的。序列化接口没有方法或字段，仅用于标识可序列化的语义。当试图对一个对象进行序列化的时候，如果遇到不支持 Serializable 接口的对象。在此情况下，将抛出 NotSerializableException。如果要序列化的类有父类，要想同时将在父类中定义过的变量持久化下来，那么父类也应该实现java.io.Serializable接口。 Externalizable继承了Serializable，该接口中定义了两个抽象方法: writeExternal()与readExternal()。当使用Externalizable接口来进行席列化与反序列化的时候需要开发人员重写writeExternal()与readExternal()方法。如果没有在这两个方法中定义序列化实现细节，那么序列化之后，对象内容为空。实现Externalizable接口的类必须要提供一个public的无参的构造器。 所以，实现Externalizable，并实现writeExternal()和readExternal()方法可以指定序列化哪些属性 serialVersionUID 有什么作用？ 序列化指的是将对象的状态信息转换为可存储或者传输的形式，在JVM中，Java对象保存在JVM的堆内存中，因此如果JVM不存在，则表示对象随之消失。而序列化提供了一种方案，可以在JVM停机的情况下也把对象保存下来的方案。该方法通过将对象序列化成为可存储或者传输的形式（如二进制），比如保存在文件中，那么下次需要这个对象的时候，再从文件中读取出二进制流，再从二进制流中反序列化出对象。 虚拟机是否允许反序列化，不但取决于类路径和功能代码是否一致，最重要的是两个类的序列化ID是否相同，也就是 serialVersionUID 的值是否一致。在进行反序列化的时候，JVM会将传来的字节流的serialVersionUID 与本地相应实体类的serialVersionUID 进行比较，如果一致则进行反序列化，否则会出现序列化版本不一致的情况，也就是InvalidCastException，这样可以保证安全，因为文件存储的内容可能被篡改。（举个例子，你在本地使用序列号为1的Person序列化的对象，那么当你读取接收的时候也需要用这个实体类）。 当实现java.io.Serializable接口的类没有显式地定义一个serialVersionUID变量时候，Java序列化机制会根据编译的Class自动生成一个serialVersionUID作序列化版本比较用，这种情况下，如果Class文件没有发生变化，就算编译多次，serialVersionUID也不会变化的。但是，如果发生了变化，那么这个文件对应的serialVersionUID也就会发生变化。 基于以上原理，如果我们一个类实现了Serializable接口，但是没有定义serialVersionUID，然后序列化。在序列化之后，由于某些原因，我们对该类做了变更，重新启动应用后，我们相对之前序列化过的对象进行反序列化的话就会报错。 fastjson 反序列化有什么漏洞？ 首先当fastjson进行序列化的时候，当类中包含一个接口或者抽象类的时候，会将子类型抹去，只保留接口或者抽象类，这样会使得在反序列化的时候无法拿到原始类型。（举个例子，假设Apple类实现Fruit接口，那么在反序列化的时候，只能知道类型时Fruit而无法判断是Apple） 为了解决这个问题，fastjson引入了AutoType这个功能，也就是将JSON字符串反序列化的时候，自动读取@type的值，试图将JSON内容反序列化成为这个对象，并且会调用这个类的setter方法 那么这个特性就可能被利用，攻击者自己构造一个JSON字符串，并且使用 @type 指定一个自己想要使用的攻击类库实现攻击。 Java中异常分为哪两类？ Java中的异常，主要可以分为两大类，即受检异常 (checked exception) 和非受检异常 (uncheckedexception) 对于受检异常来说，如果一个方法在声明的过程中证明了其要有受检异常抛出:public void test() throws Exception{}。那么，当我们在程序中调用他的时候，一定要对该异常进行处理(捕获或者向上抛出)，否则是无法编译通过的。这是一种强制规范。 这种异常在IO操作中比较多。比如FileNotfFoundException ，当我们使用IO流处理文件的时候，有一种特殊情况，就是文件不存在。所以，在文件处理的接口定义时他会显示抛出FileNotFoundException，其目的就是告知方法的调用者，这个方法不保证一定可以成功，是有可能找不到对应的文件的，你要明确的对这种情况做特殊处理。 所以说，当我们希望我们的方法调用者，明确的处理一些特殊情况的时候，就应该使用受检异常. 对于非受检异常来说，一般是运行时异常，继承自RuntimeException。在编写代码的时候，不需要显示的捕获但是如果不捕获，在运行期如果发生异常就会中断程序的执行。这种异常一般可以理解为是代码原因导致的。比如发生空指针、数组越界等。所以，只要代码写的没问题，这些异常都是可以避免的。也就不需要我们显示的进行处理。 什么是Throwable？ Throwable是java中最顶级的异常类，继承Object，实现了序列化接口，有两个重要的子类: Exception和Error，二者都是 Java 异常处理的重要子类，各自都包含大量了类。 Error和Exception的区别和联系 error表示系统级的错误，是java运行环境内部错误或者硬件问题，不能指望程序来处理这样的问题，除了退出运行外别无选择，它是Java虚拟机抛出的。如OutOfMemoryError、StackOverflowErrorD这两种常见的错误都是ERROR。 exception 表示程序需要捕捉、需要处理的异常，是由与程序设计的不完善而出现的问题，程序必须处理的问题.分为RuntimeException和其他异常。 请列举几个常用的RuntimeException。 AnnotationTypeMismatchException, ArithmeticException, ArrayStoreException,BufferOverflowException, BufferUnderflowException, CannotRedoException, CannotUndoException，ClassCastException, CMMException, ConcurrentModificationException, DataBindingException,DOMException, EmptyStackException, EnumConstantNotPresentException, EventException,FileSystemAlreadyExistsException, FileSystemNotFoundException, llegalArgumentException,llegalMonitorStateException, llegalPathStateException, llegalStateException, llformedLocaleException.magingOpException, ncompleteAnnotationException, IndexOutOfBoundsException.MRuntimeException, LSException, MalformedParameterizedTypeException, MirroredTypesExceptionMissingResourceException, NegativeArraySizeException, NoSuchElementException，NoSuchMechanismException, NullPointerException, ProfileDataException, ProviderException，ProviderNotFoundException, RasterFormatException, RejectedExecutionException, SecurityException，SystemException, TypeConstraintException, TypeNotPresentException, UndeclaredThrowableExceptionJnknownEntityException, UnmodifiableSetException, UnsupportedOperationExceptionWebServiceException, WrongMethodTypeException 说一下Java中异常处理的几个关键字及用途 常见关键字有 throw、throws、try、catch、finally throw 用于明确的抛出一个异常 throws 用于向上抛出异常，通常是抛出所有可能的异常 try 是用来指定一块预防所有异常的程序 catch 使用在try 后面，用来指定想要捕获的异常的类型 finally 用于确保一段代码不管发生什么异常都会被执行 如何自定义异常？ 自定义异常就是开发人员自己定义的异常，一般通过继承Exception的子类的方式实现。 编写自定义异常类实际上是继承一个API标准异常类，用新定义的异常处理信息覆盖原有信息的过程 这种用法在Web开发中也比较常见，一般可以用来自定义业务异常。如余额不足、重复提交等。这种自定义异常有业务含义，更容易让上层理解和处理。 两种异常处理类型如何选用？ 两种异常处理类型指的是向上抛出throws和捕获并且处理异常try-catch 对于两种类型的选用遵循以下原则：如果知道如何处理就使用捕获并且处理异常try-catch方法；如果不知道如何进行处理则向上抛出 finally 中的代码一定会被执行吗？ 通常情况下，finally的代码一定会被执行，但是这是有一个前提的，: 1、对应 try 语句块被执行，2、程序正常运行。 如果没有符合这两个条件的话，finally中的代码就无法被执行，如发生以下情况，都会导致finally不会执行 System.exit() 方法被执行 Runtime.getRuntime().halt()方法被执行 try或者catch中有死循环 操作系统强制杀掉了JVM进程，如执行了kill -9 其他原因导致的虚拟机崩溃了 虚拟机所运行的环境挂了，如计算机电源断了 如果一个finally是由守护线程执行的，那么是不保证一定能执行的，如果这时候JVM要退出，JVM会检查其他非守护线程，如果都执行完了，那么就直接退出了。这时候finally可能就没办法执行完。 Java中枚举类有什么好处？ 枚举类型是指由一组固定的常量组成合法的类型。Java中由关键字enum来定义一个枚举类型 其好处有： 枚举的 valueof 可以自动对入参进行非法参数的校验（枚举的 valueOf 方法可以自动对输入参数进行校验，确保传入的值是有效的枚举常量。如果传入一个不存在的枚举常量名，会抛出 IllegalArgumentException。） 可以调用枚举中的方法，相对于普通的常量来说操作性更强。（枚举不仅仅是一组常量，它们可以具有方法，从而可以为每个枚举常量提供特定的行为，这使得操作枚举常量更加灵活和有用。） 枚举实现接口的话，可以很容易的实现策略模式。（枚举类可以实现接口，这意味着你可以根据不同的枚举常量选择不同的实现，实现了策略模式的思想。这在某些情况下能够更方便地管理和切换不同的行为。） 枚举可以自带属性，扩展性更强。（枚举类可以像普通类一样拥有字段和方法。这使得你可以将额外的信息与每个枚举常量关联起来，使枚举更具表现力和扩展性。） 枚举类使用哪种比较方式？ 枚举类equals底层也是使用==进行比较，所以二者均可以 简述 BIO、NIO、AIO 的特性以及应用场景 BIO 指的是同步阻塞 I/O，线程发起 IO 请求之后，一直阻塞，直到缓冲区数据就绪之后，才进入下一步操作 NIO 指的是同步非阻塞 I/O，线程发起 IO 请求之后，线程不需要阻塞，立即返回，用户线程不需要原地等待 IO 缓冲区，可以先做一些其他操作，只需要定时轮询 IO 缓冲区数据是否就绪即可。 AIO 指的是异步非阻塞 I/O，线程发起 IO 请求之后，不需要阻塞，立即返回，也不需要定时轮询检查结果，异步 IO 操作之后会立即回调通知调用方。 应用场景： BIO方式话用于连接数目比较小目固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中，JDK1.4以前的唯一选择，但程序直观简单易理解 NIO方式适用于连接数目多且连接比较短（轻操作)的架构，比如聊天服务器，并发局限于应用中，编程比较复杂，JDK1.4开始支持。 AIO方式适用于连接数目多且连接比较长(重操作)的架构，比如相册服务器，充分调用OS参与并发操作，编程比较复杂，JDK7开始支持。 Java是值传递还是引用传递？ 在程序设计中，求值策略有很多种，比较常见的就是值传递和引用传递。还有一种值传递的特例一一共享对象传递。 值传递和引用传递最大的区别是传递的过程中有没有复制出一个副本来，如果是传递副本，那就是值传递，否则就是引用传递。 在Java中，其实是通过值传递实现的参数传递，只不过对于Java对象的传递，传递的内容是对象的引用。所以可以说，Java中的求值策略是共享对象传递。 什么是深拷贝和浅拷贝？ 浅拷贝指的是将一个对象复制到另一个变量中的时候，只复制对象的地址，而不是对象本身。也就是说，原始对象和复制对象实际上是共享同一个内存地址的。这种拷贝方式，修改其中一个对象的属性或者元素，另一个对象的属性和元素也会随着变化。 深拷贝是指将一个对象及其所有的子对象都复制到另一个变量中，也就是说，他会创建一个全新的对象，并且将原始对象中的所有属性或元素都复制到新的对象中。因此在这种拷贝方式下，修改其中一个对象的属性或者元素的时候，另一个对象的属性或元素不改变。 实现深拷贝有哪些方式？ 实现 Clonable 方法，重写 clone() 方法。如果不重写 clone 方法，则依旧是浅拷贝。 序列化实现深拷贝。可以借助序列化来实现深拷贝。先把对象序列化成流，再从流中反序列化成对象，这样就一定是新的对象了序列化的方式有很多，比如我们可以使用各种JSON工具，把对象序列化成JSON字符串，然后再从字符串中反序列化成对象。 SimpleDateFormat 是线程安全的吗？ SimpleDateFormat是非线程安全的，所以在多线程场景中，不能使用SimpleDateFormat作为共享变量。 因为SimpleDateFormat中的format方法在执行过程中，会使用一个成员变量calendar来保存时间。如果我们在声明SimpleDateFormat的时候，使用的是static定义的。那么这个SimpleDateFormat就是一个共享变量，随之，simpleDateFormat中的calendar也就可以被多个线程访问到。 如何解决其线程不安全的问题？ 使用局部变量。将SimpleDateFormat 设置为局部变量，可以避免其被多个线程访问。 添加同步锁 使用ThreadLocal对每一个线程都创建一个SimpleDateFormat。 使用 DateTimeFormatter UUID 一定是唯一的吗？ UUID 全称全局唯一标识符，是指在一台机器上生成的数字，它的目标是保证对在同时空中的所有机器都是唯一的。UUID 的生成是基于一定算法，通常使用的是随机数生成器或者基于时间戳的方式，生成的 UUID 由 32 位 16 进制数表示，共有 128位(标准的UUID格式为: xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx(8-4-4-4-12)，共32字符)。由于 UUID 是由 MAC 地址、时间戳、随机数等信息生成的，因此 UUID 具有极高的唯一性，可以说是几乎不可能重复，但是在实际实现过程中，UUID有多种实现版本，他们的唯一性指标也不尽相同。 UUID 有哪些优缺点？ UUID 的优点就是他的性能比较高，不依赖网络，本地就可以生成，使用起来也比较简单。 UUID 的缺点是长度过长和没有任何含义。 char可以存储中文吗？ 在Java中，char类型是用来表示一个16位的Unicode字符，它可以存诸任何Unicode字符集中的字符，当然也包括中文字符。 while(true) 和 for(;;) 哪个性能更好？ 一样的，二者编译之后都是使用goto来实现的，实现方法一样，性能相同。 ClassNotFoundException和NoClassDefFoundError的区别是什么 ClassNotFoundException是一个受检异常 (checked exception)。他通常在运行时，在类加载阶段尝试加载类的过程中，找不到类的定义时触发。通常是由Class.forName或类加载器loadClass或者findSystemClass时在类路径中没有找到指定名称的类时，会抛出该异常。表示所需的类在类路径中不存在。这通常是由于类名拼写错误或缺少依赖导致的。 NoClassDefFoundError是一个错误 (error) ，它表示运行时尝试加载一个类的定义时，虽然找到了类文件，但是在加载、解析或链接类的过程中发生了问题。这通常是由于依赖问题或类定义文件 (.class文件)损坏导致的。也就是说这个类在编译时存在，运行时丢失了，就会导致这个异常。","link":"/2023/08/24/JavaSE/"},{"title":"数据结构","text":"本篇内容： 对数据结构进行整体的复习 除了数据结构理论知识以外，本篇更注重实践，提供了各种数据结构的代码 对数据结构常见面试题进行分模块整理 链表1.链表简介1.1链表是什么？链表是数据元素的线性集合， 元素的线性顺序不是由它们在内存中的物理地址给出的，即链表的物理地址不连续。 它是由一组节点组成的数据结构， 每个元素指向下一个元素，每个节点由数据和指针（存放指向下一个节点的指针）两部分组成， 这种数据结构允许在迭代时有效地从序列中的任何位置插入或删除元素。这些节点一起，表示线性序列。 1.2链表的优点和缺点 优点：可以不需要扩容空间就更高效的插入和删除元素的操作。 缺点：在指定位置操作、或者访问任意元素下， 是需要循环遍历的， 这将导致时间复杂度的提升。 总结来说，链表适合插入和删除元素多的场景，不适合查找多的场景。 2.链表分类2.1单向链表单链表由数据和指针构成，指针指向下一个节点。 可以对单链表执行的操作包括插入、 删除和遍历。 2.2双向链表双向链表包括数据、指向下一个节点的字段和指向上一个节点的字段。 2.3循环链表循环链表是在单链表的基础上，将最后一个节点的指针指向了第一个节点，从而构成了一个环。 3.常见面试问题 描述一下链表的数据结构？ 链表是一组元素的线性集合，元素顺序不是由物理地址决定。单向链表是由数据+指向下一个节点的指针组成；双向链表是由数据+指向下一个节点的指针+指向上一个节点的指针组成；双向链表在单项链表的基础上，在最后一个元素添加指向第一个元素的指针。链表的数据结构便于插入和删除元素，其复杂度为 O(1)。 Java 中 LinkedList 使用的是单向链表、双向链表还是循环链表？ 双向链表。其节点是由 prev指针 + 数据 + next指针组成。 链表中数据的插入、删除、获取元素，时间复杂度是多少？ 插入、删除单个元素：O(1) 删除多个、获取元素：O(n) 什么场景下使用链表更合适？ 经常进行插入和删除元素；很少进行查找操作的情况下。 数组1.数组的简介1.1什么是数组？数组（Array） 是一种线性表数据结构。它用一组连续的内存空间， 来存储一组具有相同类型数据的集合。 1.2数组的特点数组的特点： 数组是相同数据类型的元素集合（int 不能存放 double） 数组中各元素的存储是有先后顺序的，它们在内存中按照这个顺序连续存放到一起，内存地址连续。 数组获取元素的时间复杂度为 O(1) 2.数组的类型1.1一维数组一维数组是最常用的数组， 其他很多数据结构的变种也都是从一维数组来的。 例如 HashMap 的拉链寻址结构， ThreadLocal 的开放寻址结构， 都是从一维数组上实现的。 1.2二维数组3.数组的实现在 Java 的源码中，数组是一个非常常用的数据结构，很多其他数据结构也都有数组的影子。在一些数据存放和使用的场景中，基本也都是使用 ArrayList 而不是 LinkedList ArrayList 实现过程： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778package array_list;import java.util.Arrays;public class ArrayList&lt;E&gt; implements List&lt;E&gt; { /** * 默认初始化空间 */ private static final int DEFAULT_CAPACITY = 10; /** * 空元素 */ private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {}; /** * ArrayList 元素数组缓存区 */ transient Object[] elementData; /** * List 集合元素数量 */ private int size; public ArrayList() { // 默认给个空的元素，当开始添加元素的时候在初始化长度 this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; } @Override public boolean add(E e) { // 确保内部容量 int minCapacity = size + 1; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) { minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); } // 判断扩容操作 if (minCapacity - elementData.length &gt; 0) { int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) { newCapacity = minCapacity; } elementData = Arrays.copyOf(elementData, newCapacity); } // 添加元素 elementData[size++] = e; return true; } @Override public E remove(int index) { E oldValue = (E) elementData[index]; int numMoved = size - index - 1; if (numMoved &gt; 0) { // 从原始数组的某个位置，拷贝到目标对象的某个位置开始后n个元素 System.arraycopy(elementData, index + 1, elementData, index, numMoved); } elementData[--size] = null; // clear to let GC do its work return oldValue; } @Override public E get(int index) { return (E) elementData[index]; } @Override public String toString() { return &quot;ArrayList{&quot; + &quot;elementData=&quot; + Arrays.toString(elementData) + &quot;, size=&quot; + size + '}'; }} 逐步解析： add 方法： 1234567891011121314151617181920@Override public boolean add(E e) { // 确保内部容量 int minCapacity = size + 1; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) { minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); } // 判断扩容操作 if (minCapacity - elementData.length &gt; 0) { int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) { newCapacity = minCapacity; } elementData = Arrays.copyOf(elementData, newCapacity); } // 添加元素 elementData[size++] = e; return true; } minCapacity 是表示当前ArrayList中元素的数量加上要添加的新元素数量。在add方法中，minCapacity 的计算方式是 size + 1，其中 size 表示当前ArrayList中已有元素的数量，而 1 表示要添加的新元素数量。 在 ArrayList 中，size 属性表示当前列表中已经存储的元素数量，而 elementData 是内部的数组用于存储元素。当我们向ArrayList中添加新元素时，会根据 minCapacity 来判断是否需要进行扩容操作，保证足够的容量来存放新的元素。 注意，在添加元素之前，minCapacity 需要考虑到当前已有元素的数量，因为我们要确保能够容纳新元素。所以，minCapacity 的值等于 size + 1，其中 size 是已有元素的数量，1 是要添加的新元素数量。如果 minCapacity - elementData.length &gt; 0 条件成立，说明当前容量不足以容纳要添加的新元素，需要进行扩容操作。 扩容操作：新容量 = 旧容量 + （旧容量）/ 2 如果扩容之后仍然不满足条件，即容量小于包含的元素数量，即newCapacity - minCapacity &lt; 0，此时令newCapacity = minCapacity;，然后使用 Arrays.copyOf(数据, 容量)拷贝到新数组中。 执行添加元素操作 remove 方法： 1234567891011@Overridepublic E remove(int index) { E oldValue = (E) elementData[index]; int numMoved = size - index - 1; if (numMoved &gt; 0) { // 从原始数组的某个位置，拷贝到目标对象的某个位置开始后n个元素 System.arraycopy(elementData, index + 1, elementData, index, numMoved); } elementData[--size] = null; // clear to let GC do its work return oldValue;} System.arraycopy()各参数的作用 4.常见面试题 数据结构中有哪些是线性表数据结构？ 链表、队列、数组、栈、哈希表 数组的元素删除和获取，时间复杂度是多少？ 删除：O(n) 获取：O(1) ArrayList 中默认的初始化长度是多少？ 10 ArrayList 中扩容的范围是多大一次？ 1.5倍。原始容量 + 原始容量 / 2 ArrayList 是如何完成扩容的，System.arraycopy 各个入参的作用是什么？ 每次添加元素前，size+1， 与当前容器长度进行比较，当增加一个后的容量大于当前容量，调用 Arrays.copyOf 方法进行扩容1.5倍，参数为原始链表，扩容后的容量，其本质是调用本地函数 System.arraycopy public static native void arraycopy(Object src, int srcPos,Object dest, int destPos,int length); 第一个参数 src ：原始容器 第二个参数 srcPos：原始容器开始下标 第三个参数 dest：新容器 第四个参数 destPos：新容器开始下标 第五个参数 length：要移动的个数 队列1.队列的简介1.1队列的简介队列是一种特殊类型的抽象数据类型或集合（可以使用链表实现，也可以使用数组实现），集合中的实体对象按顺序保存。 将元素添加到队列后的操作称之为入队，从队列中移除的操作称之为出队。同时也包括有 peek、element 操作。队列的特点是先进先出（FIFO）。 1.2队列的实现 理论上来说，队列没有特定的容量。不管包含多少元素，总能继续添加新元素。 队列既可以使用数组实现，也可以使用链表实现（后面详细叙述） 队列不只是可以单端从一个口入，一个口出，也可以是双端队列（Deque）。 1.2.1单端队列(Queue)Queue 的实现类有 LinkedList 和 PriorityQueue。最常用的实现类是 LinkedList。 12Queue&lt;Object&gt; queue = new LinkedList&lt;&gt;();Queue&lt;Object&gt; queue = new PriorityQueue&lt;&gt;(); 常用的方法： 添加元素操作：add() 和 offer() 相同点：当容量未满的时候，在队列末尾进行元素添加，返回被添加的元素 不同点：当容量满了之后，add 方法爆出异常，offer 方法返回 false 删除元素操作：remove() 和 poll() 相同点：当容量不为 0 的时候，删除并返回队尾被删除的元素 不同点：当容量为 0 的时候，remove 爆出异常，poll 方法返回 false 取出队头元素：element() 和 peek() 相同点：当容量不为 0 的时候，返回队头元素，但是不删除 不同点：当容量为 0 的时候，element()会抛出异常，peek()返回null 队列通常（但并非一定）以 FIFO（先进先出）的方式排序各个元素。不过优先级队列和 LIFO 队列（或堆栈）例外，前者根据提供的比较器或元素的自然顺序对元素进行排序，后者按 LIFO（后进先出）的方式对元素进行排序。无论使用哪种排序方式，队列的头都是调用 remove() 或 poll() 所移除的元素。在 FIFO 队列中，所有的新元素都插入队列的末尾。其他种类的队列可能使用不同的元素放置规则。每个 Queue 实现必须指定其顺序属性。 1.2.2双端队列(Deque)Deque 是一个双端队列接口，继承自 Queue 接口，Deque的实现类是 LinkedList、ArrayDeque、LinkedBlockingDeque，其中LinkedList 是最常用的。 Deque 的用途： 普通队列（一端进一端出）： 12Queue queue = new LinkedList();Deque deque = new LinkedList();// 双端队列也可以实现单端队列的功能 双端队列（两端都可进出） 1Deque deque = new LinkedList(); 堆栈 1Deque deque = new LinkedList(); 注意：Java 堆栈 Stack 已经过时，Java 官方推荐使用 Deque 替代 Stack 使用。Deque 堆栈操作方法：push()、pop()、peek()。 双端队列与单端队列方法映射关系 Queue方法 等效Deque方法 add(e) addLast(e) offer(e) offerLast(e) remove() removeFirst() poll() pollFirst() element() getFirst() peek() peekFirst() 双端队列与堆栈的方法映射关系 堆栈方法 等效Deque方法 push(e) addFirst(e) pop() removeFirst() peek() peekFirst() 2.延迟队列的实现——实战3.常见面试题 单端队列和双端队列，分别对应的实现类是哪个？ 单端队列：LinkedList 和 PriorityList 双端队列：LinkedList 和 ArrayDeque 简述延迟队列/优先队列的实现方式 DelayQueue 是一个 BlockingQueue（无界阻塞）队列，它封装了一个使用完全二叉堆排序元素的 PriorityQueue（优先队列）。在添加元素时使用 Delay（延迟时间）作为排序条件，延迟最小的元素会优先放到队首。并且在删除和添加元素的时候都会添加锁，从而保证线程安全。 二叉堆插入/弹出元素的过程 插入：首先二叉堆的性质是父节点的值小于等于子节点，因此在插入元素时，首先将其插入二叉堆末尾，然后判断该元素与父节点值的大小，如果小于父节点的值，则进行上移，指导满足二叉堆的性质 弹出：元素的出队只要把根元素直接删除弹出即可。但是在根元素迁移走后，寻找另外的最小元素迁移到堆头。这个过程与入队正好相反，这是一个不断向下迁移的过程。 延迟队列的使用场景 定时任务调度、任务重试、延迟发送。 延迟消费。比如： 用户生成订单之后，需要过一段时间校验订单的支付状态，如果订单仍未支付则需要及时地关闭订单。 用户注册成功之后，需要过一段时间比如一周后校验用户的使用情况，如果发现用户活跃度较低，则发送邮件或者短信来提醒用户使用。 延迟重试。比如消费者从队列里消费消息时失败了，但是想要延迟一段时间后自动重试。 延迟队列为什么添加信号量 信号量（Semaphore）是一种用于控制对共享资源的访问的机制，它可以用来限制同时访问某一资源的线程或进程的数量。信号量常用于避免竞争条件，确保多个线程或进程能够有序地访问共享资源，从而防止数据损坏或不一致性。将信号量与延迟队列结合起来，可以在某些特定场景下实现更为复杂的业务逻辑。例如，在一个需要执行多个延迟任务的系统中，通过使用信号量可以控制同时执行这些任务的数量，以避免资源过度消耗，同时保证任务的有序执行。 限制并发执行数量：在某些情况下，你可能希望限制延迟队列中的任务并发执行的数量，以免资源被过度占用。信号量可以帮助你控制同时处理的任务数量，从而避免系统过载。 平滑流量：如果你有一个大量的延迟任务需要执行，使用信号量可以使这些任务以适当的速率被执行，而不是一下子全部执行，从而平滑系统的负载。 优先级控制：通过设置不同的信号量值，你可以为不同的延迟任务设定不同的优先级。这样，你可以确保高优先级的任务能够更快地得到执行。 资源管理：延迟队列可能需要占用一些系统资源，通过信号量可以控制这些资源的使用，避免资源浪费或冲突。 补充知识点逻辑移位和算数移位 逻辑移位：（&gt;&gt;&gt;） 逻辑左移：将二进制数的所有位都向左移动，右侧填充0。这会使数值增大，相当于乘以2的移动次幂。 逻辑右移：将二进制数的所有位都向右移动，左侧填充0。这会使数值减小，相当于除以2的移动次幂。 算数移位:（&gt;&gt;） 算数左移：将二进制数的所有位都向左移动，右侧填充0。这类似于逻辑左移，但在最左侧的符号位不变。 算数右移：将二进制数的所有位都向右移动，左侧使用最左侧的位来填充。这会保持符号位不变，但数值会减小，相当于除以2的移动次幂。 栈1.栈的简介栈是一种 LIFO（后进先出）的线性的数据结构，或者更抽象说是一种顺序集合，push 和 pop 操作只发生在结构的一端，称为栈顶。 注意：之前刷算法也确实存在这个问题。栈使用的时候一定不要使用 Stack 类，这个类是在 JDK1.0 的时候创建的，性能较差。应当使用 ArrayDeque 或者 LinkedList 来实现 2.ArrayDequeArrayDeque 是一个基于数组实现的栈数据结构，在数据存放时元素通过二进制与运算获取对应的索引存放元素。当数组长度超过初始空间后，进行2的n次幂左移一位扩容，并将数组内容的元素按照分半分别进行迁移。 源码解析： 由于Deque接口是双向队列，所以再进行添加元素的时候会指定head指针和tail尾指针，head指针指向数据元素的头部，tail指针指向数据元素的尾部，通过head指针和tail指针控制是从头部进行操作还是尾部进行操作，以下是ArrayDeque中的字段信息： 12345678910111213141516171819/** * 数组存储的元素。 */transient Object[] elements; // non-private to simplify nested class access/** * 头指针。 */transient int head;/** * 尾指针。 */transient int tail;/** * 数组的默认最小大小。长度必须是2的幂次方。 */private static final int MIN_INITIAL_CAPACITY = 8; 2.1数组长度首先我们来解决第一个问题，就是数组的长度的问题，数组长度前面说必须是2的幂次方，但是看到构造函数中可以指定数组的长度，既然可以指定数组的长度，那这里指定数组长度为10，这个数字也不是2的幂次方啊，其实我们指定的虽然不是2的幂次方，但是ArrayDeque内部会帮我进行调整，调整数组长度为2的幂次方，先看一下ArrarDeque的构造函数： 12345678910111213141516171819// 默认长度为16的数组。public ArrayDeque() { elements = new Object[16];}/** * 指定数组长度，发现指定数组长度时，调用了allocateElements方法。 */public ArrayDeque(int numElements) { allocateElements(numElements);}/** * 指定集合并且初始化大小。 */public ArrayDeque(Collection&lt;? extends E&gt; c) { allocateElements(c.size()); addAll(c);} 可以看到，除了无参构造会构造一个默认长度的数组以外，其他构造方式都需要allocateElements函数来进行 123456/** * 初始化数组大小，调用calculateSize方法来调整容量大小。 */private void allocateElements(int numElements) { elements = new Object[calculateSize(numElements)];} allocateElements 又通过 calculateSize 来进行调用 12345678910111213141516171819private static int calculateSize(int numElements) { // 获取最小的初始化容量大小。 int initialCapacity = MIN_INITIAL_CAPACITY; // 如果容量大于最小的容量，则寻找一个2的幂次方的值。 if (numElements &gt;= initialCapacity) { initialCapacity = numElements; initialCapacity |= (initialCapacity &gt;&gt;&gt; 1); initialCapacity |= (initialCapacity &gt;&gt;&gt; 2); initialCapacity |= (initialCapacity &gt;&gt;&gt; 4); initialCapacity |= (initialCapacity &gt;&gt;&gt; 8); initialCapacity |= (initialCapacity &gt;&gt;&gt; 16); initialCapacity++; if (initialCapacity &lt; 0) // Too many elements, must back off initialCapacity &gt;&gt;&gt;= 1;// Good luck allocating 2 ^ 30 elements } // 返回2的幂次方值。 return initialCapacity;} 假设我们传入的参数值为 10，即 1010 。下面分析如何得到 2 的幂次方。 判断条件 10 &gt; 8 成立，进入 if 语句判断中。numElements = 10，initialCapacity = 10; initialCapacity 向右移位 1，从而得到 0101，与 1010 进行或运算，得到 1111 initialCapacity 向右挪动两位，再与 1111 做或运算，得到的依旧是 1111 直到最后，initialCapacity 保持 1111，然后对其进行 ++ 操作，得到 initialCapacity 为16 整体思路是每次移动将位数最高的值变成1，从而将二进制所有位数都变成1，变成1之后得到的十进制加上1之后得到值就是2的幂次方的值，这里的操作在JDK1.7版本中的HashMap扩容操作代码是类似的。 2.2AddFirst方法1234567public void addFirst(E e) { if (e == null) throw new NullPointerException(); elements[head = (head - 1) &amp; (elements.length - 1)] = e; if (head == tail) doubleCapacity();} 此时初始化时数组长度为16，头指针head和尾指针head默认是0，此时数组的内容如下所示： 当执行addFirst方法插入数组元素5时，通过源码可以看到需要执行elements[head = (head - 1) &amp; (elements.length - 1)] = e;这一行代码，至于后面那个head==tail是为了扩容使用，也就是只有在队列满时才会对数组进行扩容操作，队列满的标识是head==tail代表队列已经满了，这里先进行分析elements[head = (head - 1) &amp; (elements.length - 1)] = e，我们将其拆分成如下内容 head=head-1，此时的head=0，那么head-1得到值15（二进制减法操作），15使用二进制表示为：1111 elements.length - 1，这里开始是初始化大小为10，通过calculateSize方法计算的到数组长度为16，16-1=15，二进制表示方式也是1111。 1111&amp;1111依然是1111，此时数组的下标为15。即将元素插入到下标为 15 的位置 2.3AddLast方法1234567public void addLast(E e) { if (e == null) throw new NullPointerException(); elements[tail] = e; if ( (tail = (tail + 1) &amp; (elements.length - 1)) == head) doubleCapacity();} 直接使用 elements[tail] = e;即可添加元素，然后将指针向后移动。此时数组中元素存储情况以及tail指针移动位置如图。 2.4pollFirst方法12345678910111213141516public E pollFirst() { // 获取头指针。 int h = head; @SuppressWarnings(&quot;unchecked&quot;) // 获取头指针对应的数组元素值。 E result = (E) elements[h]; // Element is null if deque empty // 如果为空则说明说明数组为空，直接返回。 if (result == null) return null; // 将头指针值设置为空。 elements[h] = null; // Must null out slot // 啊哈？这里是不是我们上面猜测的内容，头指针下一个位置。 head = (h + 1) &amp; (elements.length - 1); return result;} 2.5pollLast方法1234567891011121314public E pollLast() { // 找到尾指针的前一个指针位置。 int t = (tail - 1) &amp; (elements.length - 1); @SuppressWarnings(&quot;unchecked&quot;) // 获取尾部元素。 E result = (E) elements[t]; if (result == null) return null; // 将尾部元素设置为空。 elements[t] = null; // 调整尾指针位置。 tail = t; return result;} 2.6扩容操作如上分析，我们在队头或队尾添加元素的时候都会出现容量已满需要扩容的情况。由于今天学习的数据结构是栈，栈满足的条件是后进先出，添加元素的时候使用 push，而不是分队头队尾分别添加。 我们以向栈中一次加入1、2、3、4为例。 首先假设最初栈数组长度为 2（仅限于举例，实际栈长度默认最小为 8）。 根据前面的分析，head 处于数组最后的位置，即 index 最大的位置向前进行元素添加。 在进行输出的时候，head = (head + 1) &amp; (n - 1) 也就是从下标小到大依次进行输出 触发扩容操作之后，扩容操作分为两步，前半段和后半段 ArrayDeque 每次都把 tail 设置为中点，那么只要 head == tail，那么head 就是中点，因此 head 之前的为前半段，head 之后的为后半段。第一次扩容由于tail 是 0。所以第一次扩容直接全部复制到新数组中。 之后扩容会将前半段和后半段分别进行复制操作 栈的弹出操作： 3.常问面试题 堆栈的使用场景？ 适用于后进先出的数据结构使用场景。 为什么不是用 Stack 类？ 性能上看，Deque 性能优于 Stack 。 Stack和Vector都是线程安全的，其实多数情况下并不需要做到线程安全，因此没有必要使用Stack。毕竟保证线程安全需要上锁，有额外的系统开销。 Stack从Vector继承的一个副作用是，暴露了set/get方法，可以进行随机位置的访问，这与Stack只能从尾巴上进行增减的本意相悖。此外，Deque在转成ArrayList或者stream的时候保持了“后进先出”的语义，而Stack因为是从Vector继承，没有这个语义。 ArrayDeque 是基于什么实现的？ 数组 ArrayDeque 数据结构使用过程叙述。 使用过程见上 ArrayDeque 为什么要初始化2的n次幂个长度？ 保证了在后续计算元素索引位置时，可以进行与运算。也就说 2的n次幂 -1 得到的值是一个011111的范围，在与元素索引位置计算时候，找到两个值之间1的位置即可。 哈希表1.哈希表的简介 在计算机科学中，一个哈希表（hash table、hash map）是一种实现关联数组的抽象数据结构，该结构将键通过哈希计算映射到值。也就是说我们通过对一个 Key 值计算它的哈希并与长度为2的n次幂的数组减一做与运算，计算出槽位对应的索引，将数据存放到索引下。那么这样就解决了当获取指定数据时，只需要根据存放时计算索引ID的方式再计算一次，就可以把槽位上对应的数据获取处理，以此达到时间复杂度为O(1)的情况。 哈希表也叫散列表，哈希表是一种根据关键码值 (key value) 而直接进行访问的数据结构。它提供了快速的插入操作和查找操作，无论哈希表总中有多少条数据，**插入和查找的时间复杂度都是为O(1)**，因为哈希表的查找速度非常快，所以在很多程序中都有使用哈希表。 总结来说，哈希表的存在是为了解决能通过 O(1) 时间复杂度直接索引到指定元素。 理想的情况是所有存入 key 的哈希值都不相同，即位于不同的位置。但是随着元素的增多，很可能发生哈希冲突，或者哈希值波动不大导致索引计算相同，也就是一个索引位置出现多个元素情况。解决这个问题产生了许多不同的方案，如HashMap 中的拉链寻址 + 红黑树、扰动函数、负载因子、ThreadLocal 的开放寻址、合并散列、杜鹃散列、跳房子哈希、罗宾汉哈希等各类数据结构设计。 2.哈希表的实现2.1哈希碰撞首先实现一个简单的 hashmap，如下： 1234567891011121314151617public class HashMap01&lt;K, V&gt; implements Map&lt;K, V&gt; { private final Object[] tab = new Object[8]; @Override public void put(K key, V value) { int idx = key.hashCode() &amp; (tab.length - 1); tab[idx] = value; } @Override public V get(K key) { int idx = key.hashCode() &amp; (tab.length - 1); return (V) tab[idx]; }} 这种结构会发生哈希碰撞 使用哈希散列必须解决的一个问题，无论是在已知元素数量的情况下，通过扩容数组长度解决，还是把碰撞的元素通过链表存放，都是可以的。 2.2拉链寻址既然我们没法控制元素不碰撞，但我们可以对碰撞后的元素进行管理。比如像 HashMap 中拉链法一样，把碰撞的元素存放到链表上。这里我们就来简化实现一下。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class HashMap02BySeparateChaining&lt;K, V&gt; implements Map&lt;K, V&gt; { private final LinkedList&lt;Node&lt;K, V&gt;&gt;[] tab = new LinkedList[8]; @Override public void put(K key, V value) { int idx = key.hashCode() &amp; (tab.length - 1); if (tab[idx] == null) { tab[idx] = new LinkedList&lt;&gt;(); tab[idx].add(new Node&lt;&gt;(key, value)); } else { tab[idx].add(new Node&lt;&gt;(key, value)); } } @Override public V get(K key) { int idx = key.hashCode() &amp; (tab.length - 1); for (Node&lt;K, V&gt; kvNode : tab[idx]) { if (key.equals(kvNode.getKey())) { return kvNode.value; } } return null; } static class Node&lt;K, V&gt; { final K key; V value; public Node(K key, V value) { this.key = key; this.value = value; } public K getKey() { return key; } public V getValue() { return value; } }} 因为元素在存放到哈希桶上时，可能发生下标索引膨胀，所以这里我们把每一个元素都设定成一个 Node 节点，这些节点通过 LinkedList 链表关联，当然你也可以通过 Node 节点构建出链表 next 元素即可。 那么这时候在发生元素碰撞，相同位置的元素就都被存放到链表上了，获取的时候需要对存放多个元素的链表进行遍历获取。 2.3开放寻址除了对哈希桶上碰撞的索引元素进行拉链存放，还有不引入新的额外的数据结构，只是在哈希桶上存放碰撞元素的方式。它叫开放寻址，也就是 ThreaLocal 中运用斐波那契散列+开放寻址的处理方式。 12345678910111213141516171819202122232425262728293031323334353637383940public class HashMap03ByOpenAddressing&lt;K, V&gt; implements Map&lt;K, V&gt; { private final Node&lt;K, V&gt;[] tab = new Node[8]; @Override public void put(K key, V value) { int idx = key.hashCode() &amp; (tab.length - 1); if (tab[idx] == null) { tab[idx] = new Node&lt;&gt;(key, value); } else { for (int i = idx; i &lt; tab.length; i++) { if (tab[i] == null) { tab[i] = new Node&lt;&gt;(key, value); break; } } } } @Override public V get(K key) { int idx = key.hashCode() &amp; (tab.length - 1); for (int i = idx; i &lt; tab.length; i ++){ if (tab[idx] != null &amp;&amp; tab[idx].key == key) { return tab[idx].value; } } return null; } static class Node&lt;K, V&gt; { final K key; V value; public Node(K key, V value) { this.key = key; this.value = value; } }} 开放寻址的设计会对碰撞的元素，寻找哈希桶上新的位置，这个位置从当前碰撞位置开始向后寻找，直到找到空的位置存放。 在 ThreadLocal 的实现中会使用斐波那契散列、索引计算累加、启发式清理、探测式清理等操作，以保证尽可能少的碰撞。 2.4合并散列合并散列是开放寻址和单独链接的混合，碰撞的节点在哈希表中链接。此算法适合固定分配内存的哈希桶，通过存放元素时识别哈希桶上的最大空槽位来解决合并哈希中的冲突。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class HashMap04ByCoalescedHashing&lt;K, V&gt; implements Map&lt;K, V&gt; { private final Node&lt;K, V&gt;[] tab = new Node[8]; @Override public void put(K key, V value) { int idx = key.hashCode() &amp; (tab.length - 1); if (tab[idx] == null) { tab[idx] = new Node&lt;&gt;(key, value); return; } int cursor = tab.length - 1; while (tab[cursor] != null &amp;&amp; tab[cursor].key != key) { --cursor; } tab[cursor] = new Node&lt;&gt;(key, value); // 将碰撞节点指向这个新节点 while (tab[idx].idxOfNext != 0){ idx = tab[idx].idxOfNext; } tab[idx].idxOfNext = cursor; } @Override public V get(K key) { int idx = key.hashCode() &amp; (tab.length - 1); while (tab[idx].key != key) { idx = tab[idx].idxOfNext; } return tab[idx].value; } static class Node&lt;K, V&gt; { final K key; V value; int idxOfNext; public Node(K key, V value) { this.key = key; this.value = value; } }} 合并散列的原理是，当发生哈希冲突之后，将冲突的元素加到哈希表的最后，然后将当前哈希值的指针指向冲突的元素。也就是将发生哈希碰撞的元素进行链接。 合并散列的最大目的在于将碰撞元素链接起来，避免因为需要寻找碰撞元素所发生的循环遍历。也就是A、B元素存放时发生碰撞，那么在找到A元素的时候可以很快的索引到B元素所在的位置。 2.5杜鹃散列这个名字起的比较有意思，也代表着它的数据结构。杜鹃鸟在孵化🐣的时候，雏鸟会将其他蛋或幼崽推出巢穴；类似的这个数据结构会使用2组key哈希表，将冲突元素推到另外一个key哈希表中。 123456789101112131415161718192021222324252627282930313233343536private V put(K key, V value, boolean isRehash) { Object k = maskNull(key); if (containsKey(k)) { return null; } if (insertEntry(new Entry&lt;K, V&gt;((K) k, value))) { if (!isRehash) { size++; } return null; } rehash(2 * table.length); return put((K) k, value);}private boolean insertEntry(Entry&lt;K, V&gt; e) { int count = 0; Entry&lt;K, V&gt; current = e; int index = hash(hash1, current.key); while (current != e || count &lt; table.length) { Entry&lt;K, V&gt; temp = table[index]; if (temp == null) { table[index] = current; return true; } table[index] = current; current = temp; if (index == hash(hash1, current.key)) { index = hash(hash2, current.key); } else { index = hash(hash1, current.key); } ++count; } return false;} 当多个键映射到同一个单元格时会发生这种情况。杜鹃散列的基本思想是通过使用两个散列函数而不是仅一个散列函数来解决冲突。 这为每个键在哈希表中提供了两个可能的位置。在该算法的一种常用变体中，哈希表被分成两个大小相等的较小的表，每个哈希函数都为这两个表之一提供索引。两个散列函数也可以为单个表提供索引。 在实践中，杜鹃哈希比线性探测慢约 20-30%，线性探测是常用方法中最快的。然而，由于它对搜索时间的最坏情况保证，当需要实时响应率时，杜鹃散列仍然很有价值。杜鹃散列的一个优点是它的无链接列表属性，非常适合 GPU 处理。 2.6跳房子散列跳房子散列是一种基于开放寻址的算法，它结合了杜鹃散列、线性探测和链接的元素，通过桶邻域的概念——任何给定占用桶周围的后续桶，也称为“虚拟”桶。 该算法旨在在哈希表的负载因子增长超过 90% 时提供更好的性能；它还在并发设置中提供了高吞吐量，因此非常适合实现可调整大小的并发哈希表。 跳房子散列的思路：用事先确定的，对计算机底层体系结构而言最优的一个常数，给探测序列的最大长度加个上界。三大特点：线性探测、探测长度有上限、上限是提前确定的。 举个例子进行理解： a）设置最大探测上界 MAX_DIST = 4 b）散列位置 hash(x)，则探测位置为 hash(x) + 0、hash(x) + 1、hash(x) + 2、hash(x) +3。 c）下例： 插入 A 时，在 7 的位置没有元素，因此直接插入 hash(x) + 0 的位置，因此 Hop 为 1000，同理插入 B C 插入 D 的时候，发现 7 的位置已经存在元素，因此将其存入 hash(x) + 1的位置，并且将 A 的 Hop 值设置为 1100（表示hash + 0和 hash + 1的位置都有元素），D 的 Hop 设置为 0000. 插入 E 的时候，发现被 D 占有了，因此向下寻找，直到 10 这个位置，并将 D 的值设置为 0010 （代表hash(x) + 2 的位置） 添加 G F 问：如果线性探测，直到上界都无法插入呢？ 答：当我们上界设置得不够大时，这种情况是必须考虑的。此时的插入流程将会稍微复杂。 例如：我们在上述例子中继续插入H，散列值为9。我们探测位置9、10、11、12都被占用，只能到13，但是位置13明显超过上界，即h a s h ( x ) + 3 hash(x)+3hash(x)+3都未能找到可插入点。那我们将找一个值y来替换掉。并把它重置到位置13。可以去到位置13的值只有散列值为10、11、12、13的值。如果我们检查Hop[10]，它的值为“0000”，没有可以替换的候选项，于是我们检查Hop[11],它的值为“1000”，其值为G，可以被放到位置13。于是我们将元素G放到位置13，将11空出来，插入H。 2.7罗宾汉哈希罗宾汉哈希法算法思想是，当我们进行插入时，如果发现单元格被其他键值对占用，那么就需要比较这俩人键距离其原本位置的距离。距离较远的键值对留下，距离较近的被迫后移。 举个例子： A B 正常插入 C 插入时，A 已经被占，C 被迫后移 D 插入时，C 已经被占，并且 C 的偏移量大于 D，因此 D 后移 E 插入时，在 A 处偏移量与 A 相同，所以 E 后移，到 C 的位置处，二者偏移量依旧相同，继续后移 到 D 位置的时候，此时 E 偏移量大于 D ，因此 D 后移 3.常见面试题 介绍一下散列表 散列表，也称为哈希表或散列映射，是一种用于存储和检索数据的数据结构。它基于散列函数的原理，将键映射到值，从而实现快速的数据查找和插入操作。散列表在计算机科学中被广泛用于高效地管理大量数据。 为什么使用散列表 为了解决通过 O(1)时间复杂度直接索引到指定元素。 拉链寻址和开放寻址的区别 拉链寻址是把碰撞的元素存放到链表上。开放寻址是冲突的键值对被直接存储在散列表中，而不是存储在其他数据结构中。当冲突发生时，会寻找下一个可用的槽位，直到找到一个空槽或者散列表已满。常见的开放寻址方法包括线性探测、二次探测和双重散列等。 还有其他什么方式可以解决散列哈希索引冲突 合并散列、跳房子散列、罗宾汉散列、杜鹃散列 对应的Java源码中，对于哈希索引冲突提供了什么样的解决方案 java源码哈希索引冲突是通过拉链寻址解决的。 堆1.堆的简介堆(heap) 的实现是一种基于树的特殊的数据结构，它可以在数组上构建出树的结构体，并满足堆的属性。常见的堆有二叉堆、最大堆、最小堆、斐波那契堆等等。 最小堆： 父节点的值始终小于子节点的值，则称之为最小堆。 最大堆： 父节点的值始终大于子节点的值，则称之为最大堆。 2.堆的代码实现堆的实现在 Java API 中主要体现在延迟队列的实现二叉堆上，这里单独把这部分代码拆分出来，了解下关于小堆和大堆的实现。 从对堆的数据结构介绍上可以看到，小堆和大堆的唯一区别仅是对元素的排序方式不同。所以也就是说在存放和获取元素的时候对元素的填充和摘除时，排序方式不同而已。 2.1入堆方法1234567891011121314151617181920private void siftUpComparable(int k, E x) { logger.info(&quot;【入队】元素：{} 当前队列：{}&quot;, JSON.toJSONString(x), JSON.toJSONString(queue)); while (k &gt; 0) { // 获取父节点Idx，相当于除以2 int parent = (k - 1) &gt;&gt;&gt; 1; logger.info(&quot;【入队】寻找当前节点的父节点位置。k：{} parent：{}&quot;, k, parent); Object e = queue[parent]; // 如果当前位置元素，大于父节点元素，则退出循环 if (compareTo(x, (E) e) &gt;= 0) { logger.info(&quot;【入队】值比对，父节点：{} 目标节点：{}&quot;, JSON.toJSONString(e), JSON.toJSONString(x)); break; } // 相反父节点位置大于当前位置元素，则进行替换 logger.info(&quot;【入队】替换过程，父子节点位置替换，继续循环。父节点值：{} 存放到位置：{}&quot;, JSON.toJSONString(e), k); queue[k] = e; k = parent; } queue[k] = x; logger.info(&quot;【入队】完成 Idx：{} Val：{} \\r\\n当前队列：{} \\r\\n&quot;, k, JSON.toJSONString(x), JSON.toJSONString(queue));} 以入堆 2 作为例子来看。 首先将元素2挂到队列尾部，之后通过 (k - 1) &gt;&gt;&gt; 1 计算父节点位置，与对应元素进行比对和判断交换。 交换过程包括 2-&gt;6、2-&gt;5，以此交换结束后元素保存完毕。 2.2出堆方法1234567891011121314151617181920212223242526private void siftDownComparable(int k, E x) { // 先找出中间件节点 int half = size &gt;&gt;&gt; 1; while (k &lt; half) { // 找到左子节点和右子节点，两个节点进行比较，找出最大的值 int child = (k &lt;&lt; 1) + 1; Object c = queue[child]; int right = child + 1; // 左子节点与右子节点比较，取最小的节点 if (right &lt; size &amp;&amp; compareTo((E) c, (E) queue[right]) &gt; 0) { logger.info(&quot;【出队】左右子节点比对，获取最小值。left：{} right：{}&quot;, JSON.toJSONString(c), JSON.toJSONString(queue[right])); c = queue[child = right]; } // 目标值与c比较，当目标值小于c值，退出循环。说明此时目标值所在位置适合，迁移完成。 if (compareTo(x, (E) c) &lt;= 0) { break; } // 目标值小于c值，位置替换，继续比较 logger.info(&quot;【出队】替换过程，节点的值比对。上节点：{} 下节点：{} 位置替换&quot;, JSON.toJSONString(queue[k]), JSON.toJSONString(c)); queue[k] = c; k = child; } // 把目标值放到对应位置 logger.info(&quot;【出队】替换结果，最终更换位置。Idx：{} Val：{}&quot;, k, JSON.toJSONString(x)); queue[k] = x;} 出堆只要将根节点直接删除弹出即可，但是重要的是出堆之后其他节点的排序 这里以弹出元素1举例，之后将堆尾元素替换到相应的位置。整个过程分为6张图表述。 图1到图2，找出根元素弹出。 图3到图4，将根元素向下迁移，与子元素比对，并替换位置。如果这个位置与8相比，小于8则继续向下迁移。 图4到图5，继续迁移，在原节点4的位置对应的两个子元素，都比8大，这个时候就可以停下来了。 图5到图6，更换元素位置，把队尾的元素替换到对应元素1向下迁移检测的位置。 2.3小堆的实现123456public class MinHeap extends Heap&lt;Integer&gt; { @Override public int compareTo(Integer firstElement, Integer secondElement) { return firstElement.compareTo(secondElement); }} 使用正序比，也就是 first &gt; second 则返回true 2.4大堆的实现123456public class MaxHeap extends Heap&lt;Integer&gt; { @Override public int compareTo(Integer firstElement, Integer secondElement) { return secondElement.compareTo(firstElement); }} 使用反序比，也就是 first &lt; second 则返回true 3.常见面试题 堆的数据结构是什么样？ 堆(heap) 的实现是一种基于树的特殊的数据结构，它可以在数组上构建出树的结构体，并满足堆的属性。 堆的数据结构使用场景？ 优先级队列、堆排序、动态中位数查找、最大最小堆 堆的数据结构实现方式有哪些？ 最大堆和最小堆 最小堆和最大堆的区别是什么？ 最大堆的父节点的值大于子节点；最小堆子节点的值大于父节点。 有了解斐波那契堆吗？ 斐波那契堆(Fibonacci heap)是计算机科学中最小堆有序树的集合。它和二项式堆有类似的性质，但比二项式堆有更好的均摊时间。堆的名字来源于斐波那契数，它常用于分析运行时间。 有关的内容可以见斐波那契堆(Fibonacci heap)原理详解 字典树1.字典树的简介在计算机科学中，字典树(Trie)也被称为”单词查找树“或”数字树“，有时候也被称为基数树或前缀树（因为可以通过前缀的方式进行索引）。—— 它是一种搜索树，一种已排序的数据结构，通常用于存储动态集或键为字符串的关联数组。 与二叉查找树不同，键不是直接保存在节点中，而是由节点在树中的位置决定。一个节点的所有子孙都有相同的前缀，也就是这个节点对应的字符串，而根节点对应空字符串。一般情况下，不是所有的节点都有对应的值，只有叶子节点和部分内部节点所对应的键才有相关的值。 这是一个把 battle 单词字符串，按照字母拆分到字典树进行存放的图。 2.字典树的实现树枝节点： 123456789101112131415161718192021public class TrieNode { /** 形成一个链 */ public TrieNode[] slot = new TrieNode[26]; /** 字母 */ public char c; /** 单词：数量 &gt; 0 表示一个单词 */ public boolean isWord; /** 前缀 */ public int prefix; /** 单词：具体的一个单词字符串 */ public String word; /** 解释：单词的注释说明 */ public String explain;} 由于有26个英文字母，因此使用数组大小设置为26 插入单词： 123456789101112131415public void insert(String words, String explain) { TrieNode root = wordsTree; char[] chars = words.toCharArray(); for (char c : chars) { int idx = c - 'a'; // - a 从 0 开始，参考 ASCII 码表 if (root.slot[idx] == null) { root.slot[idx] = new TrieNode(); } root = root.slot[idx]; root.c = c; root.prefix++; } root.explain = explain; // 单词的注释说明信息 root.isWord = true; // 循环拆解单词后标记} insert 方法接收单词和注释信息，并对一个单词按照 char 进行拆分，拆分后则计算出索引位置并以此存放。存放完成后标记单词和附属上单词的注释信息。 前缀查找： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public List&lt;String&gt; searchPrefix(String prefix) { TrieNode root = wordsTree; char[] chars = prefix.toCharArray(); StringBuilder cache = new StringBuilder(); // 精准匹配：根据前置精准查找 for (char c : chars) { int idx = c - 'a'; // 匹配为空 if (idx &gt; root.slot.length || idx &lt; 0 || root.slot[idx] == null) { return Collections.emptyList(); } cache.append(c); root = root.slot[idx]; } // 模糊匹配：根据前缀的最后一个单词，递归遍历所有的单词 ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(); if (root.prefix != 0) { for (int i = 0; i &lt; root.slot.length; i++) { if (root.slot[i] != null) { char c = (char) (i + 'a'); collect(root.slot[i], String.valueOf(cache) + c, list, 15); if (list.size() &gt;= 15) { return list; } } } } return list;}protected void collect(TrieNode trieNode, String pre, List&lt;String&gt; queue, int resultLimit) { // 找到单词 if (trieNode.isWord) { trieNode.word = pre; // 保存检索到的单词到 queue queue.add(trieNode.word + &quot; -&gt; &quot; + trieNode.explain); if (queue.size() &gt;= resultLimit) { return; } } // 递归调用，查找单词 for (int i = 0; i &lt; trieNode.slot.length; i++) { char c = (char) ('a' + i); if (trieNode.slot[i] != null) { collect(trieNode.slot[i], pre + c, queue, resultLimit); } }} 从字典树从检索元素的过程分为2部分，第1部分是根据提供的索引前缀精准匹配到单词信息，第2部分是根据索引前缀的最后一个单词开始，循环递归遍历从当前位置所能关联到的字母直至判断为是单词标记为结束，通过这样的方式把所有匹配动的单词索引出来。 list.size() &gt;= 15 是判定索引的最大长度，超过这个数量就停止索引了，毕竟这是一种O(n)时间复杂度的操作，如果加载数十万单词进行匹配，执行速度还是比较耗时的。 3.常见面试题 简述字典树的数据结构 字典树的每一个节点代表一个字符，从根节点到叶子节点的路径表示一个字符串。字典树的树节点包含一个节点数组，假设字典树存储的是单词，那么节点数组的长度为26。 叙述你怎么来实现一个字典树 定义一个节点。节点信息包括节点数组，节点数组的长度由保存的数据决定。如果是保存英文单词，则数组长度为26。同时节点信息还要设置一个标识符，用来判断是否结束。例如如果保存的是字符串，则根据标识符可以知道，读取到当前字符的路径所形成的字符串是否是一个保存进字典树的字符串 定义字典树结构，实例化根节点 定义插入方法：假设保存的是字符串，则循环处理进行保存。如果当前字符对应的位置为空，则创建一个新节点；并且将指针移动到相应位置处的节点上，处理下一个节点；当所有字符全部处理完毕，则插入成功 定义查询方法。查询方法分为两步 精确匹配。根据给出的前缀字符串按序循环判断 模糊匹配，根据索引前缀的最后一个单词开始，循环递归遍历从当前位置所能关联到的字母直到判断为是单词标记结束，从而将所有符合前缀的单词全部索引出来 字典树的实际业务场景举例【排序、全文搜索、网络搜索引擎、生物信息】 自动补全和搜索提示：通过构建包含所有可能搜索关键字的字典树，可以在用户输入搜索关键字时，快速找到所有具有相同前缀的字符串，并将其作为搜索建议显示给用户 单词拼写检查器：通过在字典树中搜索用户输入的单词，可以检查其是否正确拼写，或者找到可能的正确拼写建议 字符串匹配：在文本搜索和字符串匹配算法中，字典树可以用于高效地找到给定模式串在目标文本中的所有出现位置 词频统计：通过在字典树中插入所有单词，并记录每个单词的出现次数，可以高效地实现词频统计 电话号码前缀匹配：在电话通讯系统中，字典树可以用于快速匹配用户拨打的电话号码前缀，以确定应该转接到哪个地区或服务中心 编译器符号表：在编译器和解释器中，字典树可以用于实现符号表，记录程序中定义的变量、函数等符号及其对应的作用域和类型信息 字典树的存入和检索的时间复杂度 O(n) 还有哪些字典树的实现方式【后缀树 (opens new window)、哈希树 (opens new window)、帽子树 (opens new window)】 后缀树：后缀树是一种特殊的字典树，用于高效地存储一个字符串的所有后缀。后缀树在字符串处理和模式匹配等领域中非常有用，可以在线性时间内构建 哈希树：也称为哈希字典或哈希字典树，是一种结合了哈希表和字典树的数据结构。哈希树的基本思想是将字符串按照字符顺序进行哈希，然后构建一个树结构来存储这些哈希值。每个节点都对应一个哈希值，通过从根节点到叶子节点的路径表示一个字符串。在哈希树中，哈希值相同的字符串会落在同一个分支上，因此具有相同前缀的字符串在哈希树中具有相似的结构。 哈希树的节点查找过程和节点插入过程类似，就是对关键字用质数序列取余，根据余数确定下一节点的分叉路径，直到找到目标节点。如图，最小”哈希树(HashTree)在从4G个对象中找出所匹配的对象，比较次数不超过10次。也就是说：最多属于O(10)。在实际应用中，调整了质数的范围，使得比较次数一般不超过5次。也就是说：最多属于O(5)。因此可以根据自身需要在时间和空间上寻求一个平衡点。 哈希表每层存储数据数量按照质数依次增加，一般都是从2开始，即第一层的结点有2个子节点，第二层结点每个节点都有3个子节点，第三层每个节点有5个子节点，第四层结点每个节点都有7个子节点第五层每个节点有11个子节点，第六层结点每个节点都有13个子节点第七层每个节点有17子节点 二分搜索树1.二分搜索树的简介二叉搜索树（Binary Search Tree），也称二叉查找树。有序二叉树（Ordered Binary tree）、排序二叉树（Sorted Binary Tree）都是二叉搜索树。 二叉搜索树的特点： 若任意节点的左子树不空，则左子树上所有节点的值均小于它的根节点的值； 若任意节点的右子树不空，则右子树上所有节点的值均大于它的根节点的值； 任意节点的左、右子树也分别为二叉查找树； 二叉搜索树的缺点： 二叉搜索树也是一颗没有经过调衡的基础性数据结构，在一定概率上它完成有可能退化成链表，也就是从近似O(logn)的时间复杂度退化到O(n)。关于二叉搜索树的平衡解决方案，包括；AVL树、2-3树、红黑树等。 2.二叉搜索树的实现二叉搜索树是整个树结构中最基本的树，同时也是树这个体系中实现起来最容易的数据结构。但之所以要使用基于二叉搜索树之上的其他树结构，主要是因为使用数据结构就是对数据的存放和读取。那么为了提高吞吐效率，则需要尽可能的平衡元素的排序，体现在树上则需要进行一些列操作，所以会有不同的结构树实现。 定义树枝： 12345public Integer value;public Node parent;public Node left;public Node right; AVL 树需要定义树高，红黑树需要定义节点颜色 插入元素： 1234567891011121314151617181920212223242526272829public Node insert(int e) { if (null == root) { root = new Node(e, null, null, null); size++; return root; } // 索引出待插入元素位置，也就是插入到哪个父元素下 Node parent = root; Node search = root; while (search != null &amp;&amp; search.value != null) { parent = search; if (e &lt; search.value) { search = search.left; } else { search = search.right; } } // 插入元素 Node newNode = new Node(e, parent, null, null); if (parent.value &gt; newNode.value) { parent.left = newNode; } else { parent.right = newNode; } size++; return newNode;} 首先判断插入元素时候是否有树根，没有则会把当前节点创建出一颗树根来。 如果当前树是有树根的，则对插入元素与当前树进行一个节点遍历操作，找到元素可以插入的索引位置 parent（挂到这个父节点下）。也就是 search 搜索过程。 最后就是插入元素，通过给插入值创建一个 Node 节点，并绑定它的父元素，以及把新元素挂到索引到的 parent 节点下。 查找索引节点： 1234567891011public Node search(int e) { Node node = root; while (node != null &amp;&amp; node.value != null &amp;&amp; node.value != e) { if (e &lt; node.value) { node = node.left; } else { node = node.right; } } return node;} 删除节点 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public Node delete(int e) { Node delNode = search(e); if (null == delNode) return null; return delete(delNode);}private Node delete(Node delNode) { if (delNode == null) return null; Node result = null; if (delNode.left == null) { result = transplant(delNode, delNode.right); } else if (delNode.right == null) { result = transplant(delNode, delNode.left); } else { // 因为删除的节点，有2个孩子节点，这个时候找到这条分支下，最左侧做小的节点。用它来替换删除的节点 Node miniNode = getMiniNode(delNode.right); if (miniNode.parent != delNode) { // 交换位置，用miniNode右节点，替换miniNode transplant(miniNode, miniNode.right); // 把miniNode 提升父节点，设置右子树并进行挂链。替代待删节点 miniNode.right = delNode.right; miniNode.right.parent = miniNode; } // 交换位置，删除节点和miniNode 可打印测试观察；System.out.println(this); transplant(delNode, miniNode); // 把miniNode 提升到父节点，设置左子树并挂链 miniNode.left = delNode.left; miniNode.left.parent = miniNode; result = miniNode; } size--; return result;}private Node getMinimum(Node node) { while (node.left != null) { node = node.left; } return node;}private Node transplant(Node delNode, Node addNode) { if (delNode.parent == null) { this.root = addNode; } // 判断删除元素是左/右节点 else if (delNode.parent.left == delNode) { delNode.parent.left = addNode; } else { delNode.parent.right = addNode; } // 设置父节点 if (null != addNode) { addNode.parent = delNode.parent; } return addNode;} 分步骤解析删除节点操作： 123456private Node getMinimum(Node node) { while (node.left != null) { node = node.left; } return node;} 寻找以 node 为根节点的子树中的最小节点 12345678910111213141516private Node transplant(Node delNode, Node addNode) { if (delNode.parent == null) { this.root = addNode; } // 判断删除元素是左/右节点 else if (delNode.parent.left == delNode) { delNode.parent.left = addNode; } else { delNode.parent.right = addNode; } // 设置父节点 if (null != addNode) { addNode.parent = delNode.parent; } return addNode;} 将要删除的节点 delNode 替换为 addNode 1234567891011121314151617181920212223242526272829private Node delete(Node delNode) { if (delNode == null) return null; Node result = null; if (delNode.left == null) { // 如果删除节点的左节点为空，则将右节点赋给删除节点 result = transplant(delNode, delNode.right); } else if (delNode.right == null) { // 如果删除节点的右节点为空，则将左节点赋给删除节点 result = transplant(delNode, delNode.left); } else { // 因为删除的节点，有2个孩子节点，这个时候找到这条分支下，最左侧做小的节点。用它来替换删除的节点 Node miniNode = getMiniNode(delNode.right); if (miniNode.parent != delNode) { // 交换位置，用miniNode右节点，替换miniNode transplant(miniNode, miniNode.right); // 把miniNode 提升父节点，设置右子树并进行挂链。替代待删节点 miniNode.right = delNode.right; miniNode.right.parent = miniNode; } // 交换位置，删除节点和miniNode 可打印测试观察；System.out.println(this); transplant(delNode, miniNode); // 把miniNode 提升到父节点，设置左子树并挂链 miniNode.left = delNode.left; miniNode.left.parent = miniNode; result = miniNode; } size--; return result;} 举例： 待删除节点64，含有双子节点，则需要根据第一个右子节点查找最小左子节点。从89到72，如果有比72还小的左子节点，继续排查。 排查到节点72，将72这个准备替换待删元素的节点，与右子节点73进行位置交换，过程与 4.1 相同。使用交换函数 transplant 最后是进行节点72与待删节点64的交换过程，更换三角关系，父节点、左子节点、右子节点。 3.常见面试题 二叉搜索树结构简述&amp;变T的可能也让手写 若任意节点的左子树不为空，则左子树的所有元素的值均小于这个节点 若任意节点的右子树不为空，则右子树的所有元素的值均大于这个节点 任意节点的左子树和右子树都是二叉搜索树 二叉搜索树的插入、删除、索引的时间复杂度 在二叉搜索树平衡的情况下，插入、删除、索引的时间复杂度均为 O(logn)。如果二叉搜索树平衡性较差，那么二叉搜索树退化成链表，则插入、删除、索引的时间复杂度均为 O(n) 二叉搜索树删除含有双子节点的元素过程叙述 二叉搜索树的节点都包括了哪些信息 值、左节点、右节点 为什么Java HashMap 中说过红黑树而不使用二叉搜索树 Java中的HashMap在哈希冲突处理的过程中，从JDK 8 开始引入了红黑树（Red-Black Tree）作为一种优化，来替代之前的链表。这是因为在某些情况下，链表的性能可能不够理想，而红黑树可以提供更好的性能。 红黑树是一种自平衡二叉搜索树，具有以下特性： 平衡性：红黑树保持了树的高度较低，使得树的查找、插入和删除操作的时间复杂度保持在O(log n)。 插入和删除的高效性：红黑树的插入和删除操作的平均和最坏情况下都能保持在O(log n)的时间复杂度，这比一般的二叉搜索树要好。 操作的稳定性：红黑树的操作（插入、删除）不会导致树的结构失衡，这与一些其他自平衡树可能会需要频繁的重新平衡操作不同。 因此，红黑树在处理哈希冲突时，能够保持较好的性能，而链表可能在特定情况下会退化为很长，导致性能下降。Java中的HashMap使用了数组+链表（或红黑树）的方式来存储键值对，当哈希冲突较多时，将链表转换为红黑树，以保持性能的稳定和可预测性。 总之，红黑树在平衡性、插入和删除的高效性等方面相对于简单的二叉搜索树有明显的优势，所以在HashMap中采用了红黑树来处理哈希冲突。 AVL 树1.AVL 树的简介AVL 自平衡二叉树的出现，其目的在于解决二叉搜索树退化成链表的问题。当我们向BST二叉搜索树顺序存入1、2、3、4、5、6、7个元素时，它会退化成一条链表，因而失去树查询的时间复杂度，所以我们需要AVL树平衡树高。如图所示 AVL 树如何实现平衡操作？ 当二叉树的左右分支树高差不为 1 时，需要进行左旋或者右旋，来调衡树高。 AVL 实现平衡操作的四种情况： 节点树高：以节点4为说明，最长的左右分支节点个数，就是节点4的最大树高。这里节点4左右孩子节点最长路径都为2，所以它的树高为2。同理可计算其他节点树高。 平衡因子：通过当前节点的左右子节点作差计算平衡因子，之后AVL树通过平衡因子，定义了什么时候进行左旋和右旋。 2.AVL 树的实现要实现 AVL 树，首先要实现的核心逻辑是 AVL 树的自平衡，也就是使用左旋和右旋的方法来实现。 左旋： 适用于：平衡的节点位于父节点的右树枝，并且平衡节点的左子树为空。 注意：当建立关系的时候，是双向的。既需要设置父节点的左右节点，也需要设置子节点的父节点。 123456789101112131415161718192021222324protected Node rotateLeft(Node node) { Node temp = node.right; temp.parent = node.parent; node.right = temp.left; if (node.right != null) { node.right.parent = node; } temp.left = node; node.parent = temp; if (temp.parent == null) { root = temp; } else { if (temp.parent.left == node) { temp.parent.left = temp; } else { temp.parent.right = temp; } } return temp;} 过程分为四步：要平衡的节点的右节点设置为 temp，要平衡的节点设置为 node 与父节点建立关系：将 temp 的父节点设置为 node 的父节点 交付子节点：将 temp.left 托付给 node.right 角色交换：将 node 节点的父节点设置为 temp 承认关系：父节点的子节点指向 temp 右旋： 适用于：平衡的节点位于父节点的左树枝，并且平衡节点的右子树为空。 1234567891011121314151617181920protected Node rotateRight(Node node) { Node temp = node.left; temp.parent = node.parent; node.left = temp.right; if (node.left != null) { node.left.parent = node; } temp.right = node; node.parent = temp; if (temp.parent == null) { root = temp; } else { if (temp.parent.left == node) { temp.parent.left = temp; } else { temp.parent.right = temp; } } return temp;} 右旋操作与左旋类似 左旋+右旋： 适用于：平衡节点位于父节点的左子树，并且平衡节点的右子树高度大于左子树（这里叙述的是其中一种情况而已） 即 左旋+右旋 才能保证 AVL 树达到平衡状态 1234567891011121314151617181920if (factor(node.left) &gt;= 0) { // 平衡节点左子树的高度大于右子树 Node temp = super.rotateRight(node); refreshHeight(temp.right); refreshHeight(temp);} else { Node temp = super.rotateLeft(node.left); refreshHeight(temp.left); refreshHeight(temp); node.left = temp; temp = super.rotateRight(node); refreshHeight(temp.right); refreshHeight(temp);}private int factor(Node node) { int leftHeight = (node.left == null) ? -1 : (node.left).height; int rightHeight = (node.right == null) ? -1 : (node.right).height; return leftHeight - rightHeight;} 右旋+左旋： 适用于：平衡节点位于父节点的右子树，并且平衡节点的左子树高度大于右子树（这里叙述的是其中一种情况而已） 即右旋+左旋才能使得 AVL 树达到平衡 1234567891011121314if (factor(node.right) &lt;= 0) { Node temp = super.rotateLeft(node); refreshHeight(temp.left); refreshHeight(temp);} else { Node temp = super.rotateRight(node.right); refreshHeight(temp.right); refreshHeight(temp); node.right = temp; temp = super.rotateLeft(node); refreshHeight(temp.left); refreshHeight(temp);} 3.AVL 树常见面试题 AVL 树平衡因子怎么计算？ 右子树的高度-左子树的高度 在AVL树中，每个节点的平衡因子只能是-1、0、1 如果平衡因子为 -1，表示左子树高度大于右子树；如果平衡因子为 1，表示右子树高度大于左子树 AVL 树左旋操作的目的是什么？ 降低右子树的高度，从而达到平衡 AVL 树左旋操作的流程是什么？ 过程分为四步：要平衡的节点的右节点设置为 temp，要平衡的节点设置为 node 与父节点建立关系：将 temp 的父节点设置为 node 的父节点 交付子节点：将 temp.left 托付给 node.right 角色交换：将 node 节点的父节点设置为 temp 承认关系：父节点的子节点指向 temp AVL 树什么情况下要左旋+右旋？ 单次左旋和右旋无法满足平衡条件。适用的情况有平衡节点位于父节点的右子树，并且平衡节点的左子树高度大于右子树；平衡节点位于父节点的左子树，并且平衡节点的右子树高度大于左子树 AVL 树的插入和读取的时间复杂度？ 均为 O(logn) 2-3 树1.2-3树的简介2-3树是一种树形数据结构，他通过一个节点存放 1-2 个元素来实现树的平衡。因此 2-3 树分为 2 叉和 3 叉。 在 BST 二叉搜索树可能退化成链表的基础上。引出了自平衡二叉树，包括 AVL 树和 Java API HashMap 中用到的红黑树，它们都属于 BalancedTree，统称为B树。 2-3 树中每个具有子节点（内部节点）的节点要么有两个子节点（2 节点）和一个数据元素（对应于2叉），要么有三个子节点（3 节点）和两个数据元素（3叉）。 举例来看2-3树的插入过程 2-3 树的插入过程与 BST 树类似，会通过树的左右节点大小，找到自己的插入位置。 一个节点可以右 1-3 个元素，但当元素个数为 3 时，则需要调衡。把三个节点的中间节点晋升上来，其余两个节点为子节点。 如果进行一次调衡后，上一层父节点达到 3 个元素，则需要 2 次调衡，来满足2-3树的规则。 2.2-3树的实现节点定义： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788/** * 2-3树节点 */ static class Node_2_3 { // 定义当前节点包含的元素 public int[] items; // 序号 public int number; // 定义当前节点的子节点 public Node_2_3[] children; // 定义当前节点的父节点 public Node_2_3 parent; /** 第一种初始化方法 元素个数初始化为3 序号值初始化为0 父节点初始化为null */ public Node_2_3() { this.items = new int[3]; this.number = 0; this.children = new Node_2_3[4]; this.parent = null; } /** 第二种初始化方法： 元素第一个值初始化为item 序号值初始化为 1 */ public Node_2_3(int item) { this(); this.items[0] = item; this.number = 1; } /** 第三种初始化方法： 当前元素的第一个子节点初始化为输入的 child 值 */ public Node_2_3(Node_2_3 child){ this(); this.children[0] = child; } // number初始化为0，表示当前节点中有几个数字，当插入一个数字的时候，需要对比查找当前数字应当插在哪个数字右边 public void insert(int e) { int idx = this.number - 1; while (idx &gt;= 0) { if (this.items[idx] &lt; e) break; this.items[idx + 1] = this.items[idx]; --idx; } this.items[idx + 1] = e; ++this.number; } // 判断当前节点是否没有子节点 public boolean isLeaf(){ return this.children[0] == null; } // 判断当前节点的最小值 public int getMinItem(){ return this.items[0]; } // 判断当前节点中间的值 public int getMiddleItem(){ return this.items[1]; } // 判断当前节点的最大值 public int getMaxItem(){ return this.items[2]; } // 获得子节点的最左边的值 public Node_2_3 getLeft() { return this.children[0]; } // 获得子节点中间的值 public Node_2_3 getMiddle() { return this.children[1]; } // 获得子节点的最右边的值 public Node_2_3 getRight() { return this.children[2]; } } 拆分节点操作： 12345678910111213141516171819202122232425/** * 拆分节点，中间节点上提，形成一个三角关系 * [1,2,3] * &lt;p&gt; * /---- 3 * 2 * \\---- 1 */private Node_2_3[] triangle(Node_2_3 node) { Node_2_3[] newNodes = new Node_2_3[2]; newNodes[0] = new Node_2_3(node.items[0]); newNodes[1] = new Node_2_3(node.items[2]); if (!node.isLeaf()) { // 左孩子 newNodes[0].children[0] = node.children[0]; newNodes[0].children[1] = node.children[1]; // 右孩子 newNodes[1].children[0] = node.children[2]; newNodes[1].children[1] = node.children[3]; } return newNodes;} 方法实现，并排的三个节点，将中间的节点提取作为父节点并且左右节点作为子节点 替换旧节点： 123456789101112131415private void replaceChild(Node_2_3 parent, Node_2_3 oldChild, Node_2_3 child01, Node_2_3 child02) { if (oldChild == parent.children[0]) { parent.children[3] = parent.children[2]; parent.children[2] = parent.children[1]; parent.children[1] = child02; parent.children[0] = child01; } else if (oldChild == parent.children[1]) { parent.children[3] = parent.children[2]; parent.children[2] = child02; parent.children[1] = child01; } else { parent.children[3] = child02; parent.children[2] = child01; } } 该操作将旧节点替换为新节点 如果要替换的是处于最左边的节点，那么需要将所有节点的位置都发生变化，以此类推 整体分割操作： 1234567891011private Node_2_3 split(Node_2_3 node, Node_2_3 parent) { if (parent == null) { parent = new Node_2_3(node); } parent.insert(node.getMiddleItem()); Node_2_3[] newNodes = this.triangle(node); this.replaceChild(parent, node, newNodes[0], newNodes[1]); return parent;} 首先判断父节点是否为空，如果为空，那么将创造一个父节点 如果不为空，将中间节点插入 然后通过 triangle() 方法将长度为 3 的节点进行拆分 最后通过 replaceChild() 操作将旧节点替换 插入操作： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public void insert(int e) { // 记录元素 elementList.add(e); // 插入元素 if (root == null) { root = new Node_2_3(e); } else { root = insert(e, root); if (root.number == 3) { root = split(root, null); } }}/** * 递归调用插入元素 */private Node_2_3 insert(int e, Node_2_3 parent) { if (parent.isLeaf()) { parent.insert(e); return parent; } Node_2_3 child = null; if (parent.number == 1) { if (e &lt; parent.getMinItem()) { child = insert(e, parent.getLeft()); } else { child = insert(e, parent.getMiddle()); } } else { if (e &lt; parent.getMinItem()) { child = insert(e, parent.getLeft()); } else if (e &gt; parent.getMiddleItem()) { child = insert(e, parent.getRight()); } else { child = insert(e, parent.getMiddle()); } } if (child.number == 3) { return this.split(child, parent); } return parent;} 调用递归插入元素，并且使得子节点的长度保持小于3 返回给 insert(int e) 方法，并且对 root 节点的长度进行判断，如果大于 3 则进行拆分 3.常见面试题 2-3树的数据结构描述 2-3树是一种树形数据结构，他通过一个节点存放 1-2 个元素来实现树的平衡。因此 2-3 树分为 2 叉和 3 叉。 2-3树一个节点最多可以存放几个元素 2 个 2-3树插入节点时间复杂度 log(n) 2-3树一个节点有3个元素，如何迁移。需要旋转吗 不需要旋转，迁移方法如下： 首先将 3 个元素中处于中间位置的元素提取到父节点的位置，并且将左右两个元素的父节点设置为该元素 如果父节点的元素个数也等于 3，此时再对父节点进行节点提取操作 2-3树，你能手写一下吗？ 红黑树1.红黑树的简介建立在 BST 二叉搜索树的基础上，AVL、2-3树、红黑树都是自平衡二叉树。但相比于AVL树，高度平衡所带来的时间复杂度，红黑树对平衡的控制要宽松一些，红黑树只需要保证黑色节点平衡即可。也正因红黑树在插入和删除时不需要太多的平衡操作，也让它成为；Java中HashMap的元素碰撞后的转换、Linux的CFS进行调度算法、多路复用技术的Epoll等各类底层的数据结构实现。 2.红黑树的性质 每个节点不是红色就是黑色。 黑色决定平衡，红色不决定平衡。这对应了2-3树中一个节点内可以存放1~2个节点。 根是黑色的。 这条规则有时会被省略。由于根总是可以从红色变为黑色，但不一定相反，因此该规则对分析几乎没有影响。 所有叶子 (NIL) 都是黑色的。（NIL 即空节点） 这里指的是红黑树都会有一个空的叶子节点，是红黑树自己的规则。 如果一个节点是红色的，那么它的两个子节点都是黑色的。 通常这条规则也叫不会有连续的红色节点。这体现在2-3树中，一个节点最多临时会有3个节点，中间是黑色节点，左右是红色节点。2-3树中出现这样的情况后，会进行节点迁移，中间节点成为父节点，左右节点成为子节点。 从给定节点到其任何后代 NIL 节点的每条路径都包含相同数量的黑色节点。 对应2-3树中，每一层都只是有一个节点贡献了树高决定平衡性，也就是对应红黑树中的黑色节点。 3.红黑树的实现3.1左倾染色即当前新增节点的父节点是爷爷节点的左节点 染色的步骤： 根据新增节点的父节点的父节点找到其叔叔节点 如果叔叔节点的颜色为红色，那么就将叔叔节点的颜色和父节点的颜色全部替换为黑色，并且将祖父节点替换为红色（如果祖父节点是根节点，则会进行判断改为黑色） 示例代码： 12345678Node uncle = grandParent.right;// 染色if (uncle.color == Node.Color.RED){ parent.color = Node.Color.BLACK; uncle.color = Node.Color.BLACK; grandParent.color = Node.Color.RED; current = grandParent;} 3.2右倾染色即当前节点的父节点是爷爷节点的右节点 染色的步骤： 根据新增节点的父节点的父节点找到其叔叔节点 如果叔叔节点的颜色为红色，那么就将叔叔节点的颜色和父节点的颜色全部替换为黑色，并且将祖父节点替换为红色（如果祖父节点是根节点，则会进行判断改为黑色） 示例代码： 12345678Node uncle = grandParent.left;// 染色if(uncle.color == Node.Color.RED){ parent.color = Node.Color.BLACK; uncle.color = Node.Color.BLACK; grandParent.color = Node.Color.RED; current= grandParent;} 3.3左旋调衡一次左旋 对照2-3树，只有当一个节点内有3个节点的时候，才需要调衡。那么红黑树则是判断当前节点的叔叔节点是否为红色节点，如果不是则没法通过染色调衡，也就是需要选择进行调衡。 123parent.color = Node.Color.BLACK;grandParent.color = Node.Color.RED;super.rotateLeft(grandParent); 当你把红黑树对照理解成2-3树，如图中第1步骤下的左侧小图，新增的节点5倒置2-3树不平衡。 那么这个时候需要把2-3树中节点4提起来，而对应红黑树则需要先进行染色，待操作的节点4为黑色，两个孩子节点为红色。 最后是把节点3进行一次左旋操作，完成树的平衡。对应步骤3中的左侧小图是2-3树调衡后的结果。 右旋+左旋 123456789// 偏左↙，先右旋一次调衡if (current == parent.left){ current = parent; super.rotateRight(current); parent = current.parent;}parent.color = Node.Color.BLACK;grandParent.color = Node.Color.RED;super.rotateLeft(grandParent); 3.4右旋调衡一次右旋 对照2-3树，只有当一个节点内有3个节点的时候，才需要调衡。那么红黑树则是判断当前节点的叔叔节点是否为红色节点，如果不是则没法通过染色调衡，也就是需要选择进行调衡。 123parent.color = Node.Color.BLACK;grandParent.color = Node.Color.RED;super.rotateRight(grandParent); 当你把红黑树对照理解成2-3树，如图中第1步骤下的右侧小图，新增的节点1倒置2-3树不平衡。 那么这个时候需要把2-3树中节点2提起来，而对应红黑树则需要先进行染色，待操作的节点2为黑色，两个孩子节点为红色。 最后是把节点2进行一次右旋操作，完成树的平衡。对应步骤3中的右侧小图是2-3树调衡后的结果。 左旋+右旋 当一次左旋没法调衡，需要左旋+右旋的情况，在AVL树中有同样的场景。本身树需要右旋操作，但整体分支树节点偏右，此时需要左旋调整树结构再右旋。 123456789// 偏右↘，先左旋一次调衡if (current == parent.right){ current = parent; super.rotateLeft(current); parent = current.parent;}parent.color = Node.Color.BLACK;grandParent.color = Node.Color.RED;super.rotateRight(grandParent); 4.常见面试题 红黑树都有哪些使用场景？ 红黑树在插入和删除时不需要太多的平衡操作，也让它成为：Java中HashMap的元素碰撞后的转换、Linux的CFS进行调度算法、多路复用技术的Epoll等各类底层的数据结构实现。 相比于BST树，红黑树有什么用途？ 平衡性保证: 红黑树是一种自平衡二叉搜索树，它通过一系列的平衡性维护规则来确保树的高度始终保持在可控范围内。这样可以避免出现极端情况下的不平衡树，从而保持插入、删除和查找操作的高效性能。 平均复杂度保证: 红黑树的平均高度较低，这意味着它的插入、删除和查找操作的平均时间复杂度是 o(log n)。而在普通 BST中，最坏情况下，可能会出现链式结构，导致操作的平均复杂度变为 o(n)。有序性保证: 与普通 BST 类似，红黑树也可以保持元素的有序性，这对于需要进行范围查找或范围操作的场景非常有用。需要注意的是，红黑树的自平衡操作会导致相对较高的常数开销，因此在某些情况下，对于小规模数据集或静态数据集，普通的 BST 也可能更加合适然而，在大多数情况下，红黑树提供了在平衡性、插入和删除操作上更好的性能保证。 B-树是什么意思，都包括哪些？ B-树 (B-tree) 是一种用于实现高效的动态数据集合的自平衡树数据结构。它被广泛应用于数据库系统、文件系统以及其他需要支持高效插入、删除和查找操作的场景。B-树具有以下特点:有序性: 每个节点内的元素是有序的，这使得在节点内进行二分查找操作成为可能。平衡性: B-树通过一系列的自平衡操作来保持树的平衡性。每次插入或删除操作后，B-树会根据一定的规则进行调整，确保树的高度始终在可接受范围内，从而保持高效的插入、删除和查找操作。 适应磁盘存储: B-树的设计考虑了磁盘存储的特点，适用于需要大量磁盘读写操作的场景。它通过每个节点存诸多个元素，减少了磁盘访问次数，提高了性能。分裂和合并操作: 当节点的元素数量达到一定闻值时，B-树会进行分裂操作，将节点分成两个。当节点的元素数量过少时，B-树会进行合并操作，将相邻的节点合并为一个。这些操作有助于保持树的平衡性。 适用于范围查询: B-树支持范围查询，因为每个节点内的元素是有序的，可以在节点内进行二分查找。常见变种: B-树有多个变种，如B+树、B*树等，它们在原始的B-树基础上做了一些改进，以适应不同的应用场景和优化性能。总之，B-树是一种用于实现高效的动态数据集合的数据结构，特别适用于需要大量插入、删除和查找操作的场景，如数据库系统和文件系统。 新增加一个节点后，什么情况下需要染色、什么情况要左旋、什么情况要左旋+右旋？ 普通染色：当新增节点的父节点（即新增节点为根节点）为空，直接染色为黑或者新增节点的父节点为黑色的时候，染红色 左倾染色：当新增节点的父节点（parent）位于爷爷节点的左子树并且叔叔节点（uncle）为红色，则进行左倾染色 右倾染色：当新增节点的父节点（parent）位于爷爷节点的右子树并且叔叔节点（uncle）为红色，则进行右倾染色 左旋调衡： 一次左旋：当新增节点导致树发生失衡，并且新增节点位于父节点的右子树，新增节点的父节点位于爷爷节点的右子树，并且为红色节点 右旋+左旋：当新增节点导致树发生失衡，并且新增节点位于父节点的左子树，新增节点的父节点位于爷爷节点的右子树，并且为红色节点。单次调衡无法满足平衡条件 右旋调衡： 一次右旋：当新增节点导致树发生失衡，并且新增节点位于父节点的左子树，新增节点的父节点位于爷爷节点的左子树，并且为红色节点 左旋+右旋：当新增节点导致树发生失衡，并且新增节点位于父节点的右子树，新增节点的父节点位于爷爷节点的左子树，并且为红色节点。单次调衡无法满足平衡条件 红黑树的特点是什么？ 每个节点一定是红色或者黑色 红色节点的子节点一定是黑色 根节点一定是黑色 从任意节点到其叶子结点路径上的黑色节点数目相同 所有叶子结点是黑色的（NIL） 并查集1.并查集的简介并查集数据结构（也称为联合-查找数据结构或合并-查找集）基于数组实现的一种跟踪元素的数据结构，这些元素被划分为多个不相交（非重叠）的子集。 并查集的优点以及应用场景： 并查集提供了近乎恒定的时间操作（以逆阿克曼函数为界）来添加新集合、合并现有集合以及确定元素是否在同一个集合中。 适用于：推荐算法、好友关系链、族谱等，并且并查集在 Kruskal 算法中扮演着关键角色，用于寻找无向边加权图的最小生成树。 2.并查集合并的几种方式： 并查集的实体类 12345678public class DisjointSet { // 元素 public int[] items; // 数量【可选】 public int[] count; // 排序【可选】 public int[] rank;} 2.1默认合并（合并(1,8)） 123456789101112131415161718@Overridepublic int find(int i) { if (i &lt; 0 || i &gt;= items.length) throw new IllegalArgumentException(&quot;Index out of range.&quot;); return items[i];}@Overridepublic void union(int parent, int child) { int parentVal = find(parent); int childVal = find(child); if (parentVal == childVal) return; for (int i = 0; i &lt; items.length; i ++){ // 所有值等于原孩子节点对应值的都替换为新的父节点值 if (items[i] == childVal){ items[i] = parentVal; } }} 目标：union(1, 8) 将8的根节点合并到1的根节点 union 是合并元素的方法，两个入参意思是把 child 指向的根节点，指向 parent 指向的根节点。后面所有案例中 union 方法属性字段意思相同。 find 找到元素对应的根节点值，之后使用 union 方法对 items 数组内的元素全部遍历，把所有值等于 child 的节点，都替换为 parent 节点值。 每次合并都for循环比较耗时，所以后续做了一些列的优化。 2.2粗暴合并（合并(1,8)） 123456789101112131415161718192021@Overridepublic int find(int i) { if (i &lt; 0 || i &gt;= items.length) throw new IllegalArgumentException(&quot;Index out of range.&quot;); // 找到元素的根节点，当i == item[i]，就是自己指向自己，这个节点就是根节点 while (i != items[i]) { i = items[i]; } return i;}@Overridepublic void union(int parent, int child) { // 父亲节点的根节点下标值 int parentRootIdx = find(parent); // 孩子节点的根节点下标值 int childRootIdx = find(child); if (parentRootIdx == childRootIdx) return; // 孩子节点值替换为父节点值 items[childRootIdx] = items[parentRootIdx];} 目标：union(1, 8) 将8的根节点合并到1的根节点 find 循环找到置顶节点的最终根节点，例如；8 → 6、6 → 6，那么说明8的根节点是6，因为6自己指向自己了，它就是根节点。 union 将 8 指向的根节点 6，更换为 1 指向的根节点 0。最终替换完就是 6 → 0，那么8的根节点有也是0了。 这样虽然减少了每次 for 循环更新，但粗暴的合并会对节点的索引带来一定的复杂度。所以还需要继续优化。 2.3数量合并（合并(1,8)） 1234567891011121314151617181920212223242526@Overridepublic int find(int i) { if (i &lt; 0 || i &gt;= items.length) throw new IllegalArgumentException(&quot;Index out of range.&quot;); // 找到元素的根节点，当i == item[i]，就是自己指向自己，这个节点就是根节点 while (i != items[i]) { i = items[i]; } return i;}@Overridepublic void union(int parent, int child) { // 父亲节点的根节点下标值 int parentRootIdx = find(parent); // 孩子节点的根节点下标值 int childRootIdx = find(child); if (parentRootIdx == childRootIdx) return; if (count[parentRootIdx] &gt;= count[childRootIdx]) { items[childRootIdx] = items[parentRootIdx]; count[parentRootIdx] += count[childRootIdx]; } else { items[parentRootIdx] = items[childRootIdx]; count[childRootIdx] += count[parentRootIdx]; }} 目标：union(1, 8) 将8的根节点合并到1的根节点 &amp; 基于节点的 count 值合并 find 循环找到置顶节点的最终根节点，例如；8 → 6、6 → 6，那么说明8的根节点是6，因为6自己指向自己了，它就是根节点。 union 在进行元素的根节点合并时，会判断哪个根下的元素少，用少的元素合并到多的元素下。因为这样可以减少多的元素因为处于更低位置所带来的索引耗时。树越深，子叶节点越多，越耗时。 2.4排序合并（合并(1,8)） 12345678910111213141516171819202122232425262728@Overridepublic int find(int i) { if (i &lt; 0 || i &gt;= items.length) throw new IllegalArgumentException(&quot;Index out of range.&quot;); // 找到元素的根节点，当i == item[i]，就是自己指向自己，这个节点就是根节点 while (i != items[i]) { i = items[i]; } return i;}@Overridepublic void union(int parent, int child) { // 父亲节点的根节点下标值 int parentRootIdx = find(parent); // 孩子节点的根节点下标值 int childRootIdx = find(child); if (parentRootIdx == childRootIdx) return; if (rank[parentRootIdx] &gt; rank[childRootIdx]) { items[childRootIdx] = items[parentRootIdx]; } else if (rank[parentRootIdx] &lt; rank[childRootIdx]) { items[parentRootIdx] = items[childRootIdx]; } else { items[childRootIdx] = items[parentRootIdx]; rank[parentRootIdx]++; }} 目标：union(8, 1) 将1的根节点合并到8的根节点（其实效果和union(1,8)是一样的，之所以用union(8, 1)主要体现基于 rank 排序后的合并）&amp; 基于节点的 rank 值合并 find 循环找到置顶节点的最终根节点，例如；8 → 6、6 → 6，那么说明8的根节点是6，因为6自己指向自己了，它就是根节点。 union 在进行元素的根节点合并时，会判断哪个根的排序小，用少的元素合并到大的根元素下。因为这样可以减少树深大的元素因为处于更低位置所带来的索引耗时。树越深，子叶节点越多，越耗时。 那么此时基于 count、rank 都可以进行优化，不过优化过程中 1→0、0→2 还有2个树高，也可以优化。这就是压缩路径的作用 2.5压缩合并（合并(1,8)） 1234567891011121314151617181920212223242526272829@Overridepublic int find(int i) { if (i &lt; 0 || i &gt;= items.length) throw new IllegalArgumentException(&quot;Index out of range.&quot;); while (i != items[i]) { // 路径压缩 items[i] = items[items[i]]; i = items[i]; } return i;}@Overridepublic void union(int parent, int child) { // 父亲节点的根节点下标值 int parentRootIdx = find(parent); // 孩子节点的根节点下标值 int childRootIdx = find(child); if (parentRootIdx == childRootIdx) return; if (rank[parentRootIdx] &gt; rank[childRootIdx]) { items[childRootIdx] = items[parentRootIdx]; } else if (rank[parentRootIdx] &lt; rank[childRootIdx]) { items[parentRootIdx] = items[childRootIdx]; } else { items[childRootIdx] = items[parentRootIdx]; rank[parentRootIdx]++; }} 目标：union(8, 1) 在rank合并下，压缩路径长度。 这里的 union 方法与4. 排序合并相比并没有变化，变化的地方主要在 find 过程中压缩路径。 find 基于查找根元素时，对当前元素值对应的父节点值，替换给当前元素。减少一级路径，做到压缩路径的目的 3.常见面试题 并查集叙述？ 并查集数据结构是基于数组实现的一种跟踪元素的数据结构，这些元素被划分为多个不相交（非重叠）的子集。 并查集的使用场景？ 推荐算法、好友关系链、族谱等，并且并查集在 Kruskal 算法中扮演着关键角色，用于寻找无向边加权图的最小生成树。 并查集怎么合并元素？ 在并查集中，合并操作的目标是将两个元素所在的集合合并为一个集合。以下是并查集中合并元素的基本步骤： 找到代表元素： 对于每个元素，首先要找到它所在的集合的代表元素（也称为根节点）。 合并代表元素： 将一个元素的代表元素指向另一个元素的代表元素，从而将两个集合合并为一个集合。 并查集合并元素的优化策略？ 数量合并，排序合并，压缩路径 如何压缩路径？ 在执行查找操作时，除了找到元素的代表元素外，还可以将查找路径上的每个节点直接链接到根节点。这样，在之后的查找操作中，树的高度会减少，从而提高了查找操作的效率。 图1.图的简介图（Graph）结构是一种比树结构复杂的非线性的数据结构，图在实际生活中的例子非常多，比如；地铁线路网、微信好友关系链、计算机中的状态执行等，都可以抽象成图的结构。 图（Graph）是由顶点的有穷非空集合和顶点之间边的集合组成，通常表示为：G(V,E) = 【G表示图、V表示顶点个数、E表示边的个数】。图的数据结构是多对多关系，就像你的微信好友可能也是我的微信好友，且相互交叉对应。与之对应的是树，树是1对多关系，所以树也是一种特殊的没有闭环的图。 2.图的分类按照是否有方向和是否有权重，可以将图分成四种情况。 U/U U/W D/U D/W 无向图&amp;无权重 无向图&amp;有权重 有向图&amp;无权重 有向图&amp;有权重 顶点：图中的任意节点都算作顶点，图中任意两个顶点间都可能存在连接，如果没有顶点间没有连线则称为空图。 无向图：图中任意两个顶点间都没有指向，则称这样的图为无向图。 有向图：图中任意两个顶点间都有指向边，则称这样的图为有向图。 无权重：图中任意两个顶点间的连线，没有权重值，则无权重。 有权重：图中任意两个顶点间的连线，包含权重值，则有权重。 3.图的实现图的类实现 1234567891011// 图的顶点数protected int v;// 图的边个数protected int e;// 图的矩阵【数组】protected int[][] table;// 图的矩阵【链表】protected LinkedList&lt;Integer[]&gt;[] table;// 图的矩阵【红黑树】private TreeSet&lt;Integer&gt;[] table; 图的数据存放可以通过 int 数组、LinkedList 链表、红黑树来实现 3.1数组实现无向图&amp;无权重： 123456789101112// 图的顶点数protected int v;// 图的边个数protected int e;// 图的矩阵protected int[][] table;// 对称插入，无方向，无权重public void insert(int x, int y) { table[x][y] = 1; table[y][x] = 1;} 邻接矩阵通过数组存放元素，会有一些浪费空间，所有的空间都会填满。 在插入元素的时候，对称插入节点。例如：0→1、1→0，两个方向都插入元素。 有向图&amp;有权重 1234567891011// 图的顶点数protected int v;// 图的边个数protected int e;// 图的矩阵protected int[][] table;// 对称插入，无方向，无权重public void insert(int x, int y, int weight) { table[x][y] = weight;} 邻接矩阵通过数组存放元素，会有一些浪费空间，所有的空间都会填满。 在插入元素的时候，插入单向节点，节点值为权重值。例如：0→2，权重值是4。 3.2链表实现无向图&amp;无权重 123456789101112// 图的顶点数protected int v;// 图的边个数protected int e;// 图的矩阵protected LinkedList&lt;Integer[]&gt;[] table;// 对称插入，无方向，无权重public void insert(int x, int y) { table[x].add(new Integer[]{y}); table[y].add(new Integer[]{x});} 通过数组+链表的实现方式可以减少非必要的元素存储，更加节省空间。 其实插入元素的过程和数组类似，无向无权重直接对称插入元素即可。 有向图&amp;有权重 1234567891011// 图的顶点数protected int v;// 图的边个数protected int e;// 图的矩阵protected LinkedList&lt;Integer[]&gt;[] table;// 对称插入，有方向，有权重public void insert(int x, int y, int weight) { table[x].add(new Integer[]{y, weight});} 通过数组+链表的实现方式可以减少非必要的元素存储，更加节省空间。 其实插入元素的过程和数组类似，有方向有权重则只插入单个指向，并需要通过数组或者对象的方式记录权重值。 3.3红黑树实现图的最终实现是通过 TreeSet 红黑树的方式，这样即节省空间，又能提高元素的索引和遍历效率。 无向图 vs 有向图 无向图 有向图 对称插入：table[x].add(y); table[y].add(x); 单向插入：table[x].add(y); 广度遍历 vs 深度遍历 U/U U/U D/U D/U 深度遍历 广度遍历 深度遍历 广度遍历 深度遍历，不断地向下探测。广度遍历横行探测。 当有权重时候，则深度和广度会按照权重进行选择优先遍历的顺序。 12345678910111213141516171819202122232425262728public void bfs(int s) { Queue&lt;Integer&gt; queue = new LinkedList&lt;&gt;(); visited[s] = true; queue.add(s); while (!queue.isEmpty()) { int v = queue.remove(); order.add(v); for (int w : G.adj(v)) { if (!visited[w]) { queue.add(w); visited[w] = true; } } }}private void dfs(int v) { visited[v] = true; // 深度优先，前序遍历 pre.add(v); for (int w : graph.adj(v)) { if (!visited[w]) { dfs(w); } } // 深度优先，后序遍历 post.add(v);} 广度优先算法： 首先，一个队列 queue 被创建用于存储待访问的节点。 然后，起始节点 s 被标记为已访问，并加入到队列中。 进入 while 循环，只要队列不为空，就一直执行以下步骤： a. 移除队列头部的节点，将其作为当前要处理的节点。 b. 将当前节点添加到遍历顺序列表 order 中，以记录遍历的顺序。 c. 遍历当前节点的所有相邻节点（使用 G.adj(v) 获取当前节点的相邻节点列表）。 如果相邻节点尚未被访问过，将其加入队列并标记为已访问。 循环结束后，遍历顺序列表 order 中包含了按照广度优先遍历得到的节点访问顺序。 深度优先算法： 递归的深度优先遍历函数 dfs 接受一个节点编号 v 作为参数。 首先，将当前节点 v 标记为已访问，表示正在访问这个节点。 在前序遍历位置，将当前节点编号 v 添加到前序遍历顺序列表 pre 中，以记录前序遍历顺序。 进入一个 for 循环，遍历当前节点的所有相邻节点（使用 graph.adj(v) 获取当前节点的相邻节点列表）。 如果相邻节点尚未被访问过（即 visited[w] 为 false），则递归调用 dfs(w) 对相邻节点进行深度优先遍历。 在后序遍历位置，将当前节点编号 v 添加到后序遍历顺序列表 post 中，以记录后序遍历顺序。 4.常见面试题 图的使用场景是什么？ 地铁线路网、微信好友关系链、计算机中的状态执行等，都可以抽象成图的结构。 图有的分类？ 根据有无权重和有无方向可以分为四种，分别是：无权重无向图、无权重有向图、有权重无向图、有权重有向图。 图怎么存放权重值？ 邻接矩阵、邻接表、关联矩阵 图的广度遍历 从起始节点开始，将其入队列 对于当前队列中的节点，依次出队列并进行处理 遍历当前节点的所有未被访问的邻居节点，并且将其入队 重复步骤2和3知道队列为空 图的深度遍历 从起始节点开始，首先将其设置为已访问 之后遍历其相邻节点，如果节点未被访问过，则递归调用深度遍历 布隆过滤器1.布隆过滤器的简介布隆过滤器是一种节省空间的概率数据结构，包括一个很长的二进制向量和一些列随机映射函数。 布隆过滤器是一个基于数组和哈希函数散列元素的结构，很像 HashMap 的哈希桶。布隆过滤器可以用于检测一个元素是否在集合中。它的优点是空间效率和查询时间比一般算法要好很多，但也有一定概率的误判性。如HashMap出现哈希碰撞 布隆过滤器的优点： 时间复杂度低，增加和查询元素的时间复杂为O(N)，（N为哈希函数的个数，通常情况比较小） 保密性强，布隆过滤器不存储元素本身 存储空间小，如果允许存在一定的误判，布隆过滤器是非常节省空间的（相比其他数据结构如Set集合） 布隆过滤器的缺点： 有一定的误判率，但是可以通过调整参数来降低 无法获取元素本身 很难删除元素 2.布隆过滤器使用场景布隆过滤器可以告诉我们“某样东西一定不存在或者可能存在”，也就是说布隆过滤器说这个数不存在则一定不存，布隆过滤器说这个数存在可能不存在，利用这个判断是否存在的特点可以做很多事情。例如 解决Redis缓存穿透问题（面试重点） 邮件过滤，使用布隆过滤器来做邮件黑名单过滤 对爬虫网址进行过滤，爬过的不再爬 解决新闻推荐过的不再推荐(类似抖音刷过的往下滑动不再刷到) HBase\\RocksDB\\LevelDB等数据库内置布隆过滤器，用于判断数据是否存在，可以减少数据库的IO请求 3.布隆过滤器的原理3.1数据结构布隆过滤器它实际上是一个很长的二进制向量和一系列随机映射函数。以 Redis 中的布隆过滤器实现为例，Redis 中的布隆过滤器底层是一个大型位数组（二进制数组）+多个无偏hash函数。 一个大型的二进制数组： 多个无偏的 hash 函数： 无偏 hash 函数就是能把元素的 hash 值计算的比较均匀的 hash 函数，能使得计算后的元素下标比较均匀的映射到位数组中。 如下就是一个简单的布隆过滤器示意图，其中k1、k2代表增加的元素，a、b、c即为无偏hash函数，最下层则为二进制数组。 3.2空间计算在布隆过滤器增加元素之前，首先需要初始化布隆过滤器的空间，也就是上面说的二进制数组，除此之外还需要计算无偏 hash 函数的个数。布隆过滤器提供了两个参数，分别是预计加入元素的大小n，运行的错误率f。布隆过滤器中有算法根据这两个参数会计算出二进制数组的大小l，以及无偏hash函数的个数k。它们之间的关系比较简单： 错误率越低，位数组越长，控件占用较大 错误率越低，无偏hash函数越多，计算耗时较长 3.3增加元素往布隆过滤器增加元素，添加的 key 需要根据 k 个无偏 hash 函数计算得到多个 hash 值，然后对数组长度进行取模得到数组下标的位置，然后将对应数组下标的位置的值置为 1。详细步骤如下： 通过k个无偏hash函数计算得到k个hash值 依次取模数组长度，得到数组索引 将计算得到的数组索引下标位置数据修改为1 例如，key = Liziba，无偏hash函数的个数 k=3，分别为 hash1、hash2、hash3。三个hash函数计算后得到三个数组下标值，并将其值修改为 1。如图所示： 3.4查询元素布隆过滤器最大的用处就在于判断某样东西一定不存在或者可能存在，而这个就是查询元素的结果。其查询元素的过程如下： 通过k个无偏hash函数计算得到k个hash值 依次取模数组长度，得到数组索引 判断索引处的值是否全部为1，如果全部为1则存在（这种存在可能是误判），如果存在一个0则必定不存在 关于误判，其实非常好理解，hash函数再怎么好，也无法完全避免hash冲突，也就是说可能会存在多个元素计算的 hash 值是相同的，那么它们取模数组长度后的到的数组索引也是相同的，这就是误判的原因。例如李子捌和李子柒的 hash 值取模后得到的数组索引都是1，但其实这里只有李子捌，如果此时判断李子柒在不在这里，误判就出现啦！因此布隆过滤器最大的缺点误判只要知道其判断元素是否存在的原理就很容易明白了！ 3.5修改&amp;删除元素布隆过滤器对元素的修改和删除不太支持，目前有一些变形的特定布隆过滤器支持元素的删除！关于为什么对修改和删除不太支持，其实也非常好理解，hash 冲突必然存在，修改和删除肯定是很苦难的！ 4.布隆过滤器的实现布隆过滤器类实现： 123456789public class BloomFilter { private static final HashGenerator.HashGroup[] GROUPS = new HashGenerator.HashGroup[]{HashGenerator.HashGroup.G1, HashGenerator.HashGroup.G2, HashGenerator.HashGroup.G3, HashGenerator.HashGroup.G4}; private final BitSet bits; private HashGenerator[] generators;} 多个无偏的 hash 函数 1234567891011121314151617181920212223242526272829303132333435private int hashG1(String value) { int hash = 0; for (int idx = 0; idx &lt; value.length(); idx++) { char c = value.charAt(idx); hash = (hash &lt;&lt; 5) + hash + c; hash &amp;= hash; hash = Math.abs(hash); } return hash % (seed * size - 1);}private int hashG2(String value) { int hash = 7397; for (int idx = 0; idx &lt; value.length(); idx++) { char c = value.charAt(idx); hash = (hash &lt;&lt; 5) + hash + c; } return Math.abs(hash % seed * (size - 1));}private int hashG3(String value) { int hash = 0; for (int idx = 0; idx &lt; value.length(); idx++) { char c = value.charAt(idx); hash = (hash &lt;&lt; 5) + hash + c; hash += c; hash &amp;= hash; } return Math.abs(hash % (seed * size - 1));}private int hashG4(String value) { int h; return (value == null) ? 0 : Math.abs(seed * (size - 1) &amp; ((h = value.hashCode()) ^ (h &gt;&gt;&gt; 16)));} 这里提供了四种哈希计算的方式，相当于每一个哈希计算都是一次扰动处理。一个元素的存放可以经过四次哈希，尽量让元素值做到散列。 构建容器： 1234567public BloomFilter(int size, int[] seeds) { bits = new BitSet(size); generators = new HashGenerator[seeds.length]; for (int i = 0; i &lt; seeds.length; i++) { generators[i] = new HashGenerator(size, seeds[i], GROUPS[i % GROUPS.length]); }} 构造函数根据所需创建的容器大小和哈希种子来初始化布隆过滤器。 添加元素： 123456public void add(String value) { for (HashGenerator generator : generators) { int hash = generator.doHash(value); bits.set(hash, true); }} 添加元素时按照元素初始化时的哈希计算种类，获取哈希并存放。 比对元素： 1234567public boolean contains(String value) { boolean ret = true; for (HashGenerator generator : generators) { ret = ret &amp;&amp; bits.get(generator.doHash(value)); } return ret;} 比对元素时用的是同一类哈希计算方式，并且把这些哈希值 &amp;&amp; 计算。用N个比特位置记录一个值更准确 5.常见面试题 布隆过滤器的使用场景？ 布隆过滤器用于检验一个元素是否存在集合中，布隆过滤器的特点是根据其判断不存在集合中的元素一定不存在集合中，判断其存在集合中的元素不一定存在。其具体应用场景有： 解决Redis缓存穿透问题（面试重点） 邮件过滤，使用布隆过滤器来做邮件黑名单过滤 对爬虫网址进行过滤，爬过的不再爬 解决新闻推荐过的不再推荐(类似抖音刷过的往下滑动不再刷到) HBase\\RocksDB\\LevelDB等数据库内置布隆过滤器，用于判断数据是否存在，可以减少数据库的IO请求 布隆过滤器的实现原理和方式？ 布隆过滤器底层是一个基于大型位数组（二进制数组）+多个无偏哈希函数实现的。其添加元素的方法是通过不同的哈希函数，将要添加的元素映射到数组的不同的位置上，并且将对应的位置设置为1。在判断元素是否存在的时候，同样通过不同的哈希函数将其映射到位数组上，并检查对应的位置是否均为1，若所有位置都为1，则表示该元素存在（存在误判）；如果有任何一个位置为0，则认为该元素不存在。 如何提高布隆过滤器的准确性？ 适当选择哈希函数数量: 哈希函数的数量对于布隆过滤器的准确性很重要。较多的哈希函数可以减少冲突和误判的可能性。但同时也会增加计算开销需要权衡。 使用高质量的哈希函数: 使用具有低冲突率和较好分布性的哈希函数可以减少误判。一些通用的哈希函数，如 MurmurHash、CityHash等，通常在布隆过滤器中表现良好。 动态调整位数组大小: 可以根据预期的元素数量和期望的误判率来动态调整位数组的大小。较大的位数组可以降低误判率，但也会增加空间消耗使用多人独立的布隆过滤器: 使用多人布隆过滤器，每个布隆过滤器使用不同的哈希函数和参数。将查询结果通过多个布隆过滤器的结果进行逻辑操作，可以减少误判。 组合其他数据结构: 可以将布隆过滤器与其他数据结构结合使用，例如使用个小的布隆过滤器进行快速筛选，然后再通过一个精确的数据结构 (如散列表)来进行最终的判断 定期重建: 定期重建布隆过滤器，清除旧的元素，可以有效减少误判。但这会增加计算开销。 有哪些中哈希计算方式？ 除留余数法(Division Hashing)：这是一种简单的哈希函数，将输入值除以个素数，然后取余数作为哈希值。通常票要选择一个适当的素数作为除数，以避免哈希碰撞。 乘法哈希 (Multiplicative Hashing) : 这种方法首先将输入值乘以一个常数A，提取乘积的小数部分，然后乘以哈希表大小 M，并取整得到最终哈希值。常数 A 通常取一个个于 0 和 1之间的数。 加法哈希 (Additive Hashing) : 将输入值的每个字符 (或字节) 转化为数值，然后将所有数值相加，最后取和的模作为哈希值。 旋转哈希 (Rotating Hash) : 对输入值的二进制表示进行循环移位(旋转)，然后将每一位都参与哈希计算。 位运算哈希(Bitwise Hashing) : 使用位运算(如异或、与、或等)对输入值的不同部分进行组合，得到哈希值。 都有哪些类型的布隆过滤器实现？Google 开源的 Guava 中自带的布隆过滤器、Redis 中的布隆过滤器","link":"/2023/08/16/Data-Structure/"},{"title":"KMP 算法","text":"学习目标： 掌握 KMP 算法思想 掌握前缀表的定义与求取 掌握力扣 KMP 相关题目 KMP 算法简介KMP 算法主要用于字符串匹配上面，KMP的主要思想是当出现字符串不匹配时，可以知道一部分之前已经匹配的文本内容，可以利用这些信息避免从头再去做匹配了。 举个例子来说： 当遍历文本串到 aabaab 的时候，发现 b 与模式串不匹配，此时如果采取暴力解法的话，采用的办法是从头再次进行遍历，时间复杂度为 O(m * n)，但是如果我此时可以做到继续与模式串的 b 开始匹配，那么只需要将文本串遍历一次即可，此时的时间复杂度为 O(n)，加上寻找模式串的前缀表，可以得知，时间复杂度为O(m +n)。 前缀表定义：记录下标i之前（包括i）的字符串中，有多大长度的相同前缀后缀。 作用：前缀表是用来回退的，它记录了模式串与主串(文本串)不匹配的时候，模式串应该从哪里开始重新匹配。 其中， 前缀是指不包含最后一个字符的所有以第一个字符开头的连续子串。 后缀是指不包含第一个字符的所有以最后一个字符结尾的连续子串。 也就是说，当匹配失败的时候，可以根据前缀表，从某个位置（模式串）开始继续匹配 一般将前缀表用 next 数组进行表示 那么如何获取前缀表呢？获取前缀表的方法和字符串匹配方法类似，即通过遍历模式串，不断累加，知道遇到不匹配的时候进行回退，即退回到匹配的前一个位置，然后继续进行匹配。 获取前缀表的三个步骤： 初始化 处理前后缀不相同的情况 处理前后缀相同的情况 初始化： 12j = 0next[0] = 0 也就是将模式串的遍历指针指向首端，将前缀表的第一个值赋为 0。 处理前后缀不相同的情况： next[j] 就是记录着 j（包括 j ）之前的子串的相同前后缀的长度。 那么 s[i] 与 s[j+1] 不相同，就要找 j+1前一个元素在 next 数组里的值（就是 next[j] ）。 123while (j &gt; 0 &amp;&amp; s.charAt(i) != s.charAt(j)) { j = next[j - 1];} 处理前后缀相同的情况： 如果 s[i] 与 s[j + 1] 相同，那么就同时向后移动i 和j 说明找到了相同的前后缀，同时还要将j（前缀的长度）赋给next[i], 因为next[i]要记录相同前后缀的长度 1234if (s.charAt(i) == s.charAt(j)) { j++;}next[i] = j; 整体获取前缀表的代码12345678910111213private void getNext(int[] next, String s) { int j = 0; next[0] = 0; for (int i = 1; i &lt; s.length(); i++) { while (j &gt; 0 &amp;&amp; s.charAt(i) != s.charAt(j)) { j = next[j - 1]; } if (s.charAt(i) == s.charAt(j)) { j++; } next[i] = j; }} 字符串匹配在进行字符串匹配的时候，采用的方法和求取前缀表相同 整体代码示例如下： 123456789101112131415161718192021222324252627282930313233343536class Solution { public int strStr(String haystack, String needle) { if (needle.length() == 0) { return 0; } int[] next = new int[needle.length()]; getNext(next, needle); int j = 0; for(int i = 0; i &lt; haystack.length(); i++) { while (j &gt; 0 &amp;&amp; needle.charAt(j) != haystack.charAt(i)) { j = next[j - 1]; } if (needle.charAt(j) == haystack.charAt(i)) { j++; } if (j == needle.length()) return i - needle.length() + 1; } return -1; } private void getNext(int[] next, String s) { int j = 0; next[0] = 0; for (int i = 1; i &lt; s.length(); i++) { while (j &gt; 0 &amp;&amp; s.charAt(i) != s.charAt(j)) { j = next[j - 1]; } if (s.charAt(i) == s.charAt(j)) { j++; } next[i] = j; } }} 其他题目：给定一个非空的字符串 s ，检查是否可以通过由它的一个子串重复多次构成。 1234567891011121314151617181920212223242526class Solution { public boolean repeatedSubstringPattern(String s) { if (s.equals(&quot;&quot;)) { return false; } int len = s.length(); char[] chars = s.toCharArray(); int[] next = new int[len]; next[0] = 0; for (int i = 1, j = 0; i &lt; len; i++) { while (j &gt; 0 &amp;&amp; chars[i] != chars[j]) { j = next[j-1]; } if (chars[i] == chars[j]) { j++; } next[i] = j; } if (next[len - 1] &gt; 0 &amp;&amp; len % (len - next[len - 1]) == 0) { return true; } return false; }}","link":"/2023/06/29/KMP/"},{"title":"深入理解 Java 原理之SSM","text":"本篇内容： 学习 Spring、SpringMVC、MyBatis 相关理论基础以及底层实现 学习相关面试常见题目，掌握问答精髓 回顾当天所学知识，加深印象 Spring 常见经典问答 什么是 Spring 框架？ Spring 是一款开源的轻量级 Java 开发框架，旨在提高开发人员的开发效率以及系统的可维护性。 我们一般说 Spring 框架指的都是 Spring Framework，它是很多模块的集合，使用这些模块可以很方便地协助我们进行开发，比如说 Spring 支持 IoC、 AOP，并且可以很方便地对数据库进行访问、可以很方便地集成第三方组件（电子邮件，任务，调度，缓存等等）、对单元测试支持比较好、支持 RESTful Java 应用程序的开发。 Spring 都有哪些主要模块？ Core Container、Data Access/Integration、AOP、Spring Web、Spring Test等模块。 Spring、SpringMVC、SpringBoot 三者有什么区别？ Spring 包含了多个功能模块，其中最重要的是 Spring-Core（主要提供 IoC 依赖注入功能的支持） 模块， Spring 中的其他模块（比如 Spring MVC）的功能实现基本都需要依赖于该模块。 Spring MVC 是 Spring 中的一个很重要的模块，主要赋予 Spring 快速构建 MVC 架构的 Web 程序的能力。MVC 是模型(Model)、视图(View)、控制器(Controller)的简写，其核心思想是通过将业务逻辑、数据、显示分离来组织代码。 使用 Spring 进行开发各种配置过于麻烦比如开启某些 Spring 特性时，需要用 XML 或 Java 进行显式配置。于是，有了 SpringBoot。Spring Boot 主要是为了简化 Spring 开发，省略了许多配置文件。 简述对 IOC 的理解 IOC，也就是Inversion of control，控制反转/反转控制，它是一种思想不是一个技术实现。其思想就是将原本在程序中手动创建对象的控制权，交由 Spring 框架来管理。 例如：现有类 A 依赖于类 B 传统的开发方式：往往是在类 A 中手动通过 new 关键字来 new 一个 B 的对象出来 使用 IoC 思想的开发方式：不通过 new 关键字来创建对象，而是通过 Spring 框架中的 IoC 容器来帮助我们实例化对象。我们需要哪个对象，直接从 IoC 容器里面获取即可。 也就是说，如果没有 Spring 的话，我们想要使用的对象，需要我们自己创建，而有了 Spring 的 IOC 之后，对象由 IOC 容器创建并管理，在想要使用的时候从容器中获取即可。 IOC 有什么优点？ 将对象之间的相互依赖关系交给 IoC 容器来管理，并由 IoC 容器完成对象的注入。这样可以很大程度上简化应用的开发，把应用从复杂的依赖关系中解放出来。 IoC 容器就像是一个工厂一样，当我们需要创建一个对象的时候，只需要配置好配置文件和注解即可，完全不用考虑对象是如何被创建出来的。 同样的，如果两个对象使用同一个Bean的话，也不需要创建多个Bean导致资源的浪费。 通俗易懂的帖子：https://www.zhihu.com/question/23277575/answer/169698662 IOC 如何实现的？ 从配置元数据中获取要的业务POJO (这里的配置元数据包括xml，注解，configuration类等） 将业务POJO形成BeanDefinition注入到Spring Container中 使用方通过ApplicationContext从Spring Container直接获取即可。 什么是 Spring Bean？ 简单来说，Bean 代指的就是那些被 IoC 容器所管理的对象。 我们需要告诉 IoC 容器帮助我们管理哪些对象，这个是通过配置元数据来定义的。配置元数据可以是 XML 文件、注解或者 Java 配置类。 将一个类设置为 Bean 的注解有哪些？ @Component：通用的注解，可标注任意类为 Spring 组件。如果一个 Bean 不知道属于哪个层，可以使用@Component 注解标注。 @Repository : 对应持久层即 Dao 层，主要用于数据库相关操作。 @Service : 对应服务层，主要涉及一些复杂的逻辑，需要用到 Dao 层。 @Controller : 对应 Spring MVC 控制层，主要用于接受用户请求并调用 Service 层返回数据给前端页面。 注入Bean的注解有哪些？ @Autowired、@Resource 二者有什么区别？ @Autowired 是 Spring 提供的注解，@Resource 是 JDK 提供的注解。假设系统容器从 Spring 迁移到其他IOC容器中，JDK支持的不需要修改代码。 Autowired 默认的注入方式为byType（根据类型进行匹配），@Resource默认注入方式为 byName（根据名称进行匹配）。 当一个接口存在多个实现类的情况下，@Autowired 和@Resource都需要通过名称才能正确匹配到对应的 Bean。Autowired 可以通过 @Qualifier 注解来显式指定名称，@Resource可以通过 name 属性来显式指定名称。 @Autowired 可以作用在构造器、字段、setter 方法上；@Resource只可以用于field、setter方法上。 Bean 的作用域有哪些？ singleton : IoC 容器中只有唯一的 bean 实例。Spring 中的 bean 默认都是单例的，是对单例设计模式的应用。 prototype : 每次获取都会创建一个新的 bean 实例。也就是说，连续 getBean() 两次，得到的是不同的 Bean 实例。 request （仅 Web 应用可用）: 每一次 HTTP 请求都会产生一个新的 bean（请求 bean），该 bean 仅在当前 HTTP request 内有效。 session （仅 Web 应用可用） : 每一次来自新 session 的 HTTP 请求都会产生一个新的 bean（会话 bean），该 bean 仅在当前 HTTP session 内有效。 application/global-session （仅 Web 应用可用）：每个 Web 应用在启动时创建一个 Bean（应用 Bean），该 bean 仅在当前应用启动时间内有效。 websocket （仅 Web 应用可用）：每一次 WebSocket 会话产生一个新的 bean。 Bean是线程安全的吗？ 当 Bean 的作用域为 prototype 的时候，每次都会创建一个新的Bean实例，因此不存在线程安全问题。但是大多数情况下，Bean 的作用域为 singleton，在这种情况下，IoC 容器中只有唯一的 bean 实例，可能会存在资源竞争问题（取决于 Bean 是否有状态）。如果这个 bean 是有状态的话，那就存在线程安全问题（有状态 Bean 是指包含可变的成员变量的对象）。大多数情况下，如 Dao、Service 是不存在可变的成员变量的，因此不存在线程安全问题。如果遇到线程不安全的情况，可以采取以下措施： 在 Bean 中尽量避免定义可变的成员变量。 在类中定义一个 ThreadLocal 成员变量，将需要的可变成员变量保存在 ThreadLocal 中（推荐的一种方式）。 Bean的生命周期 Bean 容器找到配置文件中 Spring Bean 的定义。 Bean 容器利用 Java Reflection API 创建一个 Bean 的实例。 如果涉及到一些属性值 利用 set()方法设置一些属性值。 检查 Aware 相关接口并且设置相关依赖 如果 Bean 实现了 BeanNameAware 接口，调用 setBeanName()方法，传入 Bean 的名字。 如果 Bean 实现了 BeanClassLoaderAware 接口，调用 setBeanClassLoader()方法，传入 ClassLoader对象的实例。 如果 Bean 实现了 BeanFactoryAware 接口，调用 setBeanFactory()方法，传入 BeanFactory对象的实例。 与上面的类似，如果实现了其他 *.Aware接口，就调用相应的方法。 如果有和加载这个 Bean 的 Spring 容器相关的 BeanPostProcessor 对象，执行postProcessBeforeInitialization() 方法 如果 Bean 实现了InitializingBean接口，执行afterPropertiesSet()方法。 如果 Bean 在配置文件中的定义包含 init-method 属性，执行指定的方法。 如果有和加载这个 Bean 的 Spring 容器相关的 BeanPostProcessor 对象，执行postProcessAfterInitialization() 方法 当要销毁 Bean 的时候，如果 Bean 实现了 DisposableBean 接口，执行 destroy() 方法。 当要销毁 Bean 的时候，如果 Bean 在配置文件中的定义包含 destroy-method 属性，执行指定的方法。 Spring AOP 的理解 AOP(Aspect-Oriented Programming:面向切面编程)能够将那些与业务无关，却被业务模块所共同调用的逻辑或责任（例如事务处理、日志管理、权限控制等）封装起来，便于减少系统的重复代码，降低模块间的耦合度，并有利于未来的可拓展性和可维护性。 多个切面的执行顺序如何实现？ 通常使用@Order 注解直接定义切面顺序，值越小越先执行。 Spring 框架中实现了哪些设计模式？ 工厂设计模式 : Spring 使用工厂模式通过 BeanFactory、ApplicationContext 创建 bean 对象。 代理设计模式 : Spring AOP 功能的实现。 单例设计模式 : Spring 中的 Bean 默认都是单例的。 模板方法模式 : Spring 中 jdbcTemplate、hibernateTemplate 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式。 包装器设计模式 : 我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源。 观察者模式: Spring 事件驱动模型就是观察者模式很经典的一个应用。 适配器模式 : Spring AOP 的增强或通知(Advice)使用到了适配器模式、spring MVC 中也是用到了适配器模式适配Controller。 Spring 事务 什么是事务？ 事务是指逻辑上的一组操作，要么都执行，要么全部不执行。 事务的特性（ACID）简单叙述一下 原子性（Atomicity）：事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用； 一致性（Consistency）：执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的； 隔离性（Isolation）：并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的； 持久性（Durability）：一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。 AID是手段，C是目的。 Spring 支持事务有哪些方式？ 编程式事务。通过 TransactionTemplate或者TransactionManager手动管理事务。 声明式事务。使用 @Transactional注解进行事务管理。 Spring 事务管理有哪些接口？ **PlatformTransactionManager**：（平台）事务管理器，Spring 事务策略的核心。 **TransactionDefinition**：事务定义信息(事务隔离级别、传播行为、超时、只读、回滚规则)。 **TransactionStatus**：事务运行状态。 @Transactional 的作用范围 方法：推荐将注解使用于方法上，不过需要注意的是：该注解只能应用到 public 方法上，否则不生效。 类：如果这个注解使用在类上的话，表明该注解对该类中所有的 public 方法都生效。 接口：不推荐在接口上使用。 @Transactional 的原理解析 @Transactional 的工作机制是基于 AOP 实现的，AOP 又是使用动态代理实现的。如果一个类或者一个类中的 public 方法上被标注@Transactional 注解的话，Spring 容器就会在启动的时候为其创建一个代理类，在调用被@Transactional 注解的 public 方法的时候，实际调用的是，TransactionInterceptor 类中的 invoke()方法。这个方法的作用就是在目标方法之前开启事务，方法执行过程中如果遇到异常的时候回滚事务，方法调用完成之后提交事务。 事务隔离级别相关内容见 MySQL 相关总结 Transactional(rollbackFor = Exception.class)注解了解吗？ Exception 分为运行时异常 RuntimeException 和非运行时异常。事务管理对于企业应用来说是至关重要的，即使出现异常情况，它也可以保证数据的一致性。当 @Transactional 注解作用于类上时，该类的所有 public 方法将都具有该类型的事务属性，同时，我们也可以在方法级别使用该标注来覆盖类级别的定义。如果类或者方法加了这个注解，那么这个类里面的方法抛出异常，就会回滚，数据库里面的数据也会回滚。 在 @Transactional 注解中如果不配置rollbackFor属性,那么事务只会在遇到RuntimeException的时候才会回滚，加上 rollbackFor=Exception.class,可以让事务在遇到非运行时异常时也回滚。 简单叙述一下 Spring AOP 的自调用问题 当一个方法被标记了@Transactional 注解的时候，Spring 事务管理器只会在被其他类方法调用的时候生效，而不会在一个类中方法调用生效。即在如下情况下不会生效： 123456789101112@Servicepublic class MyService {private void method1() { method2(); //......}@Transactional public void method2() { //...... }} @Transactional 的使用注意事项总结 @Transactional 注解只有作用到 public 方法上事务才生效，不推荐在接口上使用； 避免同一个类中调用 @Transactional 注解的方法，这样会导致事务失效； 正确的设置 @Transactional 的 rollbackFor 和 propagation 属性，否则事务可能会回滚失败; 被 @Transactional 注解的方法所在的类必须被 Spring 管理，否则不生效； 底层使用的数据库必须支持事务机制，否则不生效； Spring MVC 常见经典问答 说说自己对于 Spring MVC 了解? MVC 是一种设计模式，是模型(Model)、视图(View)、控制器(Controller)的简写，其核心思想是通过将业务逻辑、数据、显示分离来组织代码。Spring MVC 是一款很优秀的 MVC 框架。Spring MVC 可以帮助我们进行更简洁的 Web 层的开发，并且它天生与 Spring 框架集成。Spring MVC 下我们一般把后端项目分为 Service 层（处理业务）、Dao 层（数据库操作）、Entity 层（实体类）、Controller 层(控制层，返回数据给前台页面)。 Spring MVC 的核心组件有哪些？ DispatcherServlet：核心的中央处理器，负责接收请求、分发，并给予客户端响应。 HandlerMapping：处理器映射器，根据 uri 去匹配查找能处理的 Handler ，并会将请求涉及到的拦截器和 Handler 一起封装。 HandlerAdapter：处理器适配器，根据 HandlerMapping 找到的 Handler ，适配执行对应的 Handler； Handler：请求处理器，处理实际请求的处理器。 ViewResolver：视图解析器，根据 Handler 返回的逻辑视图 / 视图，解析并渲染真正的视图，并传递给 DispatcherServlet 响应客户端 Spring MVC 的底层原理如何实现的？ 客户端（浏览器）发送请求， DispatcherServlet拦截请求。 DispatcherServlet 根据请求信息调用 HandlerMapping 。HandlerMapping 根据 uri 去匹配查找能处理的 Handler（也就是我们平常说的 Controller 控制器） ，并会将请求涉及到的拦截器和 Handler 一起封装。 DispatcherServlet 调用 HandlerAdapter适配器执行 Handler 。 Handler 完成对用户请求的处理后，会返回一个 ModelAndView 对象给DispatcherServlet，ModelAndView 顾名思义，包含了数据模型以及相应的视图的信息。Model 是返回的数据对象，View 是个逻辑上的 View。 ViewResolver 会根据逻辑 View 查找实际的 View。 DispaterServlet 把返回的 Model 传给 View（视图渲染）。 把 View 返回给请求者（浏览器） 统一异常处理如何实现？ 使用注解的方式统一异常处理，具体会使用到 @ControllerAdvice + @ExceptionHandler 这两个注解。这种异常处理方式下，会给所有或者指定的 Controller 织入异常处理的逻辑（AOP），当 Controller 中的方法抛出异常的时候，由被@ExceptionHandler 注解修饰的方法进行处理。ExceptionHandlerMethodResolver 中 getMappedMethod 方法决定了异常具体被哪个被 @ExceptionHandler 注解修饰的方法处理异常。getMappedMethod()会首先找到可以匹配处理异常的所有方法信息，然后对其进行从小到大的排序，最后取最小的那一个匹配的方法(即匹配度最高的那个)。 1234567891011121314@ControllerAdvice@ResponseBodypublic class GlobalExceptionHandler { @ExceptionHandler(BaseException.class) public ResponseEntity&lt;?&gt; handleAppException(BaseException ex, HttpServletRequest request) { //...... } @ExceptionHandler(value = ResourceNotFoundException.class) public ResponseEntity&lt;ErrorReponse&gt; handleResourceNotFoundException(ResourceNotFoundException ex, HttpServletRequest request) { //...... }} MyBatis 常见经典问答 #{} 和 ${} 的区别是什么？ ${}是 Properties 文件中的变量占位符，它可以用于标签属性值和 sql 内部，属于静态文本替换，比如${driver}会被静态替换为com.mysql.jdbc.Driver。 #{}是 sql 的参数占位符，MyBatis 会将 sql 中的#{}替换为? 号，在 sql 执行前会使用 PreparedStatement 的参数设置方法，按序给 sql 的? 号占位符设置参数值。如果在sql语句中使用 ${id}，则翻译成sql语句之后，id 带有 “”，即where id = “id”。 xml 映射文件中，除了常见的 select、insert、update、delete 标签之外，还有哪些标签？ &lt;resultMap&gt;、 &lt;parameterMap&gt;、 &lt;sql&gt;、 &lt;include&gt;、 &lt;selectKey&gt; ，加上动态 sql 的 9 个标签， trim|where|set|foreach|if|choose|when|otherwise|bind 等，其中 &lt;sql&gt; 为 sql 片段标签，通过 &lt;include&gt; 标签引入 sql 片段， &lt;selectKey&gt; 为不支持自增的主键生成策略标签。 123456789101112131415161718192021在这里对这些标签的使用方式进行举例说明&lt;resultMap&gt;用于定义如何将数据库查询结果映射到 Java 对象的属性。&lt;parameterMap&gt;目前基本不使用&lt;sql&gt;：这个标签用于定义可重用的 SQL 片段。例如： &lt;sql id=&quot;userColumns&quot;&gt; user_id, username, user_email &lt;/sql&gt;&lt;include&gt;用于引用&lt;sql&gt;标签中的代码 &lt;select id=&quot;getUser&quot; resultMap=&quot;userResultMap&quot;&gt; SELECT &lt;include refid=&quot;userColumns&quot;/&gt; FROM users WHERE user_id = #{userId} &lt;/select&gt;&lt;selectKey&gt;：这个标签用于在插入语句执行后获取生成的主键值 &lt;insert id=&quot;insertUser&quot;&gt; &lt;selectKey resultType=&quot;int&quot; keyProperty=&quot;id&quot; order=&quot;AFTER&quot;&gt; SELECT LAST_INSERT_ID() &lt;/selectKey&gt; INSERT INTO users (username, user_email) VALUES (#{username}, #{email}) &lt;/insert&gt; Dao 接口里的方法，参数不同时，方法能重载吗？ Dao 接口里的方法可以重载，但是 Mybatis 的 xml 里面的 ID 不允许重复。否则就会报错。那么尽管 Dao 中的方法可以重载，那么对应到 xml 文件中的实现方式是动态sql，即可以使用动态sql的方式，例如： 12345678&lt;select id=&quot;getAllStu&quot; resultType=&quot;com.pojo.Student&quot;&gt; select * from student &lt;where&gt; &lt;if test=&quot;id != null&quot;&gt; id = #{id} &lt;/if&gt; &lt;/where&gt;&lt;/select&gt; 可以实现有无id两种方法重载。 Dao 接口的工作原理是什么？ 通常一个 xml 映射文件，都会写一个 Dao 接口与之对应。Dao 接口就是人们常说的 Mapper 接口，接口的全限名，就是映射文件中的 namespace 的值；接口的方法名，就是映射文件中 MappedStatement 的 id 值，接口方法内的参数，就是传递给 sql 的参数。 Mapper 接口是没有实现类的，当调用接口方法时，接口全限名+方法名拼接字符串作为 key 值，可唯一定位一个 MappedStatement ，举例：com.mybatis3.mappers.StudentDao.findStudentById ，可以唯一找到 namespace 为 com.mybatis3.mappers.StudentDao 下面 id = findStudentById 的 MappedStatement 。在 MyBatis 中，每一个 &lt;select&gt;、 &lt;insert&gt;、 &lt;update&gt;、 &lt;delete&gt; 标签，都会被解析为一个 MappedStatement 对象。 简述 MyBatis 的插件运行原理，以及如何编写一个插件 MyBatis 仅可以编写针对 ParameterHandler、 ResultSetHandler、 StatementHandler、 Executor 这 4 种接口的插件，MyBatis 使用 JDK 的动态代理，为需要拦截的接口生成代理对象以实现接口方法拦截功能，每当执行这 4 种接口对象的方法时，就会进入拦截方法，具体就是 InvocationHandler 的 invoke() 方法，当然，只会拦截那些你指定需要拦截的方法。 实现 MyBatis 的 Interceptor 接口并复写 intercept() 方法，然后在给插件编写注解，指定要拦截哪一个接口的哪些方法即可，记住，别忘了在配置文件中配置你编写的插件。 MyBatis 动态 sql 是做什么的？都有哪些动态 sql？能简述一下动态 sql 的执行原理不？ MyBatis 动态 sql 可以让我们在 xml 映射文件内，以标签的形式编写动态 sql，完成逻辑判断和动态拼接 sql 的功能。其执行原理为，使用 OGNL（OGNL 可以理解为一种访问和操作对象属性的方式，类似于在 Java 代码中使用点号来访问对象的属性。） 从 sql 参数对象中计算表达式的值，根据表达式的值动态拼接 sql，以此来完成动态 sql 的功能。 你知道有哪些动态 sql 的标签？ &lt;if&gt;&lt;/if&gt; &lt;where&gt;&lt;/where&gt;(trim,set) &lt;choose&gt;&lt;/choose&gt;（when, otherwise） &lt;foreach&gt;&lt;/foreach&gt; &lt;bind/&gt; MyBatis 是如何将 sql 执行结果封装为目标对象并返回的？都有哪些映射形式？ 有两种方式。 第一种是使用 &lt;resultMap&gt; 标签，逐一定义列名和对象属性名之间的映射关系。 第二种是使用 sql 列的别名功能，将列别名书写为对象属性名，比如 T_NAME AS NAME，对象属性名一般是 name，小写，但是列名不区分大小写，MyBatis 会忽略列名大小写，智能找到与之对应对象属性名，MyBatis 一样可以正常工作。 有了列名与属性名的映射关系后，MyBatis 通过反射创建对象，同时使用反射给对象的属性逐一赋值并返回，那些找不到映射关系的属性，是无法完成赋值的。 MyBatis 能执行一对一、一对多的关联查询吗？都有哪些实现方式，以及它们之间的区别 能，MyBatis 不仅可以执行一对一、一对多的关联查询，还可以执行多对一，多对多的关联查询，多对一查询，其实就是一对一查询，只需要把 selectOne() 修改为 selectList() 即可；多对多查询，其实就是一对多查询，只需要把 selectOne() 修改为 selectList() 即可。 关联对象查询，有两种实现方式，一种是单独发送一个 sql 去查询关联对象，赋给主对象，然后返回主对象。另一种是使用嵌套查询，嵌套查询的含义为使用 join 查询，一部分列是 A 对象的属性值，另外一部分列是关联对象 B 的属性值，好处是只发一个 sql 查询，就可以把主对象和其关联对象查出来。 MyBatis 的 xml 映射文件中，不同的 xml 映射文件，id 是否可以重复？ 不同的 xml 映射文件，如果配置了 namespace，那么 id 可以重复；如果没有配置 namespace，那么 id 不能重复。 原因就是 namespace+id 是作为 Map&lt;String, MappedStatement&gt; 的 key 使用的，如果没有 namespace，就剩下 id，那么，id 重复会导致数据互相覆盖。有了 namespace，自然 id 就可以重复，namespace 不同，namespace+id 自然也就不同。 MyBatis 都有哪些 Executor 执行器？它们之间的区别是什么？ MyBatis 有三种基本的 Executor 执行器： SimpleExecutor： 每执行一次 update 或 select，就开启一个 Statement 对象，用完立刻关闭 Statement 对象。 ReuseExecutor： 执行 update 或 select，以 sql 作为 key 查找 Statement 对象，存在就使用，不存在就创建，用完后，不关闭 Statement 对象，而是放置于 Map&lt;String, Statement&gt;内，供下一次使用。简言之，就是重复使用 Statement 对象。 **BatchExecutor**：执行 update（没有 select，JDBC 批处理不支持 select），将所有 sql 都添加到批处理中（addBatch()），等待统一执行（executeBatch()），它缓存了多个 Statement 对象，每个 Statement 对象都是 addBatch()完毕后，等待逐一执行 executeBatch()批处理。与 JDBC 批处理相同。 作用范围：Executor 的这些特点，都严格限制在 SqlSession 生命周期范围内。 MyBatis 是否可以映射 Enum 枚举类？ MyBatis 可以映射枚举类，不单可以映射枚举类，MyBatis 可以映射任何对象到表的一列上。映射方式为自定义一个 TypeHandler ，实现 TypeHandler 的 setParameter() 和 getResult() 接口方法。 TypeHandler 有两个作用： 一是完成从 javaType 至 jdbcType 的转换； 二是完成 jdbcType 至 javaType 的转换，体现为 setParameter() 和 getResult() 两个方法，分别代表设置 sql 问号占位符参数和获取列查询结果。 MyBatis 映射文件中，如果 A 标签通过 include 引用了 B 标签的内容，请问，B 标签能否定义在 A 标签的后面，还是说必须定义在 A 标签的前面？ 虽然 MyBatis 解析 xml 映射文件是按照顺序解析的，但是，被引用的 B 标签依然可以定义在任何地方，MyBatis 都可以正确识别。 原理是，MyBatis 解析 A 标签，发现 A 标签引用了 B 标签，但是 B 标签尚未解析到，尚不存在，此时，MyBatis 会将 A 标签标记为未解析状态，然后继续解析余下的标签，包含 B 标签，待所有标签解析完毕，MyBatis 会重新解析那些被标记为未解析的标签，此时再解析 A 标签时，B 标签已经存在，A 标签也就可以正常解析完成了。 为什么说 MyBatis 是半自动 ORM 映射工具？它与全自动的区别在哪里？ Hibernate 属于全自动 ORM 映射工具，使用 Hibernate 查询关联对象或者关联集合对象时，可以根据对象关系模型直接获取，所以它是全自动的。而 MyBatis 在查询关联对象或关联集合对象时，需要手动编写 sql 来完成，所以，称之为半自动 ORM 映射工具。 补充：Object Relational Mapping，简称ORM，即对象关系映射。一般用于实现面向对象编程语言里的对象和数据库中的之间的转换。 MyBatis 有哪些优点？ 将数据库的操作逻辑和业务操作解耦合，使得开发人员可以专心业务逻辑的处理 开发人员只写Sql就可以访问数据库，不需要关心各种数据库连接等额外的操作。各种Connection和Statement都交给了Mybatis来管理 可以将数据库表的字段按照业务规则直接映射到DO层，不用再像JDBC一样需要业务代码来转换 支持多种数据源，如POOLED，UNPOOLED，JNDI（自带的三种数据源，一般不使用，原因见后） 支持动态SQL，大大减少了代码的开发量，如if/foreach等常用的动态标签 支持事务性的一级缓存，二级缓存和自定义缓存，其中，一级缓存是以session为生命周期，默认开启；二级缓存则是根据配置的算法来计算过期时间(FIFO，LRU等)，二级缓存如果操作不当容易产生脏数据，不建议使用 为什么不适应MyBatis自带的数据源？ 空闲连接占用资源:连接池维护一定数量的空闲连接，这些连接会占用系统的资源，如果连接池设置过大，那么会浪费系统资源，如果设置过小，则会导致系统并发请求时连接不够用，影响系统性能。 连接池大小调优困难:连接池的大小设置需要根据系统的并发请求量、数据库的性能和系统的硬件配置等因素综合考虑，而这些因素都是难以预测和调整的。 连接泄漏:如果应用程序没有正确关闭连接，那么连接池中的连接就会泄漏，导致连接池中的连接数量不断增加，最终导致系统崩溃 MyBatis 插件使用的原理是什么？ Mybatis插件的运行原理主要涉及3个关键接口: Interceptor、Invocation 和 Plugin. Interceptor: 拦截器接口，定义了Mybatis插件的基本功能，包括插件的初始化、插件的拦截方法以及插的销毁方法。 Invocation: 调用接口，表示Mybatis在执行SQL语句时的状态，包括SQL语句、参数、返回值等信息 Plugin: 插件接口，Mybatis框架在执行SQL语句时，会将所有注册的插件封装成Plugin对象，通过Plugin对象实现对SQL语句的拦截和修改。 插件的运行流程如下: 首先，当Mybatis框架运行时，会将所有实现了Interceptor接口的插件进行初始化。 初始化后，Mybatis框架会将所有插件和原始的Executor对象封装成一个InvocationChain对象。(这里使用的是责任链模式) 每次执行SQL语句时，Mybatis框架都会通过InvocationChain对象依次调用所有插件的intercept方法，实现对SQL语句的拦截和修改 最后，Mybatis框架会将修改后的SQL语句交给原始的Executor对象执行，并将执行结果返回给调用方通过这种方式，Mybatis插件可以对SQL语句进行拦截和修改，实现各种功能，例如查询缓存、分页、分库分表等 MyBatis 工作的原理是什么？ 启动阶段: 定义配置文件，如XML，注解 解析配置文件，将配置文件加载到内存当中 运行阶段: 读取内存中的配置文件，并根据配置文件实现对应的功能 ✅Mybatis的工作原理？ (yuque.com) 什么是数据源、数据库和数据库连接池？ 数据源是连接管理的抽象，数据库是数据的存储，而数据库连接池是一种优化连接管理的机制，提高应用程序的性能和可伸缩性。 MyBatis 是否支持延迟加载机制？其原理是什么？ 支持。延迟加载允许在需要时按需加载关联对象，而不是在查询主对象时立即加载所有关联对象。这样做可以提高查询性能和减少不必要的数据库访问。 延迟加载的主要原理就是当开启了延迟加载功能时，当查询主对象时，MyBatis会生成一个代理对象，并将代理对象返回给调用者当后面需要访问这些关联对象时，代理对象会检查关联对象是否已加载。如果未加载，则触发额外的查询。 查询结果返回后，MyBatis会将关联对象的数据填充到代理对象中，使代理对象持有关联对象的引用。这样，下次访问关联对象时，就可以直接从代理对象中获取数据，而无需再次查询数据库。 使用 MyBatis 如何实现分页查询？ MyBatis 可以通过两种方式实现分页：基于物理分页和基于逻辑分页。数据小的话无所谓，逻辑分页更简单点，数据量大的话一定使用物理分页，避免查询慢，也避免内存被撑爆 物理分页指的是最终执行的SQL语句中进行分页，也就是SQL语句中带limit，这样的SQL语句执行之后返回的内容就是分页后的结果 逻辑分页就是在SQL语句中不进行分页，照常全部查询，但是在查询到的结果集中进行分页。 通常有四种做法： 在SQL语句中添加limit语句。物理分页 基于PageHelper分页插件实现分页。物理分页 基于RowBounds实现分页，设置其 offset 和 limit 用于分页。逻辑分页 基于MyBatis-Plus实现分页，可以根据传入的参数自动进行分页。物理+逻辑 简述RowBounds分页的原理 MyBatis的RowBounds是一个用于分页查询的简单POJO类，它包含两个属性offset和limit，分别表示分页查询的偏移量和每页查询的数据条数。 在使用RowBounds进行逻辑分页的时候，我们的SQL语句中是不需要指定分页参数的。就正常的查询即可，然后，在查询的时候，将RowBounds当做一个参数传递。这样，实际上在查询的时候，将会先将所有符合条件的记录返回，然后再在内存中进行分页，分页的方式是根据RowBounds中指定的offset和limit进行数据保留，即抛弃掉不需要的数据再返回。 简述PageHelper的原理 PageHelper是MyBatis中提供的分页插件，主要是用来做物理分页的。 当我们在代码中使用 PageHelper.startPage(int pageNum,int pagesize) 设置分页参数之后，其实PageHelper会把他们存储到ThreadLocal中。 PageHelper会在执行器的query方法执行之前，会从ThreadLocal中再获取分页参数信息，页码和页大小，然后执行分页算法，计算需要返回的数据块的起始位置和大小。最后，PageHelper会通过修改SQL语句的方式，在SQL后面动态拼接上limit语句，限定查询的数据范围，从而实现物理分页的效果。并且在查询结束后再清除ThreadLocal中的分页参数。 MyBatis Plus 常见经典问答 MyBatis Plus 有什么用？ MyBatis Plus 是一个增强的MyBatis框架，有许多常用的实用功能。 通用 Mapper：提供了一组通用的Mapper接口和实现（例如BaseMapper），可以更加快速的进行增删改查操作，不需要手写Sql语句。 分页插件：提供了一种简单易用的分页功能，可以根据传入的分页参数自动计算出分页信息，无需手动编写分页SQL语句。 自动生成代码：可以根据数据库表自动生成实体类、Mapper接口、Mapper XML映射文件等代码，大大减少开发人员的工作量。 Lambda表达式支持：提供了 LambdaQueryWrapper 和 LambdaUpdateWrapper，可以使用Lambda表达式来构造查询条件和更新操作，使得代码更加简洁和易读。 SQL注入器：提供了自定义的SQL注入器功能，可以自由扩展MyBatis的SQL语句，实现更加灵活的SQL操作。 性能分析插件：提供了性能分析插件，可以帮助开发人员分析 SQL 执行效率，优化数据库操作。 MyBatis-Plus 有哪些优缺点？ 优点 简化开发: MyBatis-Plus封装了很多CRUD操作，使得我们不需要手写大量的SQL语句，从而减少了开发时间和代码量。 提高性能: MyBatis-Plus的分页插件和缓存插件等能够提高SQL执行的效率和性能 提供了代码生成器: MyBatis-Plus提供了一款强大的代码生成器，能够根据数据库表自动生成Java Bean、Mapper接门、Service接口等代码，大大提高了开发效率。 易于扩展: MyBatis-Plus提供了丰富的插件接口，能够自定义插件，实现自己的业务需求. 缺点 技术选型限制: MyBatis-Plus是基于MyBatis的增强工具，因此使用MyBatis-Plus需要熟悉MyBatis的使用，对于不熟悉MyBatis的开发人员来说可能需要一些时间学习。 版本依赖问题: MyBatis-Plus的版本依赖于MyBatis的版本，因此需要注意版本的兼容性 自动映射不可靠: MyBatis-Plus提供了自动映射功能，但是在某些情况下可能不够可靠，需要手动进行映射。 代码生成器生成的代码可能需要手动调整: MyBatis-Plus的代码生成器可以自动生成大量的代码，但是有时候生成的代码可能不符合项目的需求，需要手动进行调整 MyBatis-Plus 分页原理是什么？ MyBatis-Plus支持逻辑分页和物理分页两种方式，并且可以根据需要自由选择。默认情况下，MyBatis-Plus使用的是物理分页。 逻辑分页是在查询结果集中进行分页，即先查询出全部结果，然后在内存中对结果进行分页。逻辑分页的优点是实现简单，可以对结果进行任意操作(例如排序、筛选等)，缺点是如果数据量过大，会导致内存溢出等问题。 物理分页是在数据库中进行分页，即直接在SQL语句中加入LIMIT语句，只查询所需的部分数据。物理分页的优点是可以减少内存占用，减轻数据库的负载，缺点是无法对结果进行任意操作。 默认情况下，MyBatis-Plus使用的是物理分页。如果需要使用逻辑分页，可以在分页插件的配置中指定分页的类型。 SpringBoot 常见经典问答","link":"/2023/08/29/Java%E5%85%AB%E8%82%A1%E4%B9%8BSSM/"},{"title":"Lottery-API","text":"","link":"/2023/07/07/Lottery-API/"},{"title":"深入 Java 原理之集合篇","text":"本篇内容： 学习 Java 集合相关理论基础以及底层实现 学习相关面试常见题目，掌握问答精髓 回顾当天所学知识，加深印象 Java 集合经典问答 Java中的集合类都有哪些？ Java 整个集合框架中，主要分为 List、Set、Queue、Stack、Map 等。其中前四种数据结构是单一元素的集合，而 Map 是 KV 形式存储元素。并且前四种都是 Collection 的子接口或者子接口的子接口，而 Collection 有继承了 Iterable 接口，说明这几种集合类型都是可以进行遍历的。 从功能上讲，List 代表一个容器，可以是先进先出，也可以是先进后出。而Set相对于List来说，是无序的，同时也是一个去重的列表，既然会去重，就一定会通过 equals，compareTo，hashCode 等方法进行比较。Map 则是 KV 的映射，也会涉及到 KV 值的查询等能力。 从实现上进，List可以有链表实现或者数组实现，两者各有优劣，链表增删快，数组查询快。Queue则可以分为优先队列，双端队列等等。Map则可以分为普通的 HashMap 和可以排序的 TreeMap 等等。 Collection 和 Collections 有什么区别？ Collection 是一个集合接口：该接口提供了对集合对象进行基本操作的通用接口方法。Collection 接口在 Java 类库中有很多具体的实现，是 list、set 的父接口。 Collections 是一个包装类：它包含各种有关集合操作的静态多态方法。此类不能实例化，就像一个工具类，服务于 Java 的 Collection 框架。 Java 中的 Collection 如何遍历迭代？ 传统的for循环 增强for循环，即for-each结构 迭代器遍历，Iterator Iterator 和 Iterable 如何使用？ Iterator 和 Iterable 是两个接口，前者代表的是选代的方式，如 next 和 hasNext 方法就是需要在该接口中实现。后者代表的是是否可以迭代，如果可以迭代，会返回 iterator 接口，即返回迭代方式。 常见的使用方式一般是集合实现 Iterable 表明该集合可以遍历，同时选择 Iterator 或者自定义一个 Iterator 的实现类去选择遍历方式。 为什么不把 Iterable 和 Iterator 合成一个使用 1. Iterable和Iterator并不是同时出现的，Iterator于1.2就出现了，目的是为了代替Enumeration，而 iterable 则是1.5才出现的2. 将是否可以选代和迭代方式抽出来，更符合单一职责原则，如果抽出来，迭代方式就可以被多个可迭代的集合复用，更符合面向对象的特点。 说出几种集合排序的方式？ 在实体类中继承并实现Comparable接口 在排序的时候使用Comparator比较器进行比较排序 使用Stream流来进行比较排序，其底层还是通过Comaprable实现的 为什么有了Comparable之后还需要Comparator？ Comparable用于使某个类具备可排序能力，通过实现该接口后覆盖其compareTo方法，即可具备可排序的能力。 但是仍然存在一些二方库的类没有实现Comparable，但是调用方也需要比较的，此时就需要使用Comparator接口。 Comparator是一个比较器接口，可以用来给不具备排序能力的对象进行排序。 追问：为什么有了Comparator之后还需要Comparable？ 自然排序: Comparable 接口为类提供了一种默认的自然排序方式。这意味着，如果一个类实现了 Comparable，那么它的对象可以在不需要额外比较器的情况下直接参与排序操作,比如使用Collections.sort()或Arrays.sort()方法。这种自然排序对于简单的、基于类内部属性的排序非常方便。 简便性: 对于某些场景，你可能只需要简单的排序规则，此时 Comparable 提供了一种更为简便的方法。你只需要实现compareTo方法，然后对象就可以直接参与排序。 API 设计: 在某些情况下，你可能控制不了外部类的代码，无法为其添加额外的比较器。如果这些类实现了 Comparable 接口，它们的对象就可以在不改变原代码的情况下，被直接用于排序操作。 性能: Comparable 接口允许对象在内部定义排序规则，这可能在某些情况下比使用外部的Comparator实现更高效 CompareTo和equals的使用场景分别是什么？ CompareTo 通常用于排序和BigDecimal等数值比较 equals常用于判断两个对象是否相同，例如String常常使用equals来比较字面意义是否相同 既然Set是无序的，那么如何实现排序？ Set的无序指的是插入顺序是无序的，也就是遍历的时候的顺序和添加时的顺序不一样。虽然Set的插入顺序是无序的，Set也可以基于SortedSet要求对象实现Comparable来对Set中的元素进行排序。 Set真的是插入无序的吗？ 并不一定是。Set的实现类LinkedHashSet，引用了LinkedHashMap，通过双向链表记录了每个node的插入顺序和查询顺序，以此来实现Set的插入有序性。 简述 fail-safe 和 fail-fast 机制 Fail-Safe： Fail-safe 是一种设计原则，它指的是在进行迭代操作时，集合会创建一个迭代器的副本，而不是直接在原始集合上进行操作。这样，即使在迭代过程中原始集合发生了修改，副本仍然可以继续进行操作，避免了并发修改异常。Java 中的 CopyOnWriteArrayList 和 ConcurrentHashMap 就是使用 fail-safe 原则的例子。在这些数据结构中，你可以在迭代时安全地进行添加、删除等操作，因为迭代器操作的是一个快照。 Fail-Fast： Fail-fast 是另一种设计原则，它强调在并发操作中，一旦检测到集合的结构被修改，就立即抛出异常，防止后续操作引发不可预料的错误。Java 的标准集合类（如 ArrayList、HashSet 等）通常是 fail-fast 的。如果你在迭代集合时，另一个线程对集合进行了修改，那么会立即抛出 ConcurrentModificationException 异常，以提醒你在并发情况下进行了非法操作。 总之，fail-safe 原则通过复制数据结构的副本来避免并发修改异常，而 fail-fast 原则通过检测修改来快速发现并报告并发问题。在选择使用哪种原则时，你需要根据应用的需求和并发情况来进行权衡。 在 CopyOnWriteArrayList 中，对add/remove方法都进行了加锁操作，但是为什么还需要 copy 一个副本出来呢？或者什么是 Copy-On-Write 机制？ Copy-On-Write简称COW，是一种用于程序设计中的优化策略。其基本思路是，从一开始大家都在共享同一个内容，当某个人想要修改这个内容的时候，才会真正把内容Copy出去形成一个新的内容然后再改，这是一种延时懒惰策略。 CopyOnWrite容器即写时复制的容器。通俗的理解是当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。 CopyOnWriteArrayList中add/remove等写方法是需要加锁的，目的是为了避免Copy出N个副本出来，导致并发写。但是，CopyOnWriteArrayList中的读方法是没有加锁的。 这样做的好处是我们可以对CopyOnWrite容器进行并发的读，当然，这里读到的数据可能不是最新的。因为写时复制的思想是通过延时更新的策略来实现数据的最终一致性的，并非强一致性。所以CopyOnWrite容器是一种读写分离的思想，读和写不同的容器。 遍历的同时修改List有几种方法？ 使用普通的 for 循环 使用迭代器循环 将原来的集合copy一个副本，遍历原来的list，然后删除副本 使用并发安全的集合类，如CopyOnWriteArrayList 通过Stream的过滤方法，因为每次Stream处理之后都会生成一个新的Stream，因此不存在并发问题，所以Stream的filter也可以修改list集合 使用removeIf方法，removeIf方法可以过滤删除所有满足条件的元素 介绍Set的实现方式并且指出他们如何保证元素不重复 Set根据实现方式不同主要分为两大类。HashSet和TreeSet。 TreeSet 是二叉树实现的，TreeSet中的数据是自动排好序的，不允许放入null值; 底层基于TreeMap。 HashSet 是哈希表实现的，HashSet中的数据是无序的，可以放入null，但只能放入一个null，两者中的值都不能重复，就如数据库中唯一约束;底层基于HashMap 在HashSet中，基本的操作都是有HashMap底层实现的，因为HashSet底层是用HashMap存储数据的。当向HashSet中添加元素的时候，首先计算元素的hashCode值，然后通过扰动计算和按位与的方式计算出这入元素的存储位置，如果这人位置为空，就将元素添加进去;如果不为空，则用equals方法比较元素是否相等，相等就不添加，否则找一个空位添加。 TreeSet的底层是TreeMap的keySet，而TreeMap是基于红黑树实现的，红黑树是一种平衡二叉查找树，它能保证任何一个节点的左右子树的高度差不会超过较矮的那棵的一倍。TreeMap是按key排序的，元素在插入TreeSet时compareTo方法要被调用，所以TreeSet中的元素要实现Comparable接口。TreeSet作为一种Set，它不允许出现重复元素。TreeSet是用compareTo来判新重复元素的。 HashSet，TreeSet，LinkedHashSet，BitSet有何区别 功能不同: HashSet是功能最简单的Set，只提供去重的能力 LinkedHashSet不仅提供去重功能，而且还能记录插入和查询顺序 TreeSet提供了去重和排序的能力; BitSet不仅能提供去重能力，同时也能减少存储空间的浪费，不过对于普通的对象不太友好，需要做额外处理 实现方式不同: HashSet基于HashMap，去重是根据HashCode和equals方法的 LinkedHashSet是基于LinkedHashMap，通过双向链表记录插入顺序 TreeSet是基于TreeMap的，去重是根据compareTo方法的 BitSet基于位数组，一般只用于数字的存储和去重。其实BitSet只是叫做Set而已，它既没有实现Collection接口，也和Iterable接口没有什么关系，但是是名字相似而已 什么是BitSet，有什么优势和缺点？ BitSet 是位集合，在底层数据结构是一个bit数组。如果n加入到集合中，就将第n位元素设置为1即可 优势：降低了存储空间，如正常情况下，将每一个int类型(32bit)的数字存储到内存中需要 4B *(2^31-1) = 8 GB，但是如果用BitSet的话，就会节省到原来的1/32。 缺点：当集合中存储一些差值比较大的数，如1亿和1两个数，就会导致内存的严重浪费 应用场景：BitSet常见的使用例子往往和大数相关 现在有1千万个随机数，随机数的范围在1到1亿之间。求出将1到1亿之间没有在随机数中的数 统计N亿个数据中没有出现的数据 将N亿个不同数据进行排序等 ArrayList、LinkedList和Vector有哪些区别？ List主要有ArrayList、LinkedList与Vector几种实现。这三者都实现了List 接口，使用方式也很相似,主要区别在于因为实现方式的不同,所以对不同的操作具有不同的效率。 ArrayLlist 是一个可改变大小的数组当元素加入到ArravList中时,其大小将会动态地增长内部的元素。可以直接通过get与set方法进行访问,因为ArrayList本质上就是一个数组。 LinkedList 是一个双向链表，在添加和删除元素时具有比ArrayList更好的性能，但在get与set方面弱于ArrayList。当然,这些对比都是指数据量很大或者操作很频繁的情况下的对比,如果数据和运算量很小,那么对比将失去意义。 Vector 和ArrayList类似,但属于强同步类。如果你的程序本身是线程安全的(thread-safe,没有在多个线程之间共享同一个集合/对象)。那么使用ArrayList是更好的选择。 Vector和ArrayList在更多元素添加进来时会请求更大的空间。Vector每次请求其大小的双倍空间，而ArrayList每次对size增长50%。而LinkedList 还实现了Queue和Deque接门,该接口比List提供了更多的方法,包括offer(),peek(),poll()等.默认情况下ArrayList的初始容量非常小,所以如果可以预估数据量的话,分配一个较大的初始值属于最佳实践，这样可以减少调整大小的开销。 ArrayList 如何进行扩容？ 检查新增元素后是否会超过数组的容量，如果超过，则进行下一步扩容 设置新的容量为老容量的1.5倍，最多不超过2^31-1 申请一个容量为1.5倍的数组，并将老数组的元素复制到新数组中，扩容完成 如何使用list实现LRU？ LRU，即最近最少使用策略，基于时空局部性原理(最近访问的，未来也会被访问)，往往作为缓存淘汰的策略。如Redis和GuavaMap都使用了这种淘汰策略。使用方式是将当前访问的进行缓存，剔除最后一个很久没被访问的元素。 ArrayList的subList有什么使用建议？ list的subList方法并没有创建一个新的List，而是使用了原List的视图，也就是在原list中指定了元素的范围然后进行展示。所以我们不能把subList方法返回的List强制转换成ArrayList等类，因为他们之间没有继承关系。 因此以下几种操作都会对二者产生影响： 对父(sourceList)子(subList)List做的非结构性修改 (non-structural changes)，都会影响到彼此（如修改元素，二者都会添加） 对子List做结构性修改，操作同样会反映到父List 上。（如在末尾增添元素，则二者都会增加） 对父List做结构性修改，会抛出异常ConcurrentModificationException。（如在末尾增添元素，则会抛出异常） ArrayList如何实现序列化？ ArrayList 底层是通过 Object 数组完成数据存储的，但是这个数组被声明成了 transient，说明在默认的序列化策略中并没有序列化数组字段。ArrayList 在实现序列化时，实际上是通过自定义序列化和反序列化方法来处理其元素。即 writeObject 和 readObject 方法，也可以在自己的类中覆盖这些方法来指定序列化和反序列化的过程。 为什么 ArrayList 底层 Object 数组设置为transient？ ArrayList实际上是动态数组，每次在放满以后自动增长设定的长度值，如果数组自动增长长度设为100而实际只放了一个元素，那就会序列化99个null元素。为了保证在序列化的时候不会将这么多null同时进行序列化，ArrayList把元素数组设置为transient。 如何解决哈希冲突？ 目前解决哈希冲突的算法有多种，例如拉链寻址、开放寻址、合并散列、杜鹃散列、跳房子散列、罗宾汉哈希等 拉链寻址。将哈希表的每个单元作为链表的头结点，所有哈希地址相同的元素构成一个链表。即发生冲突时就把该关键字链在以该单元为头结点的链表的尾部。 开放寻址。开放寻址的设计会对碰撞的元素，寻找哈希桶上新的位置，这个位置从当前碰撞位置开始向后寻找，直到找到空的位置存放。 合并散列。合并散列的原理是，当发生哈希冲突时，将冲突的元素加到哈希表的最后，然后将当前哈希值的指针指向冲突的元素。也就是将发生哈希碰撞的元素进行链接。 杜鹃散列的基本思想是通过使用两个散列函数而不是仅一个散列函数来解决冲突。 跳房子散列。 罗宾汉哈希。当我们进行插入时，如果发现单元格被其他键值对占用，那么就需要比较这俩人键距离其原本位置的距离。距离较远的键值对留下，距离较近的被迫后移。 拉链寻址法有什么优缺点？ 优点： 处理比较简单 适合经常插入或者删除的情况 适合没有预留空间的情况 缺点：当冲突较多的时候，查找时间复杂度O(n) HashMap 如何存储数据？ JDK1.8 之前 HashMap 底层是 数组和链表 结合在一起使用也就是 链表散列。HashMap 通过 key 的 hashcode 经过扰动函数处理过后得到 hash 值，然后通过 (n - 1) &amp; hash 判断当前元素存放的位置（这里的 n 指的是数组的长度），如果当前位置存在元素的话，就判断该元素与要存入的元素的 hash 值以及 key 是否相同，如果相同的话，直接覆盖，不相同就通过拉链法解决冲突。 JDK1.8 之后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。 HashMap、HashTable、CurrentHashMap有什么区别？ 线程安全: HashMap 是非线程安全的。 Hashtable 中的方法是同步的，所以它是线程安全的。 ConcurrentHashMap 在 JDK 1.8 之前使用分段锁保证线程安全，ConcurrentHashMap 默认情况下将 hash 表分为16个桶(分片)，在加锁的时候，针对每个单独的分片进行加锁，其他分片不受影响。锁的粒度更细，所以性能更好。ConcurrentHashMap在JDK 1.8中，采用了一种新的方式来实现线程安全，即使用了CAS+synchronized，这实现被称为”分段锁”的变种，也被称为”锁分离”，它将锁定粒度更细，把锁的粒度从整个Map降低到了单个桶。 继承关系： HashTable是基于陈旧的的Dictionary类继承来的。 HashMap继承的抽象类AbstractMap实现了Map接口 ConcurrentHashMap同样继承了抽象类AbstractMap，并且实现了ConcurrentMap口接。 允不允许null值: HashTable中，key和value都不允许出现null值，否则会抛出NullPointerException异常. HashMap中，null可以作为键或者值都可以。（始终放在数组的第一个位置） ConcurrentHashMap中，key和value都不允许为null。 默认初始容量和扩容机制: HashMap的默认初始容量为16，默认的加载因子为0.75，即当HashMap中元素个数超过容量的75%时，会进行扩容操作。扩容时，容量会扩大为原来的两倍，并将原来的元素重新分配到新的桶中。 Hashtable，默认初始容量为11，默认的加载因子为0.75，即当Hashtable中元素个数超过容量的75%时，会进行扩容操作。扩容时，容量会扩大为原来的两倍加1，并将原来的元素重新分配到新的桶中。 ConcurrentHashMap，默认初始容量为16，默认的加载因子为0.75，即当ConcurrentHashMap中元素个数超过容量的75%时，会进行扩容操作。扩容时，容量会扩大为原来的两倍，并会采用分段锁机制，将ConcurrentHashMap分为多个段(segment)，每个段独立进行扩容操作，避免了整个ConcurrentHashMap的锁竞争。 遍历方式的内部实现上不同: HashMap使用EntrySet进行遍历，即先获取到HashMap中所有的键值对(Entry)，然后遍历Entry集合。支持failfast，也就是说在遍历过程中，若HashMap的结构被修改 (添加或删除元素)，则会抛出ConcurrentModificationException如果只需要遍历HashMap中的key或value，可以使用KeySet或Values来遍历。 Hashtable使用Enumeration进行遍历，即获取Hashtable中所有的key，然后遍历key集合。遍历过程中Hashtable的结构发生变化时，Enumeration会失效。 ConcurrentHashMap使用分段锁机制，因此在遍历时需要注意，遍历时ConcurrentHashMap的某个段被修改不会影响其他段的遍历。可以使用EntrySet、KeySet或Values来遍历ConcurrentHashMap，其中EntrySet遍历时效率最高。遍历过程中，ConcurrentHashMap的结构发生变化时，不会抛出ConcurrentModificationExceptior异常，但是在遍历时可能会出现数据不一致的情况，因为遍历器仅提供了弱一致性保障. 为什么 HashMap 中允许键值为 null 而 ConcurrentHashMap 不允许？ ConcurrentMap (如ConcurrentHashMap、ConcurrentSkipListMap) 不允许使用null值的主要原因是，在非并发的Map中(如HashMap)，是可以容忍模糊性(二义性)的，而在并发Map中是无法容忍的。 如果所有的Map都支持null的话，那么map.get(key)就可以返回null，但是，这时候就会存在一个不确定性。当你拿到null的时候，你是不知道他是因为本来就存了一个null进去还是说就是因为没找到而返回了null。 在HashMap中，因为它的设计就是给单线程用的，所以当我们map.get(key)返回null的时候，我们是可以通过map.containsKey检查来进行检测的，如果它返回true，则认为是存了一个null，否则就是因为没找到而返回null 但是，像ConcurrentHashMap，它是为并发而生的，它是要用在并发场景中的，当我们map.get(key)返回nul的时候，是没办法通过map.contains(key)检查来准确的检测，因为在检测过程中可能会被其他线程锁修改，而导致检测结果并不可靠。 所以，为了让ConcurrentHashMap的语义更加准确，不存在二义性的问题，他就不支持null。 HashMap的get和put方法实现过程 get 方法。对于get方法来说会先查找桶，如果hash值相同并且key值相同，则返回该node节点，如果不同，则当node.next!=null时，判断是红黑树还是链表，之后根据相应方法进行查找。 put 方法。 如果数组没有被初始化，先初始化数组 首先通过定位到要put的key在哪个桶中，如果该桶中没有元素，则将该要put的entry放置在该桶中 如果该桶中已经有元素，则遍历该桶所属的链表 如果该链表已经树化，则执行红黑树的插入流程 如果仍然是链表，则执行链表的插入流程，如果插入后链表的长度大于等于8，并且桶数组的容量大于64，则执行链表的树化流程，如果插入后链表的长度大于等于8，并且桶数组的容量小于64，则先执行扩容操作。注意: 在上面的步骤中，如果元素和要put的元素相同，则直接替换 校验++size是否超过threshold，如果超过，则执行扩容流程 HashMap 如何定位 key？ 先通过 (table.length - 1) &amp; (key.hashCode ^ (key.hashCode &gt;&gt; 16)) 定位到key位于哪 table中然后再通过 key.equals(rowKey) 来判断两个key是否相同，综上，是先通过hashCode和equals来定位KEY的。 为什么是用&amp;而不是用%: 因为&amp;是基于内存的二进制直接运算，比转成十进制的取模快的多。以下运算等价: X % 2^n = X &amp; (2^n - 1) 这也是hashMap每次扩容都要到2^n的原因 为什么用key.hashCode ^(key.hashCode &gt;&gt; 16)而不是用 key.hashCode 这是因为增加了扰动计算，使得hash分布的尽可能均匀。因为hashCode是int类型，虽然能映射40亿左右的空间，但是，HashMap的table.ength毕竟不能有那么大，所以为了使hash%table.length之后，分布的尽可能均匀，就需要对实例的hashCode的值进行扰动，说白了，就是将hashCode的高16和低16位，进行异或，使得hashCode的值更加分散一点。如果不进行这步操作，那么由于table.length的原因，key.hashCode的高位无法发挥作用 为什么 HashMap 的数组长度始终为 2^n？ HashMap是通过 (table.length - 1) &amp; (key.hashode ^ (key.hashCode &gt;&gt; 16)) 定位tablelndex的。 因为&amp;是基于内存的二进制直接运算，比转成十进制的取模快的多。又因为 X % 2^n = X &amp; (2^n - 1)，可以把%运算转换为&amp;运算。所以，hashMap的capcatiy一定要是2^n，这样HashMap计算hash的速度才够快。 如何保证的 HashMap 的数组长度始终为 2^n？ 初始化时期：在初始化的时候找到一个比当前传入值大的最近的2^n的值，作为数组长度。 扩容时期：当目前HashMap中的元素个数大于临界值的时候，会发生扩容，在扩容的时候扩容为之前的两倍，同样保证了数组长度为 2^n。 HashMap中的负载因子为多少？为什么？ HashMap中的负载因子为0.75，即当当前元素个数大于数组长度 * 0.75的时候发生扩容。 原因： 如果当HashMap完全填满时，再进行发生扩容操作的代价会很高，因为需要重新计算所有键的哈希码并重新分配到新的桶中。这可能导致性能下降。而且，随着HashMap中添加的元素越来越多，哈希冲突的概率会增加，因为元素分布在相对较少的桶中，极端情况下可能会导致某个Entry下引用了很长的链表，最终的结果就是虽然节省了空间，但是查询和插入都会很耗时间。 理论上负载因子不能太大，不然会导致大量的哈希冲突，也不能太小，那样会浪费空间。通过一个数学推理，测算出这个数值在0.7左右是比较合理的。由于 threshold=loadFactor*capacity，并且capacity永远都是2的幕，为了保证负载因子(loadFactor) 容量(capacity) 的结果是一个整数，这个值是3/4比较合理，因为这个数和任何2的幂乘积结果都是整数。 HashMap为什么需要扩容？扩容操作如何进行的？ 假设现在散列表中的元素已经很多了，但是现在散列表的链化已经比较严重了，哪怕是树化了时间复杂度也没有O(1)好，所以需要扩容来降低Hash冲突的概率，以此来提高性能。 我们知道,当 ++size &gt; threshold 之后，HashMap就会初始化新的新的桶数组，该桶数组的size为原来的两倍，在扩大桶数组的过程中，会涉及两个部分: 如果某桶节点没有形成链表，则直接rehash到其他桶中 如果桶中形成链表，则将链表重新链接 如果桶中的链表已经形成红黑树，但是链表中的元素个数小于6，则进行取消树化的操作 链表重新链接的时候有两种情况： 当hash(k) &amp; oldCap = 0时，这些链表的节点还是在原来的节点中 如果hash(k) &amp; oldCap != 0时，这些链表的节点会到桶新增的位置中，且都是同一个桶。 为什么JDK8之后不继续使用链表而是改为红黑树？ 当某个bucket的哈希冲突过多的时候，其指向的链表就会变得很长，这样如果put或者get该bucket上的元素时，复杂度就无限接近于O(N)。、 所以在JDK1.7的时候，在元素put之前做hash的时候，就会充分利用扰动函数，将不同KEY的hash尽可能的分散开。不过这样做起来效果还不是太好，所以当链表过长的时候，我们就要对其数据结构进行修改。 为什么时红黑树而不是二分查找树或者AVL树？ 使用二分查找树的话，在极端情况下，例如加入的元素都小于原来的元素，那么这样的话依旧会退化成为链表。 红黑树不会像AVL树一样追求绝对的平衡，它的插入最多两次旋转，删除最多三次旋转。在频繁的插入和删除场景中，红黑树的时间复杂度，是优于AVL树的。 为什么不直接使用红黑树，而是先使用链表呢？ 从空间维度来进，因为红黑树的空间是普通链表节点空间的2倍，立刻转为红黑树后，太浪费空间；从时间维度上讲，红黑树虽然查询比链表快，但是插入比链表慢多了，每次插入都要旋转和变色，如果小于8就转为红黑树，时间和空间的综合平衡上就没有链表好 为什么设置转换的数字是8呢？ 官方文档中认为，当 hashCode遵循泊松分布时，因为哈希冲突造成桶的链表长度等于8的概率只有0.00000006。官方认为这个概率足够的低，所以指定链表长度为 8 时转化为红黑树。同时避免树化过早而造成时间和空间上的浪费。 为什么设置小于6的时候就转回来？ 这个设计的主要原因是出于对于性能和空间的考虑。转成红黑树之后总要在适当的时机转回来，要不然无论是空间占用而且插入性能都会下降。大于8的时候转成红黑树，那么如果小于8立刻转回去，那么就可能会导致频繁转换，当红黑树节点数小于 6 时，它所带来的优势其实就是已经没有那么大了，就不足以抵消由于红黑树维护节点所带来的额外开销，此时转换回链表能够节省空间和时间。但是不管怎样，6 这个数值是通过大量实验得到的经验值，在绝大多数情况下取得比较好的效果。 为什么HashMap数据结构中使用双向链表？ HashMap红黑树的数据结构中，不仅有常见的parent,left，right节点，还有一个next和prev节点。这说明，其不仅是一个红黑树，还是一个双向链表。 原因是：红黑树会记录树化之前的链表结构，这样当红黑树化成链表的时候，就可以直接按照链表重新链接的方式进行。当删除节点的时候，只有next属性是没办法将原始的链表重新链接的，所以就需要prev节点，找到上一个节点，重新成链。 HashMap的元素没有比较能力，红黑树为什么可以比较? 如果元素实现了comparable接口，则直接比较，否则使用默认的仲裁方法 HashMap中的hash方法如何实现的？ hash方法的功能是根据Key来定位这个键值对在链表数组中的位置，也就是hash方法的输入应当是一个Object类型的key，输出是一个int类型的数组下标。在HashMap中，该方法的具体实现主要是通过两个方法，一个是int hash(Object k)，另一个是int indexFor(int h, int length)来实现的。 其中，hash是将Object转换成为一个整型；indexFor是将hash生成的整型转换成链表数组中的下标。其中有两个操作： 为什么是用&amp;而不是用%: 因为&amp;是基于内存的二进制直接运算，比转成十进制的取模快的多。以下运算等价: X % 2^n = X &amp; (2^n - 1) 这也是hashMap每次扩容都要到2^n的原因 为什么用key.hashCode ^(key.hashCode &gt;&gt; 16)而不是用 key.hashCode 这是因为增加了扰动计算，使得hash分布的尽可能均匀。因为hashCode是int类型，虽然能映射40亿左右的空间，但是，HashMap的table.ength毕竟不能有那么大，所以为了使hash%table.length之后，分布的尽可能均匀，就需要对实例的hashCode的值进行扰动，说白了，就是将hashCode的高16和低16位，进行异或，使得hashCode的值更加分散一点。如果不进行这步操作，那么由于table.length的原因，key.hashCode的高位无法发挥作用 HashMap中的put方法如何实现的？ 首先，put方法会计算键的哈希值(通过调用hash方法)，并通过哈希值计算出在数组中的索引位置 如果该位置上的元素为空，那么直接将键值对存储在该位置上。 如果该位置上的元素不为空，那么遍历该位置上的元素，如果找到了与当前键相等的键值对，那么将该键值对的值更新为当前值，并返回旧值。 如果该位置上的元素不为空，但没有与当前键相等的键值对，那么将键值对插入到链表或红黑树中(如果该位置上的元素数量超过了一个阈值，就会将链表转化为红黑树来提高效率)。 如果插入成功，返回null; 如果插入失败，返回被替换的值。 插入成功后，如果需要扩容，那么就进行一次扩容操作。 HashMap中的get方法如何实现的？ 首先，需要计算键的哈希值，并通过哈希值计算出在数组中的索引位置. 如果该位置上的元素为空，说明没有找到对应的键值对，直接返回null。 如果该位置上的元素不为空，遍历该位置上的元素，如果找到了与当前键相等的键值对，那么返回该键值对的值。 如果该位置上的元素不为空，但没有与当前键相等的键值对，那么就需要在链表或红黑树中继续查找。 遍历链表或红黑树，查找与当前键相等的键值对，找到则返回该键值对的值，否则返回null。 HashMap中的remove方法如何实现的？ 首先，remove方法会计算键的哈希值，并通过哈希值计算出在数组中的索引位置。 如果该位置上的元素为空，说明没有找到对应的键值对，直接返回null。 如果该位置上的元素不为空，检查是否与当前键相等，如果相等，那么将该键值对删除，并返回该键值对的值。 如果该位置上的元素不为空，但也与当前键不相等，那么就需要在链表或红黑树中继续查找。 遍历链表或者红黑树，查找与当前键相等的键值对，找到则将该键值对删除，并返回该键值对的值，否则返回null。 ConcurrentHashMap如何保证线程安全？ 在JDK 1.7中，ConcurrentHashMap使用了分段锁技术，即将哈希表分成多个段，每个段拥有一个独立的锁。这样可以在多个线程同时访问哈希表时，只需要锁住需要操作的那个段，而不是整个哈希表，从而提高了并发性能。 虽然JDK 1.7的这种方式可以减少锁竞争，但是在高并发场景下，仍然会出现锁竞争，从而导致性能下降。 在JDK 1.8中，ConcurrentHashMap的实现方式进行了改进，使用分段锁和“CAS+Synchronized”的机制来保证线程安全。在JDK 1.8中，ConcurrentHashMap会在添加或删除元素时，首先使用CAS操作来尝试修改元素，如果CAS操作失败，则使用Synchronized锁住当前槽，再次尝试put或者delete。这样可以避免分段锁机制下的锁粒度太大，以及在高并发场景下，由于线程数量过多导致的锁竞争问题，提高了并发性能。 ConcurrentHashMap为了保证线程安全都有哪些操作？ 初始化桶操作：如果在此阶段不做并发控制，那么极有可能出现多个线程都去初始化桶的问题，导致内存浪费。所以Map在此处采用自旋操作和CAS操作，如果此时没有线程初始化，则去初始化，否则当前线程让出CPU时间片，等待下一次唤醒。 put 元素操作：如果hash之后发现桶中没有值，则会直接采用CAS插入并返回；如果发现桶中有值，那么就会对流程按照当前的桶节点为维度进行加锁，将值插入链表或者红黑树中。 扩容操作 ConcurrentHashMap如何保证fail-safe？ 首先，在 ConcurrentHashMap 中，遍历操作返回的是弱一致性迭代器，这种迭代器的特点是，可以获取到在迭代器创建后被添加到 ConcurrentHashMap 中的元素，但不保证一定能获取到在迭代器创建后被删除的元素。 另外，在JDK 1.8 中，ConcurrentHashMap 中的 Segment 被移除了，取而代之的是使用类似于CAS+synchronized的机制来实现并发访问。在遍历 ConcurrentHashMap 时，只需要获取每个桶的头结点即可，因为每个桶的头结点是原子更新的，不会被其他线程修改，因此不需要加锁。 也就是说，ConcurrentHashMap 通过弱一致性迭代器和 Segment 分离机制来实现 fail-safe 特性，可以保证在遍历时不会受到其他线程修改的影响。 什么是弱一致性保障？ ConcurrentHashMap 提供的是弱一致性保障，这是因为在多线程并发修改 ConcurrentHashMap 时，可能会出现一些短暂的不一致状态，即一个线程进行了修改操作，但是另一个线程还没有看到这个修改。因此，在并发修改ConcurrentHashMap 时，不能保证在所有时刻 ConcurrentHashMap 的状态都是一致的。 如何将集合变成线程安全的？ 在调用集合前，使用synchronized或者ReentrantLock对代码加锁(读写都要加锁) 使用ThreadLocal，将集合放到线程内访问，但是这样集合中的值就不能被其他线程访问了 使用Collections.synchronizedXXX()方法，可以获得一个线程安全的集合 使用不可变集合进行封装，当集合是不可变的时候，自然是线程安全的 HashMap在并发场景下有什么问题？ 出现并发死循环（JDK1.7之前由于采用头插法造成的，多个线程同时扩容时发生死循环。在JDK1.8之后就修复了这个BUG，采用尾插法解决了这个问题） 多线程put的时候，size的个数和真正的个数不一样 多线程put的时候，可能会把上一个put的值覆盖掉 和其他不支持并发的集合一样，HashMap也采用了fast-fail操作，当多个线程同时put和get的时候，会抛出并发异常。当既有get操作，又有扩容操作的时候，有可能数据刚好被扩容换了桶，导致get不到数据 什么是COW？该方法如何保证线程安全？ Copy-0n-Write简称COW，是一种用于程序设计中的优化策略。其基本思路是，从一开始大家都在共享同一个内容，当某个人想要修改这个内容的时候，才会真正把内容Copy出去形成一个新的内容然后再改，这是一种延时懒惰策略。 JDK1.5开始Java并发包里提供了两个使用 COW 机制实现的并发容器,它们是 CopyOnWriteArrayList 和 CopyOnWriteArraySet。 CopyOnWriteArraylist使用了一种叫写时复制的方法，当有新元素 add 到 CopyOnWriteArraylist 时，先从原有的数组中拷贝一份出来，然后在新的数组做写操作，写完之后，再将原来的数组引用指向到新数组。 这样做的好处是我们可以对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器。 注意: CopyOnWriteArrayList的整个add操作都是在锁的保护下进行的。也就是说add方法是线程安全的。 COW 适用于哪些情况？ CopyOnWrite并发容器用于读多写少的并发场景。比如白名单，黑名单，商品类目的访问和更新场景。 和ArrayList不同的是，它具有以下特性: 支持高效率并发且是线程安全的 因为通常需要复制整个基础数组，所以可变操作 (add()、set() 和 remove() 等等)的开销很大 迭代器支持hasNext(),next() 等不可变操作，但不支持可变 remove() 等操作 使用迭代器进行遍历的速度很快，并且不会与其他线程发生冲突。在构造迭代器时，迭代器依赖于不变的数组快照","link":"/2023/08/26/Java%E5%85%AB%E8%82%A1%E4%B9%8B%E9%9B%86%E5%90%88/"},{"title":"Lottery抽奖系统","text":"项目目标： 运用模板、策略、工厂、状态等设计模式，定义抽奖过程标准和实现对应的多类型抽奖的服务模块。 为了根据不同用户进行适配，根据组合模式构建决策树，开发规则引擎，通过量化，筛选用户身份标签，找到符合参与的活动号，完成自由组合的人群过滤服务，提升代码重用。 面对活动秒杀的并发场景，将秒杀锁优化为 Redis Key 加锁，又从 Redis Key 的独占锁，优化为滑块锁。缩小锁粒度，提升并发性能。 解耦抽奖流程，把抽奖和发奖用 MQ 消息串联起来，避免一个流程太长，导致用户一直等待。 使用 db-router-starter 统一路由组件。实现根据字段对库表动态切换，完成对活动参与记录的分库分表。 DAY01：环境搭建按照小册子搭建环境即可。 注意 如果使用的数据库是8版本以上，还需要再对配置文件的进行修改 将该模块下的yml配置文件中将driver-class-name 调整为com.mysql.cj.jdbc.Driver ，且因为MySQL8连接要求，必须在连接url后跟上serverTimezone 的配置，即url: jdbc:mysql://127.0.0.1:3306/lottery?useUnicode=true&amp;serverTimezone=Asia/Shanghai DDD架构：两篇文章： 美团篇：领域驱动设计在互联网业务开发中的实践 - 美团技术团队 (meituan.com) 腾讯篇：后台开发进阶：白话DDD从入门到实践 - 元宇宙 (yitb.com) RPC：之前的学习以及做的项目都是一个单体项目，也就是用户直接通过X来调用A应用，然后来实现自己的需求。但是这样的系统结构在面对一些高并发的场景时，会由于流量过多而发生异常。因此引入了扩容，即一个RPC对应一个应用的实例，当流量进入的时候，可以将流量分散开，从而保证系统正常运行。 一般RPC的结构实现： pom文件修改：如果将所有的依赖都添加在父工程的pom文件中，那么就会导致子工程在加载时会引入所有父工程的依赖，因此父工程只定义springboot和jdk版本的依赖。 关于pom文件中两种build的理解： (5条消息) POM.XML的build标签中resources标签_狂丰的博客-CSDN博客 今日总结： 今天按照小傅哥的册子跑通了广播模式RPC过程调用，过程可谓一波三折，总结以下几个问题： 首先在引入小傅哥的文件时，要修改相关的配置以及引用 在修改数据库版本的时候，要注意修改配置文件中的url和driver-class-name 注意每一个模块对其他模块的调用以及打包方式（只有interfaces层采用war包） 注意@Service是Dubbo中的注解而不是引用Spring中的 刚开始不知道为什么报错，后来又莫名其妙好了，这个我还没有想明白 注意在进行单元测试的时候，首先要向数据库添加数据，否则会报错 明日计划： 将第三节的代码自己编写一遍 学习一个简单的Dubbo项目 DAY02：今日工作： 重新编写DAY01的代码并提交到代码库中 整理代码框架 对整个框架以及DDD结构有了全新的理解 DDD架构的个人理解如果是一个单体项目采用DDD结构，那么RPC层不存在，剩余的层： interface层：接口层，负责接收前端发给的请求并且进行处理，然后调用应用层的方法来实现请求并且将结果返回给前端 application层：应用层。用来表述应用和用户行为，负责服务的组合、编排和转发，负责处理业务用例的执行顺序以及结果的拼装 domain层：领域层，负责核心业务代码的编写 infrastructure层：为各层提供资源服务（如数据库、缓存等），实现各层的解耦，降低外部资源变化对业务逻辑的影响 如果是分布式项目： RPC层：作用是提供远程调用接口 PO、VO、DO、DTO的对比参考自小傅哥： PO：persistent object 持久对象 有时也被称为Data对象，对应数据库中的entity，可以简单认为一个PO对应数据库中的一条记录。（一般存放在infrastructure层中，如上图中的Activity） 在Mybatis持久化框架中与insert/delet操作密切相关。 PO中不应该包含任何对数据库的操作。 POJO ：plain ordinary java object 无规则简单java对象 VO：value object 值对象 / view object 表现层对象（一般放在domain层中） 主要对应页面显示（web页面/swt、swing界面）的数据对象。 可以和表对应，也可以不，这根据业务的需要。 可以细分包括 req、res（请求时的实体类、返回的实体类） DO（Domain Object）：领域对象，就是从现实世界中抽象出来的有形或无形的业务实体。通常可以代替部分 PO 的职责。 DTO（TO）：Data Transfer Object 数据传输对象 用在需要跨进程或远程传输时，它不应该包含业务逻辑。 比如一张表有100个字段，那么对应的PO就有100个属性（大多数情况下，DTO内的数据来自多个表）。但view层只需显示10个字段，没有必要把整个PO对象传递到client，这时我们就可以用只有这10个属性的DTO来传输数据到client，这样也不会暴露server端表结构。到达客户端以后，如果用这个对象来对应界面显示，那此时它的身份就转为VO。 DAY03：抽奖活动策略表设计 抽奖活动策略表设计 分库分表分表的意义： MySQL数据库采用B+树来进行数据的存储和查找，如果数据量太大的话，SQL查询效率就会变低。如果一个查询SQL没有命中，那么就回去在海量数据中进行查找，从而影响性能甚至崩溃。 就算是命中，但是如果数据过多，比如千万级别。那么B+树就会变高，从而影响查询。 B+树工作原理： InnoDB存储引擎最小单元是页，一页大小就是16KB，B+树叶子节点存储的是索引和数据(针对主键而言)内部节点存储的是键值和指针。 索引组织表通过非叶子节点的二分查找法以及指针确定数据具体在哪个页里，再从数据页中寻找需要的数据。 假设B+树高度是2，(根节点占一格高度，和若干叶子节点)。这颗B+树存放的总记录数 = 根节点指针数 * 单个叶子节点记录行数 如果一行记录数的数据是1k，那么叶子节点 (单个)能存储的数据量就是 16k / k = 16 非叶子节点内存放多少指针呢？我们假设主键ID为bigint类型，长度为8字节(面试官问你int类型，一个int就是32位，4字节)，而指针大小在InnoDB源码中设置为6字节，所以就是 8+6=14 字节，16k /14B = 16 * 1024B /14B =1170 因此，一棵高度为2的B+树，能存放1170（第一层的索引数量） * 16（第二层每一个索引指向的数量）=18720条这样的数据记录。同理一棵高度为3的B+树，能存放1170 *1170 *16 =21902400，大概可以存放两千万左右的记录。B+树高度一般为1-3层，如果B+到了4层，查询的时候会多查磁盘的次数（即磁盘IO），SQL就会变慢。 如果说不进行分表，那么一行记录数的数据就会变大，单个叶子结点储存的信息数量就会减少，就会导致B+树高度变大 分库的意义：在本业务中，用户参与活动记录和次数，用户是否中奖，中奖信息需要分库 本身这些操作，属于是非常非常高频的一些操作，如果业务量剧增，数据库可能会出现性能瓶颈，这时候我们就需要考虑拆分数据库。从这几方面来看 磁盘存储业务量剧增，MySOL单机磁盘容量会撑爆，拆成多个数据库，磁盘使用率大大降低 并发连接支撑数据库的连接是有限的，在高并发场景下，大量请求访问数据库，MySQL单机无法承受，因此我们的项目采用微服务架构，通过将订单，用户，商品等不同模块都拆分成一个domain。并且将单个数据库也拆分成多个不同功能模块的数据库，或者是相同功能，放在多个库里分摊连接请求。 (同时可以采用缓存架构来降低访问) 分库分表的意义： 解决连接数瓶颈，解决数据增量，通常数据存量200万-300万，增量在单表50万就要考虑拆表了 (一开始可能很小，都设计成分库分表)因为拆分的库大多都是虚拟机上的，不会对服务器资源造成太大浪费，后续数量增多时，再迁徙物理机。 分库分表之后，数据分散，通过路由规则和负载均衡策略保证请求均衡打在不同库表上，不用担心会集中打在某个库表上造成数据库瘫痪。 本质上为:减少数据库压力，提高数据库效率，缩短查询时间 总结： 分库：解决qps过高，连接数不够用 分表：解决数据量过大，查询效率不高 分库分表：解决qps过高和查询效率不高 抽奖策略开发抽奖策略分类：场景：奖品A B C的中奖概率分别为：50%、30%、20% 总体概率：如果说A奖品被抽完了，那么B、C的中奖概率分别为60%和40% 单项概率：如果A奖品抽空后，B和C保持目前中奖概率，用户抽奖扔有20%中为A，因A库存抽空则结果展示为未中奖。为了运营成本，通常这种情况的使用的比较多 在库表设计上我们把抽奖需要的策略配置和策略明细，它们的关系是1vn。 DDD架构： model，用于提供vo、req、res 和 aggregates 聚合对象。 repository，提供仓储服务，其实也就是对Mysql、Redis等数据的统一包装。后面的话只在domain编写接口，实现类放到infrastructure层中。 service，是具体的业务领域逻辑实现层，在这个包下定义了algorithm抽奖算法实现和具体的抽奖策略包装 draw 层，对外提供抽奖接口。 算法设计：总体概率：分别把A、B、C对应的概率值转换成阶梯范围值，A=(0~0.2」、B=(0.2-0.5」、C=(0.5-1.0」，当使用随机数方法生成一个随机数后，与阶梯范围值进行循环比对找到对应的区域，匹配到中奖结果。 实现过程： 首先要从总的中奖列表中排除掉那些被排除掉的奖品，这些奖品会涉及到概率的值重新计算。 如果排除后剩下的奖品列表小于等于1，则可以直接返回对应信息 接下来就使用随机数工具生产一个100内的随值与奖品列表中的值进行循环比对，算法时间复杂度O(n) 单项概率：算法描述：单项概率算法不涉及奖品概率重新计算的问题，那么也就是说我们分配好的概率结果是可以固定下来的。好，这里就有一个可以优化的算法，不需要在轮训匹配O(n)时间复杂度来处理中奖信息，而是可以根据概率值存放到HashMap或者自定义散列数组进行存放结果，这样就可以根据概率值直接定义中奖结果，时间复杂度由O(n)降低到O(1)。这样的设计在一般电商大促并发较高的情况下，达到优化接口响应时间的目的。也就是说，现在只需要根据索引值来查找相对应的索引即可。 对于流程的分析，等代码开发完成之后进行总结。 今日总结： 完成抽奖活动策略表的设计与理解 学习分库分表的意义，以及数据库存储方式的B+树 学习第05节的视频和小册，并且理清楚相关的类 DAY04：今日任务： 代码撰写，将第05节代码进行编写 整理今天学到的知识，完成小傅哥的作业 梳理交互过程算法模块 梳理流程： （1）首先定义一个接口：IDrawAlgorithm，其中有三个方法 initRateTuple(Long strategyId, List&lt;AwardRateInfo&gt; awardRateInfoList) 1234567 定义了一个初始化的方法，也就是将每一个奖品都放置到100斐波那契散列之中，如下图这样 &lt;img src=&quot;Lottery/image-20230428151915087.png&quot; alt=&quot;image-20230428151915087&quot; style=&quot;zoom:33%;&quot; /&gt;- ``` isExistRateTuple 判断是否已经，做了数据初始化 ```randomDraw 12345678910111213 生成随机数，索引到对应的奖品信息返回结果，该方法在基础算法中不进行实现，在实际落地的算法中才加以实现（2）编写基础算法实现类BaseAlgorithm，并且重写initRateTuple和isExistRateTuple方法，还有hashIdx方法在这里先补一下关于斐波那契散列的相关知识- 哈希算法： ```java keyIndex = ((value + 1) * HASH_INCREMENT) &amp; (length - 1); //斐波那契（Fibonacci）散列法，计算哈希索引下标值；将100个奖品映射到128个空格中 //HASH_INCREMENT是常量0x61c88647；length表示数组初始化的长度，就是要定义多长的数组来放置100个奖品 算法实现： 首先定义相关的成员变量 1234567891011// 斐波那契散列增量，逻辑：黄金分割点：(√5 - 1) / 2 = 0.6180339887，Math.pow(2, 32) * 0.6180339887 = 0x61c88647private final int HASH_INCREMENT = 0x61c88647;// 数组初始化长度private final int RATE_TUPLE_LENGTH = 128;// 存放概率与奖品对应的散列结果，strategyId -&gt; rateTuple(数组长度为128，用来存放奖品的id)protected Map&lt;Long, String[]&gt; rateTupleMap = new ConcurrentHashMap&lt;&gt;();// 奖品区间概率值，strategyId -&gt; [awardId-&gt;begin、awardId-&gt;end](这个成员变量用于后面总体概率法的时候重新计算概率使用)protected Map&lt;Long, List&lt;AwardRateInfo&gt;&gt; awardRateInfoMap = new ConcurrentHashMap&lt;&gt;(); initRateTuple算法实现 1234567891011121314151617181920212223@Overridepublic void initRateTuple(Long strategyId, List&lt;AwardRateInfo&gt; awardRateInfoList) { // 保存奖品概率信息 awardRateInfoMap.put(strategyId, awardRateInfoList); // 创建奖品对应的斐波那契散列表 computeIfAbsent：如果没有就创建 String[] rateTuple = rateTupleMap.computeIfAbsent(strategyId, k -&gt; new String[RATE_TUPLE_LENGTH]); int cursorVal = 0; //按照概率，取出中奖概率对应的长度，即如果概率为0.2，那么rateVal为20 for (AwardRateInfo awardRateInfo : awardRateInfoList) { int rateVal = awardRateInfo.getAwardRate().multiply(new BigDecimal(100)).intValue(); // 循环填充概率范围值 // 计算hashindex来将对应位置填充为相应的AwardId for (int i = cursorVal + 1; i &lt;= (rateVal + cursorVal); i++) { rateTuple[hashIdx(i)] = awardRateInfo.getAwardId(); } cursorVal += rateVal; }} 重写isExistRateTuple 1234@Overridepublic boolean isExistRateTuple(Long strategyId) { return rateTupleMap.containsKey(strategyId);} 斐波那契散列法计算哈希索引下标值 12345678910/** * 斐波那契（Fibonacci）散列法，计算哈希索引下标值 * * @param val 值 * @return 索引 */protected int hashIdx(int val) { int hashCode = val * HASH_INCREMENT + HASH_INCREMENT; return hashCode &amp; (RATE_TUPLE_LENGTH - 1);} （3）编写单体概率实现方法（抽到库存为0的直接显示未中奖） 123456789101112131415161718192021@Component(&quot;singleRateRandomDrawAlgorithm&quot;)public class SingleRateRandomDrawAlgorithm extends BaseAlgorithm { @Override public String randomDraw(Long strategyId, List&lt;String&gt; excludeAwardIds) { // 获取策略对应的元祖 String[] rateTuple = super.rateTupleMap.get(strategyId); assert rateTuple != null; // 随机索引 int randomVal = new SecureRandom().nextInt(100) + 1; int idx = super.hashIdx(randomVal); // 返回结果 String awardId = rateTuple[idx]; // 库存为0则未中奖 if (excludeAwardIds.contains(awardId)) return &quot;未中奖&quot;; return awardId; }} SecureRandom方法与Random方法的区别是： SecureRandom 提供加密的强随机数生成器 (RNG)，要求种子必须是不可预知的，产生非确定性输出。 个人认为是产生相同的概率会减小 （4）编写总体概率实现方法（必中奖策略抽奖，排掉已经中奖的概率，重新计算中奖范围） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546@Component(&quot;defaultRateRandomDrawAlgorithm&quot;)public class DefaultRateRandomDrawAlgorithm extends BaseAlgorithm { @Override public String randomDraw(Long strategyId, List&lt;String&gt; excludeAwardIds) { // 此时场上还存在的中奖概率（如果场上产品只有A：0.2和B：0.5，则这个值为0.7，用于重新计算概率作为被除数） BigDecimal differenceDenominator = BigDecimal.ZERO; // 排除掉不在抽奖范围的奖品ID集合 List&lt;AwardRateInfo&gt; differenceAwardRateList = new ArrayList&lt;&gt;(); List&lt;AwardRateInfo&gt; awardRateIntervalValList = awardRateInfoMap.get(strategyId); for (AwardRateInfo awardRateInfo : awardRateIntervalValList) { String awardId = awardRateInfo.getAwardId(); if (excludeAwardIds.contains(awardId)) { continue; } differenceAwardRateList.add(awardRateInfo); differenceDenominator = differenceDenominator.add(awardRateInfo.getAwardRate()); } // 前置判断 if (differenceAwardRateList.size() == 0) return &quot;&quot;; if (differenceAwardRateList.size() == 1) return differenceAwardRateList.get(0).getAwardId(); // 获取随机概率值 SecureRandom secureRandom = new SecureRandom(); int randomVal = secureRandom.nextInt(100) + 1; // 循环获取奖品 String awardId = &quot;&quot;; int cursorVal = 0; for (AwardRateInfo awardRateInfo : differenceAwardRateList) { // awardRateInfo.getAwardRate() / differenceDenominator int rateVal = awardRateInfo.getAwardRate().divide(differenceDenominator, 2, BigDecimal.ROUND_UP).multiply(new BigDecimal(100)).intValue(); if (randomVal &lt;= (cursorVal + rateVal)) { awardId = awardRateInfo.getAwardId(); break; } cursorVal += rateVal; } // 返回中奖结果 return awardId; }} 算法实现模块实现流程（抽奖实现接口） （1）DrawConfig（提供一个配置类，将两种策略进行封装） 12345678910111213141516public class DrawConfig { @Resource private IDrawAlgorithm defaultRateRandomDrawAlgorithm; @Resource private IDrawAlgorithm singleRateRandomDrawAlgorithm; protected static Map&lt;Integer, IDrawAlgorithm&gt; drawAlgorithmMap = new ConcurrentHashMap&lt;&gt;(); @PostConstruct public void init() { drawAlgorithmMap.put(1, defaultRateRandomDrawAlgorithm); drawAlgorithmMap.put(2, singleRateRandomDrawAlgorithm); }} 解析@PostConstruct ： @PostConstruct该注解被用来修饰一个非静态的 void() 方法。被@PostConstruct修饰的方法会在服务器加载Servlet的时候运行，并且只会被服务器执行一次。@PostConstruct在构造函数之后执行，init() 方法之前执行。 该注解的方法在整个Bean初始化中的执行顺序： Constructor(构造方法) -&gt; @Autowired(依赖注入) -&gt; @PostConstruct(注释的方法) 使用该注解可以保证在init()之前将@Resource注解的对象已经注入 （2）DrawBase 123456789101112131415161718192021public class DrawBase extends DrawConfig { public void checkAndInitRateData(Long strategyId, Integer strategyMode, List&lt;StrategyDetail&gt; strategyDetailList) { // 表示策略1需要进行初始化；策略2不需要下面的初始化过程 if (1 != strategyMode) return; IDrawAlgorithm drawAlgorithm = drawAlgorithmMap.get(strategyMode); // 初始化 boolean existRateTuple = drawAlgorithm.isExistRateTuple(strategyId); if (existRateTuple) return; List&lt;AwardRateInfo&gt; awardRateInfoList = new ArrayList&lt;&gt;(strategyDetailList.size()); for (StrategyDetail strategyDetail : strategyDetailList) { awardRateInfoList.add(new AwardRateInfo(strategyDetail.getAwardId(), strategyDetail.getAwardRate())); } drawAlgorithm.initRateTuple(strategyId, awardRateInfoList); }} （3）IDrawExec 12345public interface IDrawExec { DrawResult doDrawExec(DrawReq req);} 提供一个方法接口 （4）DrawExecImpl 12345678910111213141516171819202122232425262728293031323334@Service(&quot;drawExec&quot;)public class DrawExecImpl extends DrawBase implements IDrawExec { private Logger logger = LoggerFactory.getLogger(DrawExecImpl.class); @Resource private IStrategyRepository strategyRepository; @Override public DrawResult doDrawExec(DrawReq req) { logger.info(&quot;执行策略抽奖开始，strategyId：{}&quot;, req.getStrategyId()); // 获取抽奖策略配置数据 StrategyRich strategyRich = strategyRepository.queryStrategyRich(req.getStrategyId()); Strategy strategy = strategyRich.getStrategy(); List&lt;StrategyDetail&gt; strategyDetailList = strategyRich.getStrategyDetailList(); // 校验和初始化数据 checkAndInitRateData(req.getStrategyId(), strategy.getStrategyMode(), strategyDetailList); // 根据策略方式抽奖 IDrawAlgorithm drawAlgorithm = drawAlgorithmMap.get(strategy.getStrategyMode()); String awardId = drawAlgorithm.randomDraw(req.getStrategyId(), new ArrayList&lt;&gt;()); // 获取奖品信息 Award award = strategyRepository.queryAwardInfo(awardId); logger.info(&quot;执行策略抽奖完成，中奖用户：{} 奖品ID：{} 奖品名称：{}&quot;, req.getuId(), awardId, award.getAwardName()); // 封装结果 return new DrawResult(req.getuId(), req.getStrategyId(), awardId, award.getAwardName()); }} 抽奖策略的实现 测试略 注意： 除了上面核心业务的开发以外，还有一些实体类和一些mapper方法需要编写 编写相关代码第一遍先仿照小傅哥的代码进行编写 DAY05:今日计划： 完成代码编写与测试 处理BUG：在按照上面的算法流程编写相应的代码，在测试的时候遇到了以下问题 首先在小傅哥的代码中，创建数据库和xml中查询都是直接命名为驼峰的，但是在我的代码中，并没有使用这种方式。而是使用的下划线方式来命名数据库列表的，因此造成了第一个问题就是找不到相关的列 当我把查询改为下划线格式的时候，发现始终只能查询到id，其他属性全都没有，这是由于mybatis没有配置驼峰映射，采取的第一种方式是在applicat.yml配置文件中加上 123mybatis: configuration: map-underscore-to-camel-case: true 结果报错 1Property 'configuration' and 'configLocation' can not specified with together 也就是上面的配置不能和下面的配置一起声明 123mybatis: mapper-locations: classpath:/mybatis/mapper/*.xml config-location: classpath:/mybatis/config/mybatis-config.xml 因此采取resultMap方式来进行配置，在每一个xml查询中都插入 123456789&lt;resultMap id=&quot;strategyDetailMap&quot; type=&quot;cn.spy.lottery.infrastructure.po.StrategyDetail&quot;&gt; &lt;id column=&quot;id&quot; property=&quot;id&quot;/&gt; &lt;result column=&quot;strategy_id&quot; property=&quot;strategyId&quot;/&gt; &lt;result column=&quot;award_id&quot; property=&quot;awardId&quot;/&gt; &lt;result column=&quot;award_count&quot; property=&quot;awardCount&quot;/&gt; &lt;result column=&quot;award_rate&quot; property=&quot;awardRate&quot;/&gt; &lt;result column=&quot;create_time&quot; property=&quot;createTime&quot;/&gt; &lt;result column=&quot;update_time&quot; property=&quot;updateTime&quot;/&gt;&lt;/resultMap&gt; 然后将下面的查询中的resultType改为resultMap的id即可 12345&lt;select id=&quot;queryStrategyDetailList&quot; parameterType=&quot;java.lang.Long&quot; resultMap=&quot;strategyDetailMap&quot;&gt; SELECT id, strategy_id, award_id, award_count, award_rate, create_time, update_time FROM strategy_detail WHERE strategy_id = #{strategyId}&lt;/select&gt; 注意： 这个问题改了很久，在这期间学会使用debug来不断进行排错，然后也要将自己的疑惑来及时百度来改正 DAY06: 将之前的算法以及调用流程使用模板模式处理 实现流程将配置类中的常量封装到常量枚举类之中 12345@PostConstructpublic void init(){ drawAlgorithmMap.put(Constants.StrategyMode.ENTIRETY.getCode(), defaultRateRandomDrawAlgorithm); drawAlgorithmMap.put(Constants.StrategyMode.SINGLE.getCode(), singleRateRandomDrawAlgorithm);} 优点： 使用这种方式不仅可以让后面的人更好的读懂代码，也可以方便以后加相关的策略 整体框架 核心部分：12345678910111213141516171819@Overridepublic DrawResult doDrawExec(DrawReq req) { // 1.获取抽奖策略 StrategyRich strategyRich = strategyRepository.queryStrategyRich(req.getStrategyId()); Strategy strategy = strategyRich.getStrategy(); // 2.校验和初始化数据 checkAndInitRateData(req.getStrategyId(), strategy.getStrategyMode(), strategyRich.getStrategyDetailList()); // 3.获取不在抽奖范围内的列表，包括：奖品库存为空、风控风险、临时调整等 List&lt;String&gt; excludeAwardIds = this.queryExcludeAwardIds(strategy.getStrategyId()); // 4.根据策略方式抽奖 String awardId = this.drawAlgorithm(req.getStrategyId(), drawAlgorithmMap.get(strategy.getStrategyMode()), excludeAwardIds); // 5. 包装中奖结果 return buildDrawResult(req.getuId(), req.getStrategyId(), awardId);} 模板模式就是要让过程尽可能的简洁明了，每一步都有固定的作用，关于每一步的实现逻辑方法封装到其他方法中进行实现。 对于不一样的部分在实现类中进行实现，相同的部分，比如结果封装则在抽象类中就加以实现 代码调试在写完代码使用单元测试进行代码调试的时候，为了测试库存不足时的返回情况，将库存都设置为0，遇到了这个问题 即Truncated incorrect DOUBLE value：类型不匹配问题 问题根源是，在单项概率实现策略里面 返回值为一个字符串，返回值类型有错误，应该返回null 此时测试通过 其它补充：dependencies和dependencymanagement的区别： Dependencies相对于dependencyManagement，所有生命在dependencies里的依赖都会自动引入，并默认被所有的子项目继承。 dependencyManagement里只是声明依赖，并不自动实现引入，因此子项目需要显示的声明需要用的依赖。如果不在子项目中声明依赖，是不会从父项目中继承下来的；只有在子项目中写了该依赖项，并且没有指定具体版本，才会从父项目中继承该项，并且version和scope都读取自父pom;另外如果子项目中指定了版本号，那么会使用子项目中指定的jar版本。 DAY07：今日计划： 按照 Mysql 库表使用规范调整表字段名称，如 activityId 调整为 activity_id，注意修改字符集类型 继续按照 P3C 标准，在 IDEA 插件 Alibaba Java Coding Guidelines 提醒下，修改所有涉及到的领域层、基础层中类、方法、字段的注释信息。 运用简单工厂设计模式，搭建发奖领域服务。介绍：定义一个创建对象的接口，让其子类自己决定实例化哪一个工厂类，工厂模式使其创建过程延迟到子类进行。 工厂模式：如果在代码中，使用if-else来控制使用哪种策略，这是一种方法，但是如果策略很多，在后期修改维护的时候会带来很大的不方便，很有可能会牵一发而动全身。因此尽可能使用设计模式来代替if-else，让每一个类都有自己的职责来进行业务处理。 整体流程 进行测试在测试中最初存在NPE的Bug，排查原因是发现，GoodsConfig这个配置类上面没有加入注解：@Configuration，也就表示在使用实现类的时候还未将GoodsConfig注入到容器中。两种解决方式： 在配置类上面加入注解@Configuration 在实现类集成GoodsConfig Day08：之前由于小论文进度较慢，今天开始赶进度 今日计划： 完成Lottery8节——活动领域的配置与状态模式 具体流程：1. 调整依赖 之前我们使用domain层调用infrastructure层，将仓储服务接口和实现都放在了领域层。现在我们要将infrastructure引入domain从而将仓储服务的实现放在infrastructure层，只在domain保留接口，从而符合规范。 记得要将原来的依赖注释掉 此时许多domain层的依赖丢失，解决办法是在domain中的model模块引入每一个service需要的实体类 在domain层引入spring-tx依赖，开启事务管理 2. 梳理流程2.1.1 活动部署模块只有一个简单的接口与实现 其中接口实现方法： 12345678910111213141516171819202122232425262728293031323334353637383940@Servicepublic class ActivityDeploy implements IActivityDeploy { private Logger logger = LoggerFactory.getLogger(ActivityDeploy.class); @Resource private IActivityRepository activityRepository; @Transactional(rollbackFor = Exception.class) @Override public void createActivity(ActivityConfigReq req) { logger.info(&quot;创建活动配置开始，activityId：{}&quot;, req.getActivityId()); ActivityConfigRich activityConfigRich = req.getActivityConfigRich(); try { // 添加活动配置 ActivityVO activity = activityConfigRich.getActivity(); activityRepository.addActivity(activity); // 添加奖品配置 List&lt;AwardVO&gt; awardList = activityConfigRich.getAwardList(); activityRepository.addAward(awardList); // 添加策略配置 StrategyVO strategy = activityConfigRich.getStrategy(); activityRepository.addStrategy(strategy); // 添加策略明细配置 List&lt;StrategyDetailVO&gt; strategyDetailList = activityConfigRich.getStrategy().getStrategyDetailList(); activityRepository.addStrategyDetailList(strategyDetailList); logger.info(&quot;创建活动配置完成，activityId：{}&quot;, req.getActivityId()); } catch (Exception e) { logger.error(&quot;创建活动配置失败，唯一索引冲突 activityId：{} reqJson：{}&quot;, req.getActivityId(), JSON.toJSONString(req), e); throw e; } } @Override public void updateActivity(ActivityConfigReq req) { // TODO 后期开发相关功能 }} 需要在dao和mapper中编写相应的添加语句 添加活动配置、添加奖品配置、添加策略配置、添加策略明细配置在一个事务中，所以加一个@Transactional注解 2.2.2 状态变更模块 对于这七种状态模式以及对应的方法，根据以下规则： 也可以看这张星友总结的： 使用设计模式中的状态模式，优化掉原本需要在各个流程节点中的转换使用 ifelse 的场景，这样操作以后也可以更加方便进行扩展。当然其实这里还可以使用如工作流的方式进行处理 3. 单元测试遇到的BUG： 首先是有两个@Service注解忘记加报的错误，NoSuchBeanFactory 第二个是，StrategyDetail中的awardName忘记写getter和setter方法，导致数据库一直没有相应的数据生成 4. 其它问题4.1 为什么仓储接口定义在领域层？为了领域层多聚合，如果仓储接口交给基础层实现，那么这个接口从使用上就不具备独立领域指责，其他模块都可以使用，最终就变得非常混乱了。将各自需要的接口定义在领域层，然后在基础层实现，可以避免混乱。 ID生成开发前须知 使用策略模式把三种生成ID的算法进行统一包装，由调用方决定使用哪种生成ID的策略。策略模式属于行为模式的一种，一个类的行为或算法可以在运行时进行更改 雪花算法本章节使用的是工具包 hutool 包装好的工具类，一般在实际使用雪花算法时需要做一些优化处理，比如支持时间回拨、支持手工插入、简短生成长度、提升生成速度等 而日期拼接和随机数工具包生成方式，都需要自己保证唯一性，一般使用此方式生成的ID，都用在单表中，本身可以在数据库配置唯一ID。那为什么不用自增ID，因为自增ID通常容易被外界知晓你的运营数据，以及后续需要做数据迁移到分库分表中都会有些麻烦 三种策略： 随机生成数 1234567@Componentpublic class RandomNumeric implements IIdGenerator { @Override public long nextId() { return Long.parseLong(RandomStringUtils.randomNumeric(11)); }} 雪花算法 1234567891011121314151617181920212223242526272829@Componentpublic class SnowFlake implements IIdGenerator { private Snowflake snowflake; @PostConstruct public void init() { // 0 ~ 31 位，可以采用配置的方式使用 long workerId; try { // 获取机器号 workerId = NetUtil.ipv4ToLong(NetUtil.getLocalhostStr()); } catch (Exception e) { workerId = NetUtil.getLocalhostStr().hashCode(); } // 将机器号限制在31以内，也就是五位以内 workerId = workerId &gt;&gt; 16 &amp; 31; long dataCenterId = 1L; snowflake = IdUtil.createSnowflake(workerId, dataCenterId); } @Override public synchronized long nextId() { // 调用Snowflake中生成id的方法 return snowflake.nextId(); }} Java 根据雪花算法生成ID的方式 上图中的工作机器id，其中高位5bit是数据中心ID，低位5bit是工作节点ID，做多可以容纳1024个节点。也就是可以部署1024个机器，一般没有这么高的需求。 对一些ID生成策略见processon 日期拼接随机数 123456789101112131415161718192021222324252627@Componentpublic class ShortCode implements IIdGenerator { /** * synchronized可以保证方法或者代码块在运行时，同一时刻只有一个方法可以进入到临界区， * 同时它还可以保证共享变量的内存可见性，Java中每一个对象都可以作为锁，这是synchronized实现同步的基础。 * @return */ @Override public synchronized long nextId() { Calendar calendar = Calendar.getInstance(); int year = calendar.get(Calendar.YEAR); int week = calendar.get(Calendar.WEEK_OF_YEAR); int day = calendar.get(Calendar.DAY_OF_WEEK); int hour = calendar.get(Calendar.HOUR_OF_DAY); // 打乱排序：2020年为准 + 小时 + 周期 + 日 + 三位随机数 StringBuilder idStr = new StringBuilder(); idStr.append(year - 2023); idStr.append(hour); idStr.append(String.format(&quot;%02d&quot;, week)); idStr.append(day); idStr.append(String.format(&quot;%03d&quot;, new Random().nextInt(1000))); return Long.parseLong(idStr.toString()); }} Day09:分布式路由组件spring.factories的作用 当启动类和配置类不在同一个包的时候，没有办法进行自动扫描，因此，在resources目录下新建一个META-INF的目录，然后新建一个spring.factories的文件，里面内容为： 1org.springframework.boot.autoconfigure.EnableAutoConfiguration=cn.bugstack.middleware.db.router.config.DataSourceAutoConfig 即可扫描相应的包 流程分析首先先来看整体的包结构 为什么要用分库分表： 由于业务体量较大，数据增长较快，所以需要把用户数据拆分到不同的库表中去，减轻数据库压力。 分库分表操作分类： 垂直拆分：指按照业务将表进行分类，分布到不同的数据库上，这样也就将数据的压力分担到不同的库上面。最终一个数据库由很多表的构成，每个表对应着不同的业务，也就是专库专用。 水平拆分：如果垂直拆分后遇到单机瓶颈，可以使用水平拆分。相对于垂直拆分的区别是：垂直拆分是把不同的表拆到不同的数据库中，而本章节需要实现的水平拆分，是把同一个表拆到不同的数据库中。如：user_001、user_002 涉及技术： AOP 切面拦截的使用，这是因为需要给使用数据库路由的方法做上标记，便于处理分库分表逻辑。 数据源的切换操作，既然有分库那么就会涉及在多个数据源间进行链接切换，以便把数据分配给不同的数据库。 数据库表寻址操作，一条数据分配到哪个数据库，哪张表，都需要进行索引计算。在方法调用的过程中最终通过 ThreadLocal 记录。 为了能让数据均匀的分配到不同的库表中去，还需要考虑如何进行数据散列的操作，不能分库分表后，让数据都集中在某个库的某个表，这样就失去了分库分表的意义。 设计实现1. DBRouter12345678@Documented@Retention(RetentionPolicy.RUNTIME)@Target({ElementType.TYPE, ElementType.METHOD})public @interface DBRouter { String key() default &quot;&quot;;} 其中： @Documented表示该注解将被包含在Javadoc中生成的文档中。 @Retention(RetentionPolicy.RUNTIME)指定该注解将在运行时可用，这意味着可以在程序运行时访问该注解信息。 @Target({ElementType.TYPE, ElementType.METHOD})指定了该注解的目标元素，可以应用于类和方法上。 public @interface DBRouter声明这是一个注解，注解名为DBRouter。 String key() default &quot;&quot;定义了一个名为key的属性，类型为字符串，并设置了一个默认值为空字符串，也就是后续调用这个组件的时候会传入一个属性参数 2. 解析路由配置 2.1 在配置类 1234@Configurationpublic class DataSourceAutoConfig implements EnvironmentAware { //} 2.1.1 数据源配置提取： 12345678910111213@Overridepublic void setEnvironment(Environment environment) { String prefix = &quot;router.jdbc.datasource.&quot;; dbCount = Integer.valueOf(environment.getProperty(prefix + &quot;dbCount&quot;)); tbCount = Integer.valueOf(environment.getProperty(prefix + &quot;tbCount&quot;)); String dataSources = environment.getProperty(prefix + &quot;list&quot;); for (String dbInfo : dataSources.split(&quot;,&quot;)) { Map&lt;String, Object&gt; dataSourceProps = PropertyUtil.handle(environment, prefix + dbInfo, Map.class); dataSourceMap.put(dbInfo, dataSourceProps); }} prefix，是数据源配置的开头信息，你可以自定义需要的开头内容。 dbCount、tbCount、dataSources、dataSourceProps，都是对配置信息的提取，并存放到 dataSourceMap 中便于后续使用。 其中PropertyUtil.handle()方法类为 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class PropertyUtil { private static int springBootVersion = 1; static { try { Class.forName(&quot;org.springframework.boot.bind.RelaxedPropertyResolver&quot;); } catch (ClassNotFoundException e) { springBootVersion = 2; } } /** * Spring Boot 1.x is compatible with Spring Boot 2.x by Using Java Reflect. * @param environment : the environment context * @param prefix : the prefix part of property key * @param targetClass : the target class type of result * @param &lt;T&gt; : refer to @param targetClass * @return T */ @SuppressWarnings(&quot;unchecked&quot;) public static &lt;T&gt; T handle(final Environment environment, final String prefix, final Class&lt;T&gt; targetClass) { switch (springBootVersion) { case 1: return (T) v1(environment, prefix); default: return (T) v2(environment, prefix, targetClass); } } private static Object v1(final Environment environment, final String prefix) { try { Class&lt;?&gt; resolverClass = Class.forName(&quot;org.springframework.boot.bind.RelaxedPropertyResolver&quot;); Constructor&lt;?&gt; resolverConstructor = resolverClass.getDeclaredConstructor(PropertyResolver.class); Method getSubPropertiesMethod = resolverClass.getDeclaredMethod(&quot;getSubProperties&quot;, String.class); Object resolverObject = resolverConstructor.newInstance(environment); String prefixParam = prefix.endsWith(&quot;.&quot;) ? prefix : prefix + &quot;.&quot;; return getSubPropertiesMethod.invoke(resolverObject, prefixParam); } catch (final ClassNotFoundException | NoSuchMethodException | SecurityException | InstantiationException | IllegalAccessException | IllegalArgumentException | InvocationTargetException ex) { throw new RuntimeException(ex.getMessage(), ex); } } private static Object v2(final Environment environment, final String prefix, final Class&lt;?&gt; targetClass) { try { Class&lt;?&gt; binderClass = Class.forName(&quot;org.springframework.boot.context.properties.bind.Binder&quot;); Method getMethod = binderClass.getDeclaredMethod(&quot;get&quot;, Environment.class); Method bindMethod = binderClass.getDeclaredMethod(&quot;bind&quot;, String.class, Class.class); Object binderObject = getMethod.invoke(null, environment); String prefixParam = prefix.endsWith(&quot;.&quot;) ? prefix.substring(0, prefix.length() - 1) : prefix; Object bindResultObject = bindMethod.invoke(binderObject, prefixParam, targetClass); Method resultGetMethod = bindResultObject.getClass().getDeclaredMethod(&quot;get&quot;); return resultGetMethod.invoke(bindResultObject); } catch (final ClassNotFoundException | NoSuchMethodException | SecurityException | IllegalAccessException | IllegalArgumentException | InvocationTargetException ex) { throw new RuntimeException(ex.getMessage(), ex); } }} 这个类的主要作用是在Spring Boot 1.x 和 2.x之间提供属性配置文件读取的统一接口，使得代码可以兼容这两个版本。在不同的Spring Boot版本中，读取属性配置文件的方式有所不同，而这个类通过使用Java的反射机制，根据不同的版本使用不同的方法读取属性配置文件，从而保证代码的兼容性。 2.2.2 创建数据源 12345678910111213@Beanpublic DataSource dataSource() { // 创建数据源 Map&lt;Object, Object&gt; targetDataSources = new HashMap&lt;&gt;(); for (String dbInfo : dataSourceMap.keySet()) { Map&lt;String, Object&gt; objMap = dataSourceMap.get(dbInfo); targetDataSources.put(dbInfo, new DriverManagerDataSource(objMap.get(&quot;url&quot;).toString(), objMap.get(&quot;username&quot;).toString(), objMap.get(&quot;password&quot;).toString())); } // 设置数据源 DynamicDataSource dynamicDataSource = new DynamicDataSource(); dynamicDataSource.setTargetDataSources(targetDataSources); return dynamicDataSource;} 这里是一个简化的创建案例，把基于从配置信息中读取到的数据源信息，进行实例化创建。 数据源创建完成后存放到 DynamicDataSource 中，它是一个继承了 AbstractRoutingDataSource 的实现类，这个类里可以存放和读取相应的具体调用的数据源信息 总结来说，DataSourceAutoConfig类的作用是获取到配置文件中的配置，并且创建了新的数据源，并且在另一个类中实现了1.x版本和2.x版本的兼容使用 3.切面拦截12345@Aspect@Component(&quot;db-router-point&quot;)public class DBRouterJoinPoint { //} 在 AOP 的切面拦截中需要完成；数据库路由计算、扰动函数加强散列、计算库表索引、设置到 ThreadLocal 传递数据源，整体案例代码如下： 1234567891011121314151617181920212223242526272829@Around(&quot;aopPoint() &amp;&amp; @annotation(dbRouter)&quot;)public Object doRouter(ProceedingJoinPoint jp, DBRouter dbRouter) throws Throwable { String dbKey = dbRouter.key(); if (StringUtils.isBlank(dbKey)) throw new RuntimeException(&quot;annotation DBRouter key is null！&quot;); // 计算路由 String dbKeyAttr = getAttrValue(dbKey, jp.getArgs()); int size = dbRouterConfig.getDbCount() * dbRouterConfig.getTbCount(); // 扰动函数 int idx = (size - 1) &amp; (dbKeyAttr.hashCode() ^ (dbKeyAttr.hashCode() &gt;&gt;&gt; 16)); // 库表索引 int dbIdx = idx / dbRouterConfig.getTbCount() + 1; int tbIdx = idx - dbRouterConfig.getTbCount() * (dbIdx - 1); // 设置到 ThreadLocal DBContextHolder.setDBKey(String.format(&quot;%02d&quot;, dbIdx)); DBContextHolder.setTBKey(String.format(&quot;%02d&quot;, tbIdx)); logger.info(&quot;数据库路由 method：{} dbIdx：{} tbIdx：{}&quot;, getMethod(jp).getName(), dbIdx, tbIdx); // 返回结果 try { return jp.proceed(); } finally { DBContextHolder.clearDBKey(); DBContextHolder.clearTBKey(); }} @Aspect 表示这是一个切面类 @Component(“db-router-point”) 表示这是一个Spring组件，名称为”db-router-point” @Pointcut(“@annotation(cn.bugstack.middleware.db.router.annotation.DBRouter)”) 表示定义一个切入点，通过@annotation指定对标注有@DBRouter注解的方法进行切入。 @Around(“aopPoint() &amp;&amp; @annotation(dbRouter)”) 表示定义环绕通知，在目标方法执行之前和之后都会执行，并且可以阻止目标方法的执行。这里通过@annotation(dbRouter)指定了切入点所在方法的DBRouter注解。 在doRouter方法中，首先获取DBRouter注解中的key值，并通过getAttrValue方法获取该值对应的参数值。接着，通过扰动函数计算出该key值对应的数据库和表的索引，将其设置到ThreadLocal中。最后，执行目标方法，无论是否抛出异常，都会执行finally中的代码，将ThreadLocal中的值清除。 需要注意的是，DBRouterJoinPoint类使用了@Autowired注解注入了一个DBRouterConfig类，这个类在前面我们已经讲过，是用来存储从配置文件中读取的数据库配置信息以及数据库和表的数量。 Day10:声明式事务领取活动领域开发目前的问题： 如果一个场景需要在同一个事务下，连续操作不同的DAO操作，那么就会涉及到在 DAO 上使用注解 @DBRouter(key = “uId”) 反复切换路由的操作。虽然都是一个数据源，但这样切换后，事务就没法处理了。 解决 这里选择了一个较低的成本的解决方案，就是把数据源的切换放在事务处理前，而事务操作也通过编程式编码进行处理。具体可以参考 db-router-spring-boot-starter 源码 梳理流程本次开发主要使用模板模式进行开发，其中抽象类BaseActivityPartake作为一个模板抽象类，在ActivityPartakeImpl进行开发实现，ActivityPartakeSupport是数据库支撑类的开发 个人认为还存在的问题： 如果在领取活动信息的时候出现错误，那么不会进行回滚，库存白白减1 但是按照小傅哥说法，宁愿减去也不能发生超支的错误，之后会进行改进 其他问题 编程式事务处理 编程式事务处理是指在编程时，通过代码实现事务的提交、回滚等操作。 在进行编程式的事务管理时，只需要将需要事务处理的方法，通过参数 TransactionCallback 传递给TransactionTemplate.execute () 方法，就可以实现事务的处理。 相对于声明式事务，编程式事务使用 TransactionTemplate 或者直接使用底层的PlatformTransactionManager 实现事务。对于编程式事务 Spring 比较推荐使用TransactionTemplate 来对事务进行管理 12345678910111213141516171819202122232425262728@Override protected Result grabActivity(PartakeReq partake, ActivityBillVO bill) { try { dbRouter.doRouter(partake.getuId()); // 切换数据源在事务处理之前 return transactionTemplate.execute(status -&gt; { try { // 扣减个人已参与次数 int updateCount = userTakeActivityRepository.subtractionLeftCount(bill.getActivityId(), bill.getActivityName(), bill.getTakeCount(), bill.getUserTakeLeftCount(), partake.getuId(), partake.getPartakeDate()); if (0 == updateCount) { status.setRollbackOnly(); logger.error(&quot;领取活动，扣减个人已参与次数失败 activityId：{} uId：{}&quot;, partake.getActivityId(), partake.getuId()); return Result.buildResult(Constants.ResponseCode.NO_UPDATE); } // 插入领取活动信息 Long takeId = idGeneratorMap.get(Constants.Ids.SnowFlake).nextId(); userTakeActivityRepository.takeActivity(bill.getActivityId(), bill.getActivityName(), bill.getTakeCount(), bill.getUserTakeLeftCount(), partake.getuId(), partake.getPartakeDate(), takeId); } catch (DuplicateKeyException e) { status.setRollbackOnly(); logger.error(&quot;领取活动，唯一索引冲突 activityId：{} uId：{}&quot;, partake.getActivityId(), partake.getuId(), e); return Result.buildResult(Constants.ResponseCode.INDEX_DUP); } return Result.buildSuccessResult(); }); } finally { dbRouter.clear(); } } 编程式事务与声明式事务处理的区别 编程式： 1234567891011Connection conn = dataSource.getConnection();try { conn.setAutoCommit(false); // 执行一些数据库操作 conn.commit();} catch (SQLException ex) { conn.rollback();} finally { conn.setAutoCommit(true); conn.close();} 声明式 12345@Service@Transactionalpublic void createUser(User user) { // 实现业务} 在编程式事务中，我们需要手动开启、提交、回滚事务;而在声明式事务中，我们只需要在方法上添加@Transactiona注解即可。这样就可以将操作与事务规则进行解耦，使得代码更加简洁易懂。 声明式事务和编程式事务各有优缺点。 声明式事务的 优点是:代码简洁，易于维护，不侵入业务逻辑，使得代码更加清晰，可以通过注解或配置文件来实现，使用方便。 缺点是:不够灵活，无法满足一些特殊需求，不利于调试，出现问题难以定位。 编程式事务的 优点是: 灵活性高，可以满足各种特殊需求，便于调试，出现问题容易定位。 缺点是:代码复杂，维护困难，侵入业务逻辑，使得代码不够清晰。 因此，在选择使用哪种事务管理方式时，需要根据具体情况进行选择这样看下来，其实在一些小项目里面，可能使用声明式事务会是更好的选择。在这个例子中不能使用声明式事务是因为: 如果一个场景需要在同一个事务下，连续操作不同的DAO操作，那么就会涉及到在 DAO 上使用注解 @DBRouter(key =”uld”)反复切换路由的操作。虽然都是一个数据源，但这样切换后，事务就没法处理了。 看一个例子: 我要插入两个uid，分别为uid=1和uid=2，在一般情况下，用声明式事务可以解决问题: insert两次然后commit即可: 但在这种分库分表的情况下，我现在插入一个uld=1，这条记录放在db01，uid=2的记录放在db02，在这个过程中会发生数据源的切换，切换了数据源，但是还没有提交commit，那么数据就会丢失。 总结：在分库分表的情况下，建议使用编程式事务。因为声明式事务是通过注解或配置文件来实现的，无法动态地确定开启哪个数据库实例的事务。而在分库分表时，需要动态地确定开启哪个数据库实例的事务，因此需要使用编程式事务。此外，编程式事务可以更好地控制事务的边界，保证数据的一致性。 在应用层编排抽奖过程开发过程 分别在两个分库的表 lottery_01.user_take_activity、lottery_02.user_take_activity 中添加 state【活动单使用状态 0未使用、1已使用】 状态字段，这个状态字段用于写入中奖信息到 user_strategy_export_000~003 表中时候，两个表可以做一个幂等性的事务。同时还需要加入 strategy_id 策略ID字段，用于处理领取了活动单但执行抽奖失败时，可以继续获取到此抽奖单继续执行抽奖，而不需要重新领取活动。其实领取活动就像是一种活动镜像信息，可以在控制幂等反复使用 所谓的幂等性，是分布式环境下的一个常见问题，一般是指我们在进行多次操作时，所得到的结果是一样的，即多次运算结果是一致的。 也就是说，用户对于同一操作，无论是发起一次请求还是多次请求，最终的执行结果是一致的，不会因为多次点击而产生副作用。 在 lottery-application 模块下新增 process 包用于流程编排，其实它也是 service 服务包是对领域功能的封装，很薄的一层。那么定义成 process 是想大家对流程编排有个概念，一般这一层的处理可以使用可视化的流程编排工具通过拖拽的方式，处理这部分代码的逻辑。 学习本章记得更新分支下的最新SQL语句，另外本章节还连带引入了需要MQ、Worker的场景，后续开发到这些功能的时候，会继续完善 完整流程 抽奖整个活动过程的流程编排，主要包括：对活动的领取、对抽奖的操作、对中奖结果的存放，以及如何处理发奖，对于发奖流程我们设计为MQ触发，后续再补全这部分内容。 对于每一个流程节点编排的内容，都是在领域层开发完成的，而应用层只是做最为简单的且很薄的一层。其实这块也很符合目前很多低代码的使用场景，通过界面可视化控制流程编排，生成代码 算法流程 本章出现BUG的几个位置 字段在实体类和数据库表中添加之后在查询中忘记查、在resultMap中忘记加入映射 查询是否有领取但未执行的时候没有加入@DBRouter，导致无法扫描到其他表 Day11：规则引擎量化人群参与活动 增加规则引擎开发需要的相关的配置类表：rule_tree、rule_tree_node、rule_tree_node_line rule_tree 决策树基本信息 rule_tree_node 决策树各节点信息 rule_tree_node_line 决策树树枝信息 运用组合模式搭建规则引擎领域服务，包括：logic 逻辑过滤器、engine 引擎执行器 修改 lottery-infrastructure 基础层中仓储实现类更为合适的的注解为 @Repository 包括： ActivityRepository、RuleRepository、StrategyRepository、UserTakeActivityRepository 梳理流程 Filter主要是用来进行规则过滤，也就是根据当前的matter获取到下一个节点 Engine主要是作为规则引擎，也就是根据过滤条件等来获取到最终的节点信息 门面接口封装和对象转换以 DDD 设计的结构框架，在接口层和应用层需要做防污处理，也就是说不能直接把应用层、领域层的对象直接暴露处理，因为暴露出去可能会随着业务发展的过程中不断的添加各类字段，从而破坏领域结构。那么就需要增加一层对象转换，也就有了 vo2dto、dto2vo 的操作。但这些转换的字段又基本都是重复的，在保证性能的情况下，一些高并发场景就只会选择手动编写 get、set，但其实也有很多其他的方式，转换性能也不差，这里列举一下。 本章节总体而言完成了三个工作： 完成application应用层拼接量化规则操作，返回可以抽奖的活动id 在接口层添加对象转换，完成防污处理 提供rpc接口，分别实现按照id抽奖以及按照量化人群决策进行抽奖两种模式 Day12搭建MQ消息组件Kafka服务环境使用MQ消息组件的原因： 当用户发起抽奖，如果我们一条链路进行执行的话就会造成卡顿的现象，因此需要异步调用。先告诉用户中奖了，之后再进行别的操作 windows配置kafka首先在官网下载稳定版本的kafka并且进行解压，在解压后的目录下使用终端进行打开 启动zookeeper： 1bin/windows/zookeeper-server-start.bat config/zookeeper.properties 关闭zookeeper： 1bin/windows/zookeeper-server-stop.bat config/zookeeper.properties 启动kafka： 1bin/windows/kafka-server-start.bat config/server.properties 关闭kafka： 1bin/windows/kafka-server-stop.bat config/server.properties 创建主题： 1bin/windows/kafka-topics.bat --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic Hello-Kafka 查看主题： 1bin/windows/kafka-topics.bat --list --zookeeper localhost:2181 发送消息： 1bin/windows/kafka-console-producer.bat --broker-list localhost:9092 --topic Hello-Kafka 接收消息： 1bin/windows/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic Hello-Kafka --from-beginning 使用MQ解耦抽奖发货流程大体流程如下： 在ActivityProcessImpl中的doDrawProcess方法中调用kafkaProducer.sendLotteryInvoice(invoiceVO);发送MQ，触发发奖流程 在LotteryInvoiceListener中进行监听消费，主要完成以下操作 判断消息是否存在 处理MQ消息（转换对象，获取发送奖品工厂执行发奖，打印日志，消息消费完成） Day13：xxl-job完成活动状态扫描引入过程 下载：2.3.0 打开：使用 IDEA 打开下载的 xxl-job 导表：把 xxl-job 中的 doc\\db\\tables_xxl_job.sql 导入到自己的数据库中 启动：xxl-job-admin 是用于管理分布式任务调度的后台，一切配置完后，启动 xxl-job-admin 另外你需要配置 application.properties 修改数据库链接参数和日志文件夹 案例：xxl-job-executor-samples 是一组job任务案例，运行后可以在分布式任务调度后台管理任务，配置、启动、关闭 核心：xxl-job-core 执行启动 启动前检查好 application.properties 中的端口号 确保数据库表已经初始化完成，并修改 application.properties 中数据库链接信息 修改 logback.xml 日志打印目录，否则日志找不到会报错 像启动 SpringBoot 程序一样，启动这个 xxl-job 任务调度后台，如果你是部署到云服务器，则需要打包构架部署 访问页面 地址：http://localhost:7397/xxl-job-admin 我修改端口为7397了，你按照自己的端口就可以 账号：admin 密码：123456 Day14：扫描库表补偿发货单MQ消息 我们的任务流程，完成的就是整个抽奖活动中，关于中奖结果落库后，进行MQ后。出现问题时，进行补偿消息发送处理的部分。 在MQ消息补偿的过程中，会把发送失败的消息和迟迟没有发送的消息，都进行补偿，已保障全流程的可靠性。 目前流程启动流程 启动 zk、kafka，总怕你忘记，如果你已经云服务器了，可以先部署上去。 启动 xxl-job 启动 lottery 使用debug模式，方便验证 修改库表中，user_strategy_export_001~004 中任意一个表的 MQ 状态为 2 表示发送 MQ 失败 Day15：安装宝塔linux 在官网上获得centos的命令行在虚拟机中运行即可 外网面板地址: https://101.35.210.50:28478/a612fca3 内网面板地址: https://10.0.4.11:28478/a612fca3 username: p7mm5wky password: c587d4e6 遇到的问题： 最初在自己的虚拟机上面进行安装，发现无法获取连接 原因： 购买云服务器进行配置安装 本章内容： 在云服务器搭建 Redis 服务，这样可以更加方便的使用 在抽奖系统中引入 Redis 模块，优化用户参与抽奖活动。因为只要有大量的用户参与抽奖，那么这个就属于秒杀场景。所以需要使用 Redis 分布式锁的方式来处理集中化库存扣减的问题，否则在 TPS 达到1k-2k，就会把数据库拖垮。 在设计秒杀流程时，优化锁的颗粒度力度，不要把锁直接放到活动编号上，这样在极端临界情况下会出现秒杀解锁失败，导致库存有剩余但不能下单的情况。所以需要增加锁的颗粒度，以滑动库存剩余编号的方式进行加锁，例如 100001_1、100001_2、100001_3，以此类推，具体看代码实现。 增加缓存扣减库存后，发送 MQ 消息进行异步更新数据库中活动库存，做最终数据一致性处理。这一部分如果你的系统并发体量较大，还需要把 MQ 的数据不要直接对库更新，而是更新到缓存中，再由任务最阶段同步，以此减少对数据库表的操作 滑块库存锁设计 如图所示，即使是使用 Redis 分布式锁，我们也不希望把锁的颗粒度放的太粗，否则还是会出现活动有库存但不能秒杀，提示“活动过于火爆” 那么我们就需要按照活动编号把库存锁的颗粒度缩小，实际操作也并不复杂，只是把活动ID+库存扣减后的值一起作为分布式锁的Key，这样就缩小了锁的颗粒度。 抽奖系统总体流程开发","link":"/2023/06/20/Lottery/"},{"title":"关于 Servlet 的学习","text":"学习目标： 理解并掌握 Servlet 的继承关系 了解 Servlet 的生命周期 了解 HTTP 协议与 Session 会话 1. 设置编码​ tomcat8之前，设置编码： 1234567891011get请求方式： //get方式目前不需要设置编码（基于tomcat8） //如果是get请求发送的中文数据，转码稍微有点麻烦（tomcat8之前） String fname = request.getParameter(&quot;fname&quot;); //1.将字符串打散成字节数组 byte[] bytes = fname.getBytes(&quot;ISO-8859-1&quot;); //2.将字节数组按照设定的编码重新组装成字符串 fname = new String(bytes,&quot;UTF-8&quot;);post请求方式： request.setCharacterEncoding(&quot;UTF-8&quot;); ​ tomcat8开始，设置编码，只需要针对post方式 1request.setCharacterEncoding(&quot;UTF-8&quot;); ​ 注意： 需要注意的是，设置编码(post)这一句代码必须在所有的获取参数动作之前 2.Servlet的继承关系 - 重点查看的是服务方法（service()） 继承关系javax.servlet.Servlet接口 javax.servlet.GenericServlet抽象类 javax.servlet.http.HttpServlet抽象子类 相关方法javax.servlet.Servlet接口: void init(config) - 初始化方法 void service(request,response) - 服务方法 void destory() - 销毁方法 javax.servlet.GenericServlet抽象类：void service(request,response) - 仍然是抽象的 javax.servlet.http.HttpServlet 抽象子类：void service(request,response) - 不是抽象的 String method = req.getMethod(); 获取请求的方式 各种if判断，根据请求方式不同，决定去调用不同的do方法 1234567if (method.equals(&quot;GET&quot;)) { this.doGet(req,resp);} else if (method.equals(&quot;HEAD&quot;)) { this.doHead(req, resp);} else if (method.equals(&quot;POST&quot;)) { this.doPost(req, resp);} else if (method.equals(&quot;PUT&quot;)) { 在HttpServlet这个抽象类中，do方法都差不多: 123456789protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { String protocol = req.getProtocol(); String msg = lStrings.getString(&quot;http.method_get_not_supported&quot;); if (protocol.endsWith(&quot;1.1&quot;)) { resp.sendError(405, msg); } else { resp.sendError(400, msg); }} 3.小结 继承关系： HttpServlet -&gt; GenericServlet -&gt; Servlet Servlet中的核心方法： init() , service() , destroy() 服务方法： ​ 当有请求过来时，service方法会自动响应（其实是tomcat容器调用的）​ 在HttpServlet中我们会去分析请求的方式：到底是get、post、head还是delete等等​ 然后再决定调用的是哪个do开头的方法​ 那么在HttpServlet中这些do方法默认都是405的实现风格-要我们子类去实现对应的方法，否则默认会报405错误 因此，我们在新建Servlet时，我们才会去考虑请求方法，从而决定重写哪个do方法 4.Servlet的生命周期1） 生命周期：从出生到死亡的过程就是生命周期。对应Servlet中的三个方法：init(),service(),destroy()2） 默认情况下： 第一次接收请求时，这个Servlet会进行实例化(调用构造方法)、初始化(调用init())、然后服务(调用service()) 从第二次请求开始，每一次都是服务 当容器关闭时，其中的所有的servlet实例会被销毁，调用销毁方法3） 通过案例我们发现： ​ Servlet实例tomcat只会创建一个，所有的请求都是这个实例去响应。 ​ 第一次请求时，tomcat才会去实例化，初始化，然后再服务。这样的好处是什么？ 提高系统的启动速度 。 这样的缺点是什么？ 第一次请求时，耗时较长。 ​ 因此得出结论： 如果需要提高系统的启动速度，当前默认情况就是这样。如果需要提高响应速度，我们应该设置Servlet的初始化时机。4）Servlet的初始化时机： ​ 默认是第一次接收请求时，实例化，初始化​ 可以通过来设置servlet启动的先后顺序,数字越小，启动越靠前，最小值05） Servlet在容器中是：单例的、线程不安全的 单例：所有的请求都是同一个实例去响应 不安全：一个线程需要根据这个实例中的某个成员变量值去做逻辑判断。但是在中间某个时机，另一个线程改变了这个成员变量的值，从而导致第一个线程的执行路径发生了变化 ​ （线程不安全就是说在一个线程操作的过程中，另一个线程将共享域中的数据做了修改，导致访问结果发生错误的过程；举例来说，一个人去上厕所发现里面有纸，然后他就往里走，这时候有一个人把纸拿走了） 我们已经知道了servlet是线程不安全的，给我们的启发是： 尽量的不要在servlet中定义成员变量。如果不得不定义成员变量，那么不要去：①不要去修改成员变量的值 ②不要去根据成员变量的值做一些逻辑判断 5.HTTP协议1） Http 称之为 超文本传输协议 2） Http是无状态的 3） Http请求响应包含两个部分：请求和响应 请求请求包含三个部分： 1.请求行 ； 2.请求消息头 ； 3.请求主体 请求行 作用：展示当前请求的最基本信息 POST /dynamic/target.jsp HTTP/1.1 包含三个信息： 1. 请求的方式 ； 2.请求的URL ； 3.请求的协议（一般都是HTTP1.1） 请求消息头 包含了很多客户端需要告诉服务器的信息，比如：我的浏览器型号、版本、我能接收的内容的类型、我给你发的内容的类型、内容的长度等等 作用：通过具体的参数对本次请求进行详细的说明 格式：键值对，键和值之间使用冒号隔开 相对比较重要的请求消息头： 请求体 作用：作为请求的主体，发送数据给服务器。具体来说其实就是POST请求方式下的请求参数。 三种情况： get方式，没有请求体，但是有一个queryString post方式，有请求体，form data json格式，有请求体，request payload 格式： from data 含义：当前请求体是一个表单提交的请求参数。 查看源码后，发现格式如下： username=tom&amp;password=123456 每一组请求参数是一个键值对 键和值中间是等号 键值对之间是&amp;号 Request Payload 含义：整个请求体以某种特定格式来组织数据，例如JSON格式。 响应响应也包含三本： 1. 响应行 ； 2.响应头 ； 3.响应体 响应行包含三个信息：1.协议 2.响应状态码(200) 3.响应状态(ok) 响应头：包含了服务器的信息；服务器发送给浏览器的信息（内容的媒体类型、编码、内容长度等） 响应体：响应的实际内容（比如请求add.html页面时，响应的内容就是&lt;form….） ①响应状态行 HTTP/1.1 200 OK HTTP协议版本 响应状态码 响应状态的说明文字 ②响应消息头 响应体的说明书。 服务器端对浏览器端设置数据，例如：服务器端返回Cookie信息。 名称 功能 Content-Type 响应体的内容类型 Content-Length 响应体的内容长度 Set-Cookie 服务器返回新的Cookie信息给浏览器 location 在重定向的情况下，告诉浏览器访问下一个资源的地址 ③响应体 服务器返回的数据主体，有可能是各种数据类型。 HTML页面 图片 视频 以下载形式返回的文件 CSS文件 JavaScript文件 ④响应状态码 作用：以编码的形式告诉浏览器当前请求处理的结果 状态码 含义 200 服务器成功处理了当前请求，成功返回响应 302 重定向 400 [SpringMVC特定环境]请求参数问题 403 没有权限 404 找不到目标资源 405 请求方式和服务器端对应的处理方式不一致 406 [SpringMVC特定环境]请求扩展名和实际返回的响应体类型不一致 50X 服务器端内部错误，通常都是服务器端抛异常了 404产生的具体原因： 访问地址写错了，确实是没有这个资源 访问了WEB-INF目录下的资源 Web应用启动的时候，控制台已经抛出异常，导致整个Web应用不可用，访问任何资源都是404 服务器端缓存 6.Session会话1） Http是无状态的 HTTP 无状态 ：服务器无法判断这两次请求是同一个客户端发过来的，还是不同的客户端发过来的 无状态带来的现实问题：第一次请求是添加商品到购物车，第二次请求是结账；如果这两次请求服务器无法区分是同一个用户的，那么就会导致混乱 通过会话跟踪技术来解决无状态的问题。 2） 会话跟踪技术 客户端第一次发请求给服务器，服务器获取session，获取不到，则创建新的，然后响应给客户端 下次客户端给服务器发请求时，会把sessionID带给服务器，那么服务器就能获取到了，那么服务器就判断这一次请求和上次某次请求是同一个客户端，从而能够区分开客户端 常用的API： 123456789request.getSession() -&gt; 获取当前的会话，没有则创建一个新的会话request.getSession(true) -&gt; 效果和不带参数相同request.getSession(false) -&gt; 获取当前会话，没有则返回null，不会创建新的session.getId() -&gt; 获取sessionIDsession.isNew() -&gt; 判断当前session是否是新的session.getMaxInactiveInterval() -&gt; session的非激活间隔时长，默认1800秒session.setMaxInactiveInterval()session.invalidate() -&gt; 强制性让会话立即失效.... 3） session保存作用域 session保存作用域是和具体的某一个session对应的 常用的API： 123void session.setAttribute(k,v)Object session.getAttribute(k)void removeAttribute(k) 7.服务器内部转发以及客户端重定向1） 服务器内部转发 : request.getRequestDispatcher(“…”).forward(request,response); 一次请求响应的过程，对于客户端而言，内部经过了多少次转发，客户端是不知道的 地址栏没有变化 2） 客户端重定向： response.sendRedirect(“….”); 两次请求响应的过程。客户端肯定知道请求URL有变化 地址栏有变化 8.DispatcherServlet首先我们构建的代码结构如图 如果这样构建servlet的话，结构过于复杂，因此对其进行优化 如果这样构建servlet，如果还存在与FruitServlet并列的Servlet的话也会产生较为复杂的系统，因此采用一个中央处理器，即DispatcherServlet","link":"/2022/12/25/Servlet/"},{"title":"代码随想录刷题笔记——数组、链表、哈希表、字符串篇","text":"本篇内容： 数组、链表、哈希表、字符串相关知识与结构 代码随想录相关题目总结（主要是有难度的题目） 刷题过程中的一些个人思考 数组篇1.二分查找二分查找是查找中降低复杂度，提高系统性能中最常用也是最重要的方法之一。在这里我们主要关注两种二分查找的形式 第一种写法，我们定义 target 是在一个在左闭右闭的区间里，也就是[left, right] （这个很重要非常重要）。 区间的定义这就决定了二分法的代码应该如何写，因为定义target在[left, right]区间，所以有如下两点： while (left &lt;= right) 要使用 &lt;= ，因为left == right是有意义的，所以使用 &lt;= if (nums[middle] &gt; target) right 要赋值为 middle - 1，因为当前这个nums[middle]一定不是target，那么接下来要查找的左区间结束下标位置就是 middle - 1 如果说定义 target 是在一个在左闭右开的区间里，也就是**[left, right)** ，那么二分法的边界处理方式则截然不同。 有如下两点： while (left &lt; right)，这里使用 &lt; ,因为left == right在区间[left, right)是没有意义的 if (nums[middle] &gt; target) right 更新为 middle，因为当前nums[middle]不等于target，去左区间继续寻找，而寻找区间是左闭右开区间，所以right更新为 middle，即：下一个查询区间不会去比较nums[middle] 个人一般习惯第一种写法，主要注意第一种写法的话循环条件 left &lt;= right 以及循环过程中要对middle进行+-1操作 2.移除元素题目要求：将数组中所有等于 val 的元素移除。 一般对于这种题目来说，最好不要创建一个新数组用来接收并返回最终结果，这样会白白增加空间复杂度，浪费资源。通常采用双指针的方式来完成，下面介绍两种双指针： 快慢双指针。顾名思义，一个指针快一个指针慢，快的指针用于遍历整个数组，慢的指针用于接收符合条件的元素。即当 fastIndex 处元素等于 val 的时候，fastIndex++，否则将 fastIndex 处的元素赋给 slowIndex 。 双向指针。顾名思义，一个指针在最左边，一个指针在最右边。首先使用 while 循环保证右边的指针对应的元素不等于 val ，当 left 对应的元素等于 val 的时候，将 right 对应的元素赋给 left 处。 快慢双指针 1234567891011121314151617181920class Solution { public int removeElement(int[] nums, int val) { // 双向指针法 int left = 0, right = nums.length - 1; while (right &gt;= 0 &amp;&amp; nums[right] == val) { right--; } while (left &lt;= right) { if (nums[left] == val) { nums[left] = nums[right]; right--; } left++; while (nums[right] == val) { right--; } } return left; }} 双向指针 123456789101112class Solution { public int removeElement(int[] nums, int val) { // 快慢指针 int slowIndex = 0; for (int fastIndex = 0; fastIndex &lt; nums.length; fastIndex++) { if(nums[fastIndex] != val) { nums[slowIndex++] = nums[fastIndex]; } } return slowIndex; }} 3.长度最小的子数组给定一个含有 n 个正整数的数组和一个正整数 s ，找出该数组中满足其和 ≥ s 的长度最小的 连续 子数组，并返回其长度。如果不存在符合条件的子数组，返回 0。 本题是滑动窗口解法的经典例题。基本思想就是先找到能满足和 &gt;=s 的数组，然后进行缩窗口，即判断将左边的元素删去是否满足 &gt;=s 这个条件，如果不满足则继续将窗口右指针向右移动。 代码示例 12345678910111213141516class Solution { // 滑动窗口 public int minSubArrayLen(int s, int[] nums) { int left = 0; int sum = 0; int result = Integer.MAX_VALUE; for (int right = 0; right &lt; nums.length; right++) { sum += nums[right]; while (sum &gt;= s) { result = Math.min(result, right - left + 1); sum -= nums[left++]; } } return result == Integer.MAX_VALUE ? 0 : result; }} 4.螺旋矩阵给你一个正整数 n ，生成一个包含 1 到 n2 所有元素，且元素按顺时针顺序螺旋排列的 n x n 正方形矩阵 matrix 。 个人认为这道题目与算法无关，主要就是将向右、向下、向左、向上四个过程按顺序进行模拟即可。注意以下两个易错点： 循环判断的条件满足 loop(已经螺旋的圈数) &lt; n / 2 如果是奇数，那么最中间的那个点要在最后加上（循环不到的位置） 代码示例 1234567891011121314151617181920212223242526272829303132class Solution { public int[][] generateMatrix(int n) { int i,j; int loop = 0; // 定义循环次数 int[][] res = new int[n][n]; // 定义最终二维数组 int start = 0; // 定义起始位置 int count = 1; // 定义填充的数字 while (loop++ &lt; n / 2) { // 定义从左到右填充 for (j = start; j &lt; n - loop; j++) { res[start][j] = count++; } // 定义从上到下填充 for (i = start; i &lt; n - loop; i++) { res[i][j] = count++; } // 定义从右到左填充 for (; j &gt;= loop; j--) { res[i][j] = count++; } // 定义从下到上填充 for (; i &gt;= loop; i--) { res[i][j] = count++; } start++; } if (n % 2 == 1) { res[start][start] = n*n; } return res; }} 5.总结数组常用的几个方法： 二分查找 双指针 滑动窗口 总体来说难度较小，但是与后面的数据结构等结合还是具有一定的难度的。 链表篇基础知识可以看数据结构相关资料 1.删除链表元素给你一个链表的头节点 head 和一个整数 val ，请你删除链表中所有满足 Node.val == val 的节点，并返回 新的头节点 。 对于这种题目或者说链表的大部分题目，个人都习惯于创建一个虚拟节点，好处主要在于当需要对头结点进行判断的时候，不需要进行额外的操作。本题难度较低，直接附代码。 示例代码 12345678910111213141516171819class Solution { public ListNode removeElements(ListNode head, int val) { if (head == null) { return null; } ListNode dummy = new ListNode(-1, head); ListNode pre = dummy; ListNode cur = head; while (cur != null) { if (cur.val == val) { pre.next = cur.next; } else { pre = cur; } cur = cur.next; } return dummy.next; }} 2.设计链表本题主要完成设计一条链表，包括以下五个功能： 获取链表第 index 个节点的数值 在链表的最前面插入一个节点 在链表的最后面插入一个节点 在链表第index个节点前面插入一个节点 删除链表的第index个节点 五个需求都可以使用遍历的方法实现，实现过程简单，在此不加以赘述。需要关注的易错点是，在设计链表的时候，维护一个 size 参数，在添加元素的时候进行 size++，在删除元素的时候进行 size–。依次来可以判断 index 参数是否超出界限。 3.翻转链表题目要求：将一个链表进行翻转 本题目比较简单，但是最好不要引入新的空间，加大内存消耗。在原有的链表上进行翻转处理。 实现过程： 维护一个双指针，pre 和 cur 分别代表前一个和后一个，并且定义一个临时节点 temp 保存 cur 的下一个节点。之后将 cur 指向 pre ，再将 temp 赋给 cur 即可。 代码示例 12345678910111213class Solution { public ListNode reverseList(ListNode head) { ListNode pre = null; ListNode cur = head; while (cur != null) { ListNode tmp = cur.next; cur.next = pre; pre = cur; cur = tmp; } return pre; }} 4.两两交换链表的节点给定一个链表，两两交换其中相邻的节点，并返回交换后的链表。你不能只是单纯的改变节点内部的值，而是需要实际的进行节点交换。 本题目依旧比较容易，和翻转链表类似，只要维护一个双指针即可实现功能。 实现过程：略 代码示例 1234567891011121314151617181920class Solution { public ListNode swapPairs(ListNode head) { ListNode dummy = new ListNode(-1); dummy.next = head; ListNode firstNode; ListNode secondNode; ListNode temp; ListNode cur = dummy; while (cur.next != null &amp;&amp; cur.next.next != null) { temp = cur.next.next.next; firstNode = cur.next; secondNode = cur.next.next; cur.next = secondNode; secondNode.next = firstNode; firstNode.next = temp; cur = firstNode; } return dummy.next; }} 5.删除链表的倒数第N个节点方法：快慢双指针 实现过程： 定义两个双指针，分别是 fast 和 slow 现将 fast 指针向右移动 n+1 个节点 同时将 fast 和 slow 进行移动，当 fast == null 的时候 slow 处的下一个节点就是要删除的节点 代码示例 123456789101112131415161718class Solution { public ListNode removeNthFromEnd(ListNode head, int n) { ListNode dummy = new ListNode(-1); dummy.next = head; ListNode fastNode = dummy; ListNode slowNode = dummy; for (int i = 0; i &lt;= n; i++) { fastNode = fastNode.next; } while (fastNode != null) { slowNode = slowNode.next; fastNode = fastNode.next; } slowNode.next = slowNode.next.next; return dummy.next; }} 6.链表相交找链表相交的节点，如果不相交则返回 null 假设链表A在相交之前有a个节点；链表B在相交之前有b个节点。在相交之后共有c个节点。那么可以采取双指针方法。 实现过程： headA 指针对链表 A 进行遍历，在遍历完之后移动到链表 B 的头节点。 同样的，headB 指针对链表B 进行遍历，在遍历完之后移动到链表 A 的头节点。 则二者相交的地方就是 headA == headB 的时候。原因： a+c+b = b+c+a 示例代码： 12345678public ListNode getIntersectionNode(ListNode headA, ListNode headB) { ListNode A = headA, B = headB; while (A != B) { A = A != null ? A.next : headB; B = B != null ? B.next : headA; } return A; } 7.环形链表给定一个链表，返回链表开始入环的第一个节点。 如果链表无环，则返回 null。 为了表示给定链表中的环，使用整数 pos 来表示链表尾连接到链表中的位置（索引从 0 开始）。 如果 pos 是 -1，则在该链表中没有环。 说明：不允许修改给定的链表。 实现方法：双指针 实现过程： 设定双指针 fast 和 slow，其中 fast 一次走两步，slow 一次走一步。 当 fast 和 slow 相交的时候，设置两个点， 一个从起始点出发，一个从相遇点出发 最终二者交点即为环形入口 具体数学推导自己进行 示例代码： 123456789101112131415161718public ListNode detectCycle(ListNode head) { ListNode slow = head; ListNode fast = head; while (fast != null &amp;&amp; fast.next != null) { fast = fast.next.next; slow = slow.next; if (slow == fast) { ListNode index1 = fast; ListNode index2 = head; while (index1 != index2) { index1 = index1.next; index2 = index2.next; } return index1; } } return null;} 8.总结链表题目常用方法：双指针+设置虚头节点 掌握了上述方法，大部分链表题目都会游刃有余 哈希表1.有效字母异位词给定两个字符串 s 和 t ，编写一个函数来判断 t 是否是 s 的字母异位词。 实现方法： 将 s 中的字母出现的次数加入到一个大小为 26 的数组中 遍历 t ，不断对 s 字母出现次数的数组进行–操作 如果最终数组全为0，则满足条件 2.两个数组的交集给定两个数组，编写一个函数来计算它们的交集。 注意：输出数组是不包含重复元素的 实现方法： 先将第一个数组中的所有元素添加到一个 Set 集合（去重）中，再遍历第二个数组，将 Set中包含的元素添加到resSet中即可 3.快乐数对于一个正整数，每一次将该数替换为它每个位置上的数字的平方和，然后重复这个过程直到这个数变为 1，也可能是 无限循环 但始终变不到 1。如果 可以变为 1，那么这个数就是快乐数。编写一个函数，判断输入的数字是不是快乐数。 首先对于本道题，之前我才用的方式是，重复进行 100 次，然后如果过程中没有 1 出现，那么这个数就不是快乐数，否则即为快乐数。这种方法设置重复次数主要是为了保证循环的次数足够多，从而将所有情况都加以判断。但是同时也会造成时间资源浪费。 正确的方法是采用一个 Set 集合来存储中间数，如果中间数重复出现，则直接跳出循环。这样算法性能更好。 代码示例： 1234567891011121314151617181920class Solution { public boolean isHappy(int n) { HashSet&lt;Integer&gt; set = new HashSet(); while (n != 1 &amp;&amp; !set.contains(n)) { set.add(n); n = getNextNumber(n); } return n == 1; } // 编写一个函数获取新数字 public int getNextNumber(int num) { int nextNum = 0; while (num &gt; 0) { nextNum += (num % 10) * (num % 10); num /= 10; } return nextNum; }} 4.两数之和给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。 这种方法相对于有效字母异位词这个题目来说，最大的区别是本题的数字没有一个确定的范围，如果使用数组来存储太过于困难。因此面对这种保存数字以及下标的题目，采用 map 进行存储。 代码示例： 1234567891011121314class Solution { public int[] twoSum(int[] nums, int target) { int[] res = new int[2]; HashMap&lt;Integer, Integer&gt; map = new HashMap&lt;Integer, Integer&gt;(); for(int i=0;i&lt;nums.length;i++){ if(map.containsKey(nums[i])){ res[0]=map.get(nums[i]); res[1]=i; } map.put(target-nums[i], i); } return res; }} 5.四数相加123给你四个整数数组 nums1、nums2、nums3 和 nums4 ，数组长度都是 n ，请你计算有多少个元组 (i, j, k, l) 能满足：0 &lt;= i, j, k, l &lt; nnums1[i] + nums2[j] + nums3[k] + nums4[l] == 0 本题解法与上面的方法相同，直接看示例代码 123456789101112131415161718192021class Solution { public int fourSumCount(int[] nums1, int[] nums2, int[] nums3, int[] nums4) { int res = 0; HashMap&lt;Integer,Integer&gt; map = new HashMap(); for (int i : nums1) { for (int j : nums2) { int sum = i + j; map.put(sum, map.getOrDefault(sum,0) + 1); } } for (int i : nums3) { for (int j : nums4) { res += map.getOrDefault(0-i-j,0); } } return res; }} 6.赎金信给你两个字符串：ransomNote 和 magazine ，判断 ransomNote 能不能由 magazine 里面的字符构成。 如果可以，返回 true ；否则返回 false 。 magazine 中的每个字符只能在 ransomNote 中使用一次。 实现过程： 本题目实现过程与有效字母异位词相似。区别点在于：有效字母异位词要保证所有的数组元素均为 0，赎金信则需要保证所有数组元素都大于等于 0 即可。 12345678910111213141516171819class Solution { public boolean canConstruct(String ransomNote, String magazine) { int[] record = new int[26]; for (int i = 0; i &lt; magazine.length(); i++) { record[magazine.charAt(i) - 'a']++; } for (int i = 0; i &lt; ransomNote.length(); i++) { record[ransomNote.charAt(i) - 'a']--; } for (int i : record) { if (i &lt; 0) { return false; } } return true; }} 7.三数之和给你一个整数数组 nums ，判断是否存在三元组 [nums[i], nums[j], nums[k]] 满足 i != j、i != k 且 j != k ，同时还满足 nums[i] + nums[j] + nums[k] == 0 。请 你返回所有和为 0 且不重复的三元组。 注意：答案中不可以包含重复的三元组。 实现思路： 本题与哈希表关系不大，更好的解决办法是采用双指针来解决。 代码示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243class Solution { public List&lt;List&lt;Integer&gt;&gt; threeSum(int[] nums) { List&lt;List&lt;Integer&gt;&gt; res = new ArrayList(); Arrays.sort(nums); for (int i = 0; i &lt; nums.length; i++) { if (nums[i] &gt; 0) { return res; } if (i &gt; 0 &amp;&amp; nums[i] == nums[i-1]) { continue; } int left = i + 1; int right = nums.length - 1; while (left &lt; right) { if (nums[i] + nums[left] + nums[right] == 0) { res.add(Arrays.asList(nums[i], nums[left], nums[right])); while (right &gt; left &amp;&amp; nums[right] == nums[right - 1]) { right--; } while (right &gt; left &amp;&amp; nums[left] == nums[left + 1]) { left++; } right--; left++; } else if (nums[i] + nums[left] + nums[right] &gt; 0) { right--; } else if (nums[i] + nums[left] + nums[right] &lt; 0) { left++; } } } return res; }} 本题的难点在于去重操作，需要注意 8.四数之和给定一个包含 n 个整数的数组 nums 和一个目标值 target，判断 nums 中是否存在四个元素 a，b，c 和 d ，使得 a + b + c + d 的值与 target 相等？找出所有满足条件且不重复的四元组。 实现过程： 本题思路与上一道题类似，都是采用双指针的方式来降低复杂度。但是同时本体的去重操作相对于上一题而言更加复杂。 实现代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748class Solution { public List&lt;List&lt;Integer&gt;&gt; fourSum(int[] nums, int target) { List&lt;List&lt;Integer&gt;&gt; res = new ArrayList(); Arrays.sort(nums); for (int i = 0; i &lt; nums.length; i++) { if (nums[i] &gt; 0 &amp;&amp; nums[i] &gt; target) { return res; } if (i &gt; 0 &amp;&amp; nums[i] == nums[i - 1]) { continue; } for (int j = i + 1; j &lt; nums.length; j++) { if (nums[i] + nums[j] &gt; target &amp;&amp; nums[i] + nums[j] &gt; 0) { break; } if (j &gt; i + 1 &amp;&amp; nums[j] == nums[j - 1]) { continue; } int left = j + 1; int right = nums.length - 1; while (left &lt; right) { if (nums[i] + nums[j] + nums[left] + nums[right] == target) { res.add(Arrays.asList(nums[i], nums[j], nums[left], nums[right])); // 对nums[left]和nums[right]去重 while (right &gt; left &amp;&amp; nums[right] == nums[right - 1]) right--; while (right &gt; left &amp;&amp; nums[left] == nums[left + 1]) left++; left++; right--; } else if (nums[i] + nums[j] + nums[left] + nums[right] &gt; target) { right--; } else if (nums[i] + nums[j] + nums[left] + nums[right] &lt; target) { left++; } } } } return res; }} 对于判断操作if (nums[i] + nums[j] &gt; target &amp;&amp; nums[i] + nums[j] &gt; 0){ break; }，为什么要保证 &gt;0 才可以直接返回？ 这就是因为如果 target 为 -7 ，nums是[-5,-1,-1,0]，满足条件但是会被删除造成错误 9.总结对于哈希表相关题目，如果需要进行存储的是字母或者有限个元素，则可以采用数组来进行存储；如果要存储值和下标，那么最好使用 map 来进行存储。 字符串1.反转字符串编写一个函数，其作用是将输入的字符串反转过来。输入字符串以字符数组 s 的形式给出。 实现思路： 直接首尾交换，循环进行即可 示例代码： 12345678910111213class Solution { public void reverseString(char[] s) { int left = 0; int right = s.length - 1; while (left &lt; right) { char temp = s[left]; s[left] = s[right]; s[right] = temp; right--; left++; } }} 2.反转字符串二给定一个字符串 s 和一个整数 k，从字符串开头算起, 每计数至 2k 个字符，就反转这 2k 个字符中的前 k 个字符。 如果剩余字符少于 k 个，则将剩余字符全部反转。 如果剩余字符小于 2k 但大于或等于 k 个，则反转前 k 个字符，其余字符保持原样。 一个遍历即可，每次步长为 2*k 示例代码 1234567891011121314151617class Solution { public String reverseStr(String s, int k) { char[] ch = s.toCharArray(); for (int i = 0; i &lt; s.length(); i+=2*k) { int start = i; int end = Math.min(s.length()-1,start+k-1); while (start &lt; end) { char temp = ch[start]; ch[start] = ch[end]; ch[end] = temp; start++; end--; } } return new String(ch); }} 要注意的易错点，就是end的值要同时考虑到不够 2k 和 2k 两种情况。 3.替换空格请实现一个函数，把字符串 s 中的每个空格替换成”%20”。 个人认为本题还是设置一个新的 StringBuilder 来作为新字符串比较好 实现思路： 遇到空格则append “%20”即可 4.反转字符串中的单词给定一个字符串，逐个翻转字符串中的每个单词。 例如：I am a hero —&gt; hero a am I 注意：输入字符串可以在前面或者后面包含多余的空格，但是反转后的字符不能包括。 实现思路： 将字符串首尾的空格去掉 反转所有的字符 反转每一个单词 示例代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758class Solution { public String reverseWords(String s) { /** 三个步骤： 1.先去除多余的空格 2.将整个字符串进行翻转 3.再将每个单词进行翻转 */ StringBuilder sb = removeSpaces(s); reverseString(sb, 0, sb.length() - 1); reverseEachWord(sb); return sb.toString(); } public StringBuilder removeSpaces(String s) { int start = 0; int end = s.length() - 1; while (s.charAt(start) == ' ') { start++; } while (s.charAt(end) == ' ') { end--; } StringBuilder sb = new StringBuilder(); while(start &lt;= end) { char c = s.charAt(start); if (c != ' ' || sb.charAt(sb.length() - 1) != ' ') { sb.append(c); } start++; } return sb; } public void reverseString(StringBuilder sb, int start, int end) { while (start &lt; end){ char temp = sb.charAt(start); sb.setCharAt(start, sb.charAt(end)); sb.setCharAt(end, temp); start++; end--; } } public void reverseEachWord(StringBuilder sb) { int start = 0; int end = 1; int n = sb.length(); while (start &lt; n) { while (end &lt; n &amp;&amp; sb.charAt(end) != ' ') { end++; } reverseString(sb, start, end - 1); start = end + 1; end = start + 1; } }} 5.反转子字符串字符串的左旋转操作是把字符串前面的若干个字符转移到字符串的尾部。请定义一个函数实现字符串左旋转操作的功能。比如，输入字符串”abcdefg”和数字2，该函数将返回左旋转两位得到的结果”cdefgab”。 实现思路： 反转前 k 个字符 反转其余的字符 反转所有的字符 示例代码： 12345678910111213141516171819class Solution { public String reverseLeftWords(String s, int n) { StringBuilder sb = new StringBuilder(s); reverseString(sb, 0, n-1); reverseString(sb, n, s.length()-1); reverseString(sb, 0, s.length()-1); return sb.toString(); } public void reverseString(StringBuilder sb, int start, int end) { while (start &lt; end) { char temp = sb.charAt(start); sb.setCharAt(start, sb.charAt(end)); sb.setCharAt(end, temp); start++; end--; } }} 6.总结对于字符串的相关题目，主要涉及到的就是反转，注意如何反转或者进行多少次反转可以满足题目要求。 关于字符串匹配问题——KMP算法，会单独写一个博客来进行记录 总结：在数组、链表、哈希表、字符串相关题目中，双指针方法有着不可或缺的作用，下面总结所有使用到双指针的题目： 数组移除元素 反转字符串 反转链表 删除链表中的倒数第 N 个元素 链表相交 环形链表 三数之和 四数之和 要将双指针思想用到以后的题目中，包括快慢指针和双向指针等等。","link":"/2023/06/26/%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95(1)/"},{"title":"MySQL 易忘知识复习","text":"学习目标： 对 MySQL 容易忘的知识的再回顾 基础知识： DUAL: 伪表 12SELECT 1+1,3 * 2FROM DUAL; #dual:伪表 AS:全称：alias(别名)，可以省略 12SELECT employee_id emp_id,last_name AS lnameFROM employees; DISTINCT:去除重复项 12SELECT DISTINCT department_idFROM employees; IFNULL(value,c):解决空值影响，如果不为空，那么就取value值，否则为常数c 12SELECT employee_id, salary &quot;月工资&quot;, salary * (1 + IFNULL(commission_pct,0)) * 12 &quot;年工资&quot;FROM employees; 运算符： 算数运算符 在SQL中，+ 没有连接的作用，就表示加法运算。此时会将字符串转换为数值（隐式转换） 12SELECT 100 + '1' # 在Java中，结果为：1001。FROM DUAL 在SQL中，字符在加法中表示 0 12SELECT 100 + 'a' # 此时将a看为0来进行运算FROM DUAL; 运算中NULL的情况 123SELECT 100 + NULL # null参与运算则结果为null100 DIV 0 # 分母如果为0，结果为NULLFROM DUAL; 比较运算符 = &lt;=&gt; &lt;&gt; != &lt; &lt;= &gt; &gt;= 注意：&lt;=&gt;:安全等于.记忆技巧：为null而生，有null时结果不为null 12SELECT NULL &lt;=&gt; NULL, 1 &lt;=&gt; NULLFROM DUAL; #1 0 特殊运算符 IS NULL \\ IS NOT NULL \\ ISNULL LEAST \\ GREATEST BETWEEN 条件下界 AND 条件上界（包含边界） IN (set) \\ NOT IN(set) LIKE:模糊查询 12345678SELECT last_nameFROM employeesWHERE last_name LIKE '%a%';#包含a的名字# 查询第二个字符为_且第3个字符为'a'的员工信息SELECT last_nameFROM employeesWHERE last_name LIKE '_\\_a%'; REGEXP \\ RLIKE : 正则表达式 ^ 表示以什么为开头 $ 表示以什么为结束 逻辑运算符： OR || AND &amp;&amp; NOT ! XOR（异或） 位运算符： &amp; | ^ ~ &gt;&gt; &lt;&lt; ^ 异或 ~ 取反 排序： 使用ORDER BY对查询到的数据进行排序操作 12345#升序操作：ASC(ascend)#降序操作：DESC(descend)SELECT employee_id,last_name,salaryFROM employeesORDER BY salary DESC; 注意： 可以利用列的别名进行排序 可以进行二级排序，按照声明的顺序进行排序 1234#练习：显示员工信息，按照department_id的降序排列，salary的升序排列SELECT employee_id,salary,department_idFROM employeesORDER BY department_id DESC,salary ASC; 别名只能在ORDER BY 中进行使用，不能在WHERE中进行使用原因：执行顺序是—&gt;先执行WHERE再进行别名操作，最后进行ORDER BY 分页： MySQL使用 limit 来实现数据的分页 123456#需求：每页显示pageSize条记录，此时显示第pageNo页：#公式：LIMIT (pageNo-1) * pageSize,pageSize;# 每页显示20条记录，此时显示第3页SELECT employee_id,last_nameFROM employeesLIMIT 40,20; 声明顺序： 123# 声明顺序如下： WHERE ... ORDER BY ...LIMIT # LIMIT的格式： 严格来说：LIMIT 位置偏移量,条目数# 结构&quot;LIMIT 0,条目数&quot; 等价于 &quot;LIMIT 条目数&quot; 其他特殊操作 如果表里有107条数据，我们只想要显示第 32、33 条数据怎么办呢？ 1234SELECT employee_id,last_nameFROM employees#limit 31,2;LIMIT 2 OFFSET 31; 需要查询员工最高工资怎么办呢？ 12345#查询员工表中工资最高的员工的信息SELECT employee_id,last_name,salaryFROM employeesORDER BY salary DESCLIMIT 0,1; 注意事项： LIMIT 可以使用在MySQL、PGSQL、MariaDB、SQLite 等数据库中使用，表示分页。 不能使用在SQL Server、DB2、Oracle！ 多表查询： 多表查询操作可以在WHERE中进行 123SELECT emp.employee_id,dept.department_name,emp.department_idFROM employees emp,departments deptWHERE emp.`department_id` = dept.department_id; 多表查询的分类： 等值连接 vs 非等值连接 1234#非等值连接的例子SELECT e.last_name,e.salary,j.grade_levelFROM employees e, job_grades jWHERE e.salary BETWEEN j.`lowest_sal` AND j.`highest_sal`; 自连接 vs 非自连接 12345#自连接的例子：#练习：查询员工id,员工姓名及其管理者的id和姓名SELECT emp.employee_id,emp.last_name,mgr.employee_id,mgr.last_nameFROM employees emp ,employees mgrWHERE emp.`manager_id` = mgr.`employee_id`; 内连接 vs 外连接 内连接：合并具有同一列的两个以上的表的行, 结果集中不包含一个表与另一个表不匹配的行 1234# 两个表不匹配的就被消去了SELECT employee_id,department_nameFROM employees e,departments dWHERE e.`department_id` = d.department_id; 外连接：合并具有同一列的两个以上的表的行, 结果集中除了包含一个表与另一个表匹配的行之外，还查询到了左表或右表中不匹配的行。 外连接的分类：左外连接、右外连接、满外连接 左外连接：两个表在连接过程中除了返回满足连接条件的行以外还返回左表中不满足条件的行，这种连接称为左外连接。 123SELECT last_name,department_nameFROM employees e LEFT JOIN departments dON e.`department_id` = d.`department_id`; 右外连接：两个表在连接过程中除了返回满足连接条件的行以外还返回右表中不满足条件的行，这种连接称为右外连接。 123SELECT last_name,department_nameFROM employees e RIGHT OUTER JOIN departments dON e.`department_id` = d.`department_id`; 满外连接： 1234#满外连接：mysql不支持FULL OUTER JOINSELECT last_name,department_nameFROM employees e FULL OUTER JOIN departments dON e.`department_id` = d.`department_id`; UNION 和 UNION ALL的使用 UNION：会执行去重操作 UNION ALL：不会执行去重操作 结论：如果明确知道合并数据后的结果数据不存在重复数据，或者不需要去除重复的数据，则尽量使用UNION ALL语句，以提高数据查询的效率。 SQL99语法中关于连接的新特性 12345678910111213141516171819202122232425# 10.SQL99语法的新特性1：自然连接SELECT employee_id,last_name,department_nameFROM employees e JOIN departments dON e.`department_id` = d.`department_id`AND e.`manager_id` = d.`manager_id`;SELECT employee_id,last_name,department_nameFROM employees e NATURAL JOIN departments d;#11. SQL99语法的新特性2:USINGSELECT employee_id,last_name,department_nameFROM employees e JOIN departments dON e.department_id = d.department_id;SELECT employee_id,last_name,department_nameFROM employees e JOIN departments dUSING (department_id);#拓展：SELECT last_name,job_title,department_name FROM employees INNER JOIN departments INNER JOIN jobs ON employees.department_id = departments.department_id AND employees.job_id = jobs.job_id; 单行函数： 包括数值函数、字符串函数、日期和时间函数、流程控制函数、加密与解密函数等，见w3school或者尚硅谷第七章PPT 聚合函数: 包括求最大值最小值、平均值、计算总数 ​ GROUP BY： 1234#结论1：SELECT中出现的非组函数的字段必须声明在GROUP BY 中。# 反之，GROUP BY中声明的字段可以不出现在SELECT中。#结论2：GROUP BY 声明在FROM后面、WHERE后面，ORDER BY 前面、LIMIT前面#结论3：MySQL中GROUP BY中使用WITH ROLLUP:计算整体的平均 ​ HAVING的使用 (作用：用来配合GROUP BY过滤数据的) 1234SELECT department_id,MAX(salary)FROM employeesGROUP BY department_idHAVING MAX(salary) &gt; 10000; HAVING和WHERE对比 结论：当过滤条件中有聚合函数时，则此过滤条件必须声明在HAVING中。当过滤条件中没有聚合函数时，则此过滤条件声明在WHERE中或HAVING中都可以。但是，建议大家声明在WHERE中。 从适用范围上来讲，HAVING的适用范围更广。 如果过滤条件中没有聚合函数：这种情况下，WHERE的执行效率要高于HAVING 123456789101112131415161718192021222324252627#4. SQL底层执行原理#4.1 SELECT 语句的完整结构/*#sql92语法：SELECT ....,....,....(存在聚合函数)FROM ...,....,....WHERE 多表的连接条件 AND 不包含聚合函数的过滤条件GROUP BY ...,....HAVING 包含聚合函数的过滤条件ORDER BY ....,...(ASC / DESC )LIMIT ...,....#sql99语法：SELECT ....,....,....(存在聚合函数)FROM ... (LEFT / RIGHT)JOIN ....ON 多表的连接条件 (LEFT / RIGHT)JOIN ... ON ....WHERE 不包含聚合函数的过滤条件GROUP BY ...,....HAVING 包含聚合函数的过滤条件ORDER BY ....,...(ASC / DESC )LIMIT ...,....*/#4.2 SQL语句的执行过程：#FROM ...,...-&gt; ON -&gt; (LEFT/RIGNT JOIN) -&gt; WHERE -&gt; GROUP BY -&gt; HAVING -&gt; SELECT -&gt; DISTINCT -&gt; # ORDER BY -&gt; LIMIT 子查询： 子查询的引入 1234567SELECT last_name,salaryFROM employeesWHERE salary &gt; ( SELECT salary FROM employees WHERE last_name = 'Abel'); 子查询（内查询）在主查询之前一次执行完成。 子查询的结果被主查询（外查询）使用 。 注意事项 子查询要包含在括号内 将子查询放在比较条件的右侧 单行操作符对应单行子查询，多行操作符对应多行子查询 子查询的分类 单行子查询和多行子查询 单行子查询： 123456SELECT employee_id, last_name, CASE department_id WHEN (SELECT department_id FROM departments WHERE location_id = 1800) THEN 'Canada' ELSE 'USA' END &quot;location&quot;FROM employees; 多行子查询： ​ 多行子查询的操作符： IN ANY ALL SOME(同ANY) 123456SELECT employee_id, last_name, department_id,salaryFROM employeesWHERE salary IN (SELECT MIN(salary) FROM employees GROUP BY department_id); 1234567891011# ANY / ALL:#题目：返回其它job_id中比job_id为‘IT_PROG’部门某个员工工资低的员工的员工号、#姓名、job_id 以及salarySELECT employee_id,last_name,job_id,salaryFROM employeesWHERE job_id &lt;&gt; 'IT_PROG'AND salary &lt; ANY ( SELECT salary FROM employees WHERE job_id = 'IT_PROG' ); 12345678910#题目：返回其它job_id中比job_id为‘IT_PROG’部门所有工资低的员工的员工号、#姓名、job_id 以及salarySELECT employee_id,last_name,job_id,salaryFROM employeesWHERE job_id &lt;&gt; 'IT_PROG'AND salary &lt; ALL ( SELECT salary FROM employees WHERE job_id = 'IT_PROG' ); 结论：在SELECT中，除了GROUP BY 和 LIMIT之外，其他位置都可以声明子查询！ 12345678910/* SELECT ....,....,....(存在聚合函数) FROM ... (LEFT / RIGHT)JOIN ....ON 多表的连接条件 (LEFT / RIGHT)JOIN ... ON .... WHERE 不包含聚合函数的过滤条件 GROUP BY ...,.... HAVING 包含聚合函数的过滤条件 ORDER BY ....,...(ASC / DESC ) LIMIT ...,.... */ 数据处理之增删改 将查询结果插入到新建的表中 12345INSERT INTO emp1(id,NAME,salary,hire_date)#查询语句SELECT employee_id,last_name,salary,hire_date # 查询的字段一定要与添加到的表的字段一一对应FROM employeesWHERE department_id IN (70,60); 说明：emp1表中要添加数据的字段的长度不能低于employees表中查询的字段的长度。如果emp1表中要添加数据的字段的长度低于employees表中查询的字段的长度的话，就有添加不成功的风险。 更新数据（或者修改数据） 1UPDATE .... SET .... WHERE ... 可以实现批量修改数据；可以同时修改一条数据的多个字段 删除数据 1DELETE FROM .... WHERE.... 注意： DML操作默认情况下，执行完以后都会自动提交数据。如果希望执行完以后不自动提交数据，则需要使用 1SET autocommit = FALSE. SQL8新特性：计算列 12345CREATE TABLE test1( a INT, b INT, c INT GENERATED ALWAYS AS (a + b) VIRTUAL #字段c即为计算列); 数据类型： 有关数据类型的介绍包括： 整数类型 浮点类型 定点数类型 位类型 日期与时间类型 文本字符串类型 ENUM枚举类类型 SET类型 二进制字符串类型 JSON类型 空间类型 约束：","link":"/2022/11/20/SQL/"},{"title":"代码随想录刷题笔记——栈、队列、二叉树篇","text":"本篇内容： 栈、队列与二叉树的结构与特性 代码随想录中关于栈、队列与二叉树的相关算法题 刷题过程中的一些思考与体会 栈与队列二叉树","link":"/2023/07/07/%E4%BB%A3%E7%A0%81%E9%9A%8F%E6%83%B3%E5%BD%95-2/"},{"title":"MySQL 原理的学习","text":"本篇内容： 学习 MySQL 底层原理，包括存储方式、执行流程 学习 MySQL 索引相关内容，理解 B+ 树结构 学习 MySQL 四种事务，包括他们之间的关系 掌握 MySQL 锁的相关知识 基础篇1.执行 select 语句，期间发生了什么？ 答：执行 select 语句，由连接器、查询缓存、解析 SQL、执行 SQL 四个步骤组成。 连接器：建立连接，管理连接、校验用户身份；（与客户端进行 TCP 三次握手建立连接；校验客户端的用户名和密码，如果用户名或密码不对，则会报错；如果用户名和密码都对了，会读取该用户的权限，然后后面的权限逻辑判断都基于此时读取到的权限；） 查询缓存：查询语句如果命中查询缓存则直接返回，否则继续往下执行。MySQL 8.0 已删除该模块； 解析 SQL，通过解析器对 SQL 查询语句进行词法分析、语法分析，然后构建语法树，方便后续模块读取表名、字段、语句类型； 执行 SQL：执行 SQL 共有三个阶段： 预处理阶段：检查表或字段是否存在；将 select * 中的 * 符号扩展为表上的所有列。 优化阶段：基于查询成本的考虑， 选择查询成本最小的执行计划； 执行阶段：根据执行计划执行 SQL 查询语句，从存储引擎读取记录，返回给客户端； 1.1简单叙述 MySQL 的架构？MySQL 的架构共分为两层：Server 层和存储引擎层， Server 层负责建立连接、分析和执行 SQL。MySQL 大多数的核心功能模块都在这实现，主要包括连接器，查询缓存、解析器、预处理器、优化器、执行器等。另外，所有的内置函数（如日期、时间、数学和加密函数等）和所有跨存储引擎的功能（如存储过程、触发器、视图等。）都在 Server 层实现。 存储引擎层负责数据的存储和提取。支持 InnoDB、MyISAM、Memory 等多个存储引擎，不同的存储引擎共用一个 Server 层。现在最常用的存储引擎是 InnoDB，从 MySQL 5.5 版本开始， InnoDB 成为了 MySQL 的默认存储引擎。我们常说的索引数据结构，就是由存储引擎层实现的，不同的存储引擎支持的索引类型也不相同，比如 InnoDB 支持索引类型是 B+树 ，且是默认使用，也就是说在数据表中创建的主键索引和二级索引默认使用的是 B+ 树索引。 1.2 MySQL 是否需要三次握手？MySQL 是基于 TCP 协议进行传输的，因此需要三次握手。 完成 TCP 连接之后会验证用户名和密码，验证通过则可以使用了。使用过程中如果修改密码，不影响已经建立的连接，只有新连接才使用新密码。 1.3 对于空闲连接，如何处理？会一直连接吗？MySQL 定义了空闲连接的最大空闲时长，默认值是 8 小时（28880秒），如果空闲连接超过了这个时间，连接器就会自动将它断开。 1.3.1MySQL 的连接数有限制吗？MySQL 服务支持的最大连接数由 max_connections 参数控制，并且具有长连接和短连接两种。使用长连接的好处就是可以减少建立连接和断开连接的过程，所以一般是推荐使用长连接。 1.3.2长连接有哪些缺点？应该如何解决？使用长连接后可能会占用内存增多，这些连接对象资源只有在连接断开时才会释放。如果长连接累计很多，将导致 MySQL 服务占用内存太大，有可能会被系统强制杀掉，这样会发生 MySQL 服务异常重启的现象。 1.3.3怎么解决长连接占用内存的问题？ 第一种，定期断开长连接。既然断开连接后就会释放连接占用的内存资源，那么我们可以定期断开长连接。 第二种，客户端主动重置连接。当客户端执行了一个很大的操作后，在代码里调用函数来重置连接，达到释放内存的效果。 1.4为什么 MySQL8.0 删掉了查询缓存这一步？对于更新比较频繁的表，查询缓存的命中率很低的，因为只要一个表有更新操作，那么这个表的查询缓存就会被清空。如果刚缓存了一个查询结果很大的数据，还没被使用的时候，刚好这个表有更新操作，查询缓冲就被清空了，浪费缓存资源。 2.MySQL 如何存储一行数据的？数据库表中的记录都是按行（row）进行存放的，每行记录根据不同的行格式，有不同的存储结构。 2.1表空间文件的结构是怎么样的？ 行：数据库表中的记录都是按行（row）进行存放的，每行记录根据不同的行格式，有不同的存储结构。 页：记录是按照行来存储的，但是数据库的读取并不以「行」为单位，否则一次读取（也就是一次 I/O 操作）只能处理一行数据，效率会非常低。因此，InnoDB 的数据是按「页」为单位来读写的，也就是说，当需要读一条记录的时候，并不是将这个行记录从磁盘读出来，而是以页为单位，将其整体读入内存。默认每个页的大小为 16KB，也就是最多能保证 16KB 的连续存储空间。 页是 InnoDB 存储引擎磁盘管理的最小单元，意味着数据库每次读写都是以 16KB 为单位的，一次最少从磁盘中读取 16K 的内容到内存中，一次最少把内存中的 16K 内容刷新到磁盘中。 区：InnoDB 存储引擎是用 B+ 树来组织数据的。B+ 树中每一层都是通过双向链表连接起来的，如果是以页为单位来分配存储空间，那么链表中相邻的两个页之间的物理位置并不是连续的，可能离得非常远，那么磁盘查询时就会有大量的随机I/O，随机 I/O 是非常慢的。因此在表中数据量大的时候，为某个索引分配空间的时候就不再按照页为单位分配了，而是按照区（extent）为单位分配。每个区的大小为 1MB，对于 16KB 的页来说，连续的 64 个页会被划为一个区，这样就使得链表中相邻的页的物理位置也相邻，就能使用顺序 I/O 了。 段：表空间是由各个段（segment）组成的，段是由多个区（extent）组成的。段一般分为数据段、索引段和回滚段等。 索引段：存放 B + 树的非叶子节点的区的集合； 数据段：存放 B + 树的叶子节点的区的集合； 回滚段：存放的是回滚数据的区的集合。 2.2InnoDB 行格式有哪些？行格式（row_format），就是一条记录的存储结构。 InnoDB 提供了 4 种行格式，分别是 Redundant、Compact、Dynamic和 Compressed 行格式。 关于行格式的一些内容，如果说有兴趣可以自己看小林Coding相关内容 2.3MySQL 的 NULL 值是怎么存放的？MySQL 的 Compact 行格式中会用「NULL值列表」来标记值为 NULL 的列，NULL 值并不会存储在行格式中的真实数据部分。 NULL值列表会占用 1 字节空间，当表中所有字段都定义成 NOT NULL，行格式中就不会有 NULL值列表，这样可节省 1 字节的空间。 2.4MySQL 怎么知道 varchar(n) 实际占用数据的大小？MySQL 的 Compact 行格式中会用「变长字段长度列表」存储变长字段实际占用的数据大小。 varchar(n) 中 n 最大取值为多少？ 一行记录最大能存储 65535 字节的数据，但是这个是包含「变长字段字节数列表所占用的字节数」和「NULL值列表所占用的字节数」。所以， 我们在算 varchar(n) 中 n 最大值时，需要减去这两个列表所占用的字节数。 如果一张表只有一个 varchar(n) 字段，且允许为 NULL，字符集为 ascii。varchar(n) 中 n 最大取值为 65532。 计算公式：65535 - 变长字段字节数列表所占用的字节数 - NULL值列表所占用的字节数 = 65535 - 2 - 1 = 65532。 如果有多个字段的话，要保证所有字段的长度 + 变长字段字节数列表所占用的字节数 + NULL值列表所占用的字节数 &lt;= 65535。 2.5行溢出后，MySQL 是怎么处理的？如果一个数据页存不了一条记录，InnoDB 存储引擎会自动将溢出的数据存放到「溢出页」中。 Compact 行格式针对行溢出的处理是这样的：当发生行溢出时，在记录的真实数据处只会保存该列的一部分数据，而把剩余的数据放在「溢出页」中，然后真实数据处用 20 字节存储指向溢出页的地址，从而可以找到剩余数据所在的页。 Compressed 和 Dynamic 这两种格式采用完全的行溢出方式，记录的真实数据处不会存储该列的一部分数据，只存储 20 个字节的指针来指向溢出页。而实际的数据都存储在溢出页中。 索引篇1.为什么使用B+树作为索引（B+树有哪些好处）？B+Tree 存储千万级的数据只需要 3-4 层高度就可以满足，这意味着从千万级的表查询目标数据最多需要 3-4 次磁盘 I/O，所以B+Tree 相比于 B 树和二叉树来说，最大的优势在于查询效率很高，因为即使在数据量很大的情况，查询一个数据的磁盘 I/O 依然维持在 3-4次。 1.1追问：为什么不使用B树来作为索引？（B+树和B树的区别） B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比存储即存索引又存记录的 B 树，B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的磁盘 I/O次数会更少。 B+ 树有大量的冗余节点（所有非叶子节点都是冗余索引），这些冗余索引让 B+ 树在插入、删除的效率都更高，比如删除根节点的时候，不会像 B 树那样会发生复杂的树的变化； B+ 树叶子节点之间用链表连接了起来，有利于范围查询，而 B 树要实现范围查询，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。 B+ 树与 B 树的差异，主要是以下这几点： 叶子节点（最底部的节点）才会存放实际数据（索引+记录），非叶子节点只会存放索引； 所有索引都会在叶子节点出现，叶子节点之间构成一个有序链表； 非叶子节点的索引也会同时存在在子节点中，并且是在子节点中所有索引的最大（或最小）。 非叶子节点中有多少个子节点，就有多少个索引； 1.2追问：为什么不使用二叉树作为索引？ 在实际应用中，B+ 树每个节点可以有多个叶子节点，这样就保证了，即使数据达到千万级别时，B+Tree 的高度依然维持在 34 层左右，也就是说一次数据查询操作只需要做 34 次的磁盘 I/O 操作就能查询到目标数据。 二叉树的每个父节点的儿子节点个数只能是 2 个，意味着其搜索复杂度为 O(logN)，因此二叉树检索到目标数据所经历的磁盘 I/O 次数要更多。 1.3追问：为什么不使用Hash表作为索引？Hash 表不适合做范围查询，它更适合做等值的查询，这也是 B+Tree 索引要比 Hash 表索引有着更广泛的适用场景的原因。 2.主键索引与二级索引的区别？ 主键索引的 B+Tree 的叶子节点存放的是实际数据，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里； 二级索引的 B+Tree 的叶子节点存放的是主键值，而不是实际数据。 所以，在查询时使用了二级索引，如果查询的数据能在二级索引里查询的到（如查询的恰好是主键），那么就不需要回表，这个过程就是覆盖索引。如果查询的数据不在二级索引里，就会先检索二级索引，找到对应的叶子节点，获取到主键值后，然后再检索主键索引，就能查询到数据了，这个过程就是回表。 3.联合索引的知识点什么是联合索引？ 1CREATE INDEX index_product_no_name ON product(product_no, name); 将两个索引联合起来的索引称之为联合索引。 联合索引的匹配原则： 使用联合索引时，存在最左匹配原则，也就是按照最左优先的方式进行索引的匹配。在使用联合索引进行查询的时候，如果不遵循「最左匹配原则」，联合索引会失效，这样就无法利用到索引快速查询的特性了。 比如，如果创建了一个 (a, b, c) 联合索引，则索引匹配的时候从左到右依次匹配。如果不存在a索引，那么不可以用b索引，即这样的查询联合索引无效 123- where b=2；- where c=3；- where b=2 and c=3； 联合查询的特殊情况： 联合索引的最左匹配原则会一直向右匹配直到遇到「范围查询」就会停止匹配。也就是范围查询的字段可以用到联合索引，但是在范围查询字段的后面的字段无法用到联合索引。 下面举几种特殊情况的例子： select * from t_table where a &gt; 1 and b = 2，联合索引（a, b）哪一个字段用到了联合索引的 B+Tree？ 12345 **这条查询语句只有 a 字段用到了联合索引进行索引查询，而 b 字段并没有使用到联合索引**。2. ``` select * from t_table where a &gt;= 1 and b = 2，联合索引（a, b）哪一个字段用到了联合索引的 B+Tree？ **Q2 这条查询语句 a 和 b 字段都用到了联合索引进行索引查询**。**对于符合 a = 1 的二级索引记录的范围里，b 字段的值是「有序」的**。所以对于a=1这条记录，使用联合索引进行查询。 ```SELECT * FROM t_table WHERE a BETWEEN 2 AND 8 AND b = 2，联合索引（a, b）哪一个字段用到了联合索引的 B+Tree？ 12345 **这条查询语句 a 和 b 字段都用到了联合索引进行索引查询**。4. ``` SELECT * FROM t_user WHERE name like 'j%' and age = 22，联合索引（name, age）哪一个字段用到了联合索引的 B+Tree？ 这条查询语句 a 和 b 字段都用到了联合索引进行索引查询。对于符合 name = j 的二级索引记录的范围里，age字段的值是「有序」的。所以，在确定需要扫描的二级索引的范围时，当二级索引记录的 name 字段值为 ‘j’ 时，可以通过 age = 22 条件减少需要扫描的二级索引记录范围。 综上所示，联合索引的最左匹配原则，在遇到范围查询（如 &gt;、&lt;）的时候，就会停止匹配，也就是范围查询的字段可以用到联合索引，但是在范围查询字段的后面的字段无法用到联合索引。注意，对于 &gt;=、&lt;=、BETWEEN、like 前缀匹配的范围查询，并不会停止匹配。 追问：对于联合索引（a, b），在执行 select * from table where a &gt; 1 and b = 2 语句的时候，只有 a 字段能用到索引，那在联合索引的 B+Tree 找到第一个满足条件的主键值（ID 为 2）后，还需要判断其他条件是否满足（看 b 是否等于 2），那是在联合索引里判断？还是回主键索引去判断呢？ 在 MySQL 5.6 之前，只能从 ID2 （主键值）开始一个个回表，到「主键索引」上找出数据行，再对比 b 字段值。 而 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在联合索引遍历过程中，对联合索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。 索引区分度： 实际开发工作中建立联合索引时，要把区分度大的字段排在前面，这样区分度大的字段越有可能被更多的 SQL 使用到。 即某个字段不同值的个数除以总行数。 4.索引的缺点与应用场景4.1索引有什么缺点？ 需要占用物理空间，数量越大，占用空间越大； 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增大； 会降低表的增删改的效率，因为每次增删改索引，B+ 树为了维护索引有序性，都需要进行动态维护。 4.2什么时候适合用索引？ 字段有唯一性限制的，比如商品编码； 经常用于 WHERE 查询条件的字段，这样能够提高整个表的查询速度，如果查询条件不是一个字段，可以建立联合索引。 经常用于 GROUP BY 和 ORDER BY 的字段，这样在查询的时候就不需要再去做一次排序了，因为我们都已经知道了建立索引之后在 B+Tree 中的记录都是排序好的。 4.3什么时候不需要使用索引？ WHERE 条件，GROUP BY，ORDER BY 里用不到的字段，索引的价值是快速定位，如果起不到定位的字段通常是不需要创建索引的，因为索引是会占用物理空间的。 字段中存在大量重复数据，不需要创建索引，比如性别字段，只有男女，如果数据库表中，男女的记录分布均匀，那么无论搜索哪个值都可能得到一半的数据。在这些情况下，还不如不要索引，因为 MySQL 还有一个查询优化器，查询优化器发现某个值出现在表的数据行中的百分比很高的时候，它一般会忽略索引，进行全表扫描。 表数据太少的时候，不需要创建索引； 经常更新的字段不用创建索引，比如不要对电商项目的用户余额建立索引，因为索引字段频繁修改，由于要维护 B+Tree的有序性，那么就需要频繁的重建索引，这个过程是会影响数据库性能的。 5.索引优化有哪些方法？ 前缀索引优化。使用某个字段中字符串的前几个字符建立索引，可以减小索引字段大小，增加一个索引页中存储的索引值，有效提高索引的查询速度。在一些大字符串的字段作为索引时，使用前缀索引可以帮助我们减小索引项的大小。 覆盖索引优化。指的是将所有需要的字段创建一个联合索引，避免回表操作。使用覆盖索引的好处就是，不需要查询出包含整行记录的所有信息，也就减少了大量的 I/O 操作。 主键索引最好是自增的。使用自增主键时，每次插入的新数据就会按顺序添加到当前索引节点的位置，不需要移动已有的数据，当页面写满，就会自动开辟一个新页面。因为每次插入一条新记录，都是追加操作，不需要重新移动数据，因此这种插入数据的方法效率非常高。如果我们使用非自增主键，由于每次插入主键的索引值都是随机的，因此每次插入新的数据时，就可能会插入到现有数据页中间的某个位置，这将不得不移动其它数据来满足新数据的插入，甚至需要从一个页面复制数据到另外一个页面，我们通常将这种情况称为页分裂。页分裂还有可能会造成大量的内存碎片，导致索引结构不紧凑，从而影响查询效率。 索引最好设置为 NOT NULL。有两个原因： 第一原因：索引列存在 NULL 就会导致优化器在做索引选择的时候更加复杂，更加难以优化，因为可为 NULL 的列会使索引、索引统计和值比较都更复杂，比如进行索引统计时，count 会省略值为NULL 的行。 第二个原因：NULL 值是一个没意义的值，但是它会占用物理空间，所以会带来的存储空间的问题，因为 InnoDB 存储记录的时候，如果表中存在允许为 NULL 的字段，那么行格式中至少会用 1 字节空间存储 NULL 值列表。 防止索引失效。 追问：前缀索引有什么缺点？ order by 无法使用前缀索引； 无法把前缀索引用作覆盖索引； 索引失效有哪些情况？ 当我们使用左或者左右模糊匹配的时候，也就是 like %xx 或者 like %xx%这两种方式都会造成索引失效； 当我们在查询条件中对索引列做了计算、函数、类型转换操作，这些情况下都会造成索引失效； 当我们在查询条件中对索引列进行表达式计算，也是无法索引的。（因为索引保存的是索引字段的原始值，不是表达式计算后的值） 联合索引要能正确使用需要遵循最左匹配原则，也就是按照最左优先的方式进行索引的匹配，否则就会导致索引失效。 在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。 MySQL 在遇到字符串和数字比较的时候，会自动把字符串转为数字，然后再进行比较。如果字符串是索引列，而条件语句中的输入参数是数字的话，那么索引列会发生隐式类型转换，由于隐式类型转换是通过 CAST 函数实现的，等同于对索引列使用了函数，所以就会导致索引失效。 使用模糊匹配一定会索引失效吗？ 不一定。使用左模糊匹配（like “%xx”）并不一定会走全表扫描，关键还是看数据表中的字段。如果数据库表中的字段只有主键+二级索引，那么即使使用了左模糊匹配，也不会走全表扫描（type=all），而是走全扫描二级索引树(type=index)。 6.从数据页的角度看B+树B+ 树如何进行查询？（简述B+树查询的过程） 从根节点开始，通过二分法快速定位到符合页内范围包含查询值的页，（举例，查询的主键为6，因为查询的主键值为 6，在[1, 7)范围之间，所以到页 30 中查找更详细的目录项；） 在非叶子节点（页30）中，继续通过二分法快速定位到符合页内范围包含查询值的页，主键值大于 5，所以就到叶子节点（页16）查找记录； 接着，在叶子节点（页16）中，通过槽查找记录时，使用二分法快速定位要查询的记录在哪个槽（哪个记录分组），定位到槽后，再遍历槽内的所有记录，找到主键为 6 的记录。 补充：数据页中的二分查找 从图可以看到，页目录就是由多个槽组成的，槽相当于分组记录的索引。然后，因为记录是按照「主键值」从小到大排序的，所以我们通过槽查找记录时，可以使用二分法快速定位要查询的记录在哪个槽（哪个记录分组），定位到槽后，再遍历槽内的所有记录，找到对应的记录，无需从最小记录开始遍历整个页中的记录链表。 以上面那张图举个例子，5 个槽的编号分别为 0，1，2，3，4，我想查找主键为 11 的用户记录： 先二分得出槽中间位是 (0+4)/2=2 ，2号槽里最大的记录为 8。因为 11 &gt; 8，所以需要从 2 号槽后继续搜索记录； 再使用二分搜索出 2 号和 4 槽的中间位是 (2+4)/2= 3，3 号槽里最大的记录为 12。因为 11 &lt; 12，所以主键为 11 的记录在 3 号槽里； 这里有个问题，「槽对应的值都是这个组的主键最大的记录，如何找到组里最小的记录」？比如槽 3 对应最大主键是 12 的记录，那如何找到最小记录 9。解决办法是：通过槽 3 找到 槽 2 对应的记录，也就是主键为 8 的记录。主键为 8 的记录的下一条记录就是槽 3 当中主键最小的 9 记录，然后开始向下搜索 2 次，定位到主键为 11 的记录，取出该条记录的信息即为我们想要查找的内容。 那么第三步中，如果某个槽内的记录很多，然后由于记录都是单向链表串起来的，那这样在槽内查找某个记录的时间复杂度不就是 O(n) 了吗？ 这点不用担心，InnoDB 对每个分组中的记录条数都是有规定的，槽内的记录就只有几条： 第一个分组中的记录只能有 1 条记录； 最后一个分组中的记录条数范围只能在 1-8 条之间； 剩下的分组中记录条数范围只能在 4-8 条之间。 7.为什么说 MySQL 单表数据不要超过 2000w 行？ 当MySQL 单表数据超过2000W的时候，会导致B+树层数变高，从而查询时磁盘 I/O 次数变多，影响查询性能 8.哪种 COUNT 性能最好？ count(1)、 count(*)、 count(主键字段)在执行的时候，如果表里存在二级索引，优化器就会选择二级索引进行扫描。所以，如果要执行 count(1)、 count(*)、 count(主键字段) 时，尽量在数据表上建立二级索引，这样优化器会自动采用 key_len 最小的二级索引进行扫描，相比于扫描主键索引效率会高一些。 count(*)会被转换为count(0)。因此count(1)、 count(*)二者相同，在InnoDB 循环遍历聚簇索引（主键索引），将读取到的记录返回给 server 层，但是不会读取记录中的任何字段的值。 再来，就是不要使用 count(字段) 来统计记录个数，因为它的效率是最差的，会采用全表扫描的方式来统计。如果你非要统计表中该字段不为 NULL 的记录个数，建议给这个字段建立一个二级索引。 追问：如何优化COUNT(*)？ 近似值。使用 show table status 或者 explain 命令来表进行估算。 额外表保存计数值。如果是想精确的获取表的记录总数，我们可以将这个计数值保存到单独的一张计数表中。当我们在数据表插入一条记录的同时，将计数表中的计数字段 + 1。也就是说，在新增和删除操作时，我们需要额外维护这个计数表。 9.索引篇小结 事务篇1.事务有哪些特性？ 原子性（Atomicity）：一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节，而且事务在执行过程中发生错误，会被回滚到事务开始前的状态，就像这个事务从来没有执行过一样，就好比买一件商品，购买成功时，则给商家付了钱，商品到手；购买失败时，则商品在商家手中，消费者的钱也没花出去。 一致性（Consistency）：是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态。比如，用户 A 和用户 B 在银行分别有 800 元和 600 元，总共 1400 元，用户 A 给用户 B 转账 200 元，分为两个步骤，从 A 的账户扣除 200 元和对 B 的账户增加 200 元。一致性就是要求上述步骤操作后，最后的结果是用户 A 还有 600 元，用户 B 有 800 元，总共 1400 元，而不会出现用户 A 扣除了 200 元，但用户 B 未增加的情况（该情况，用户 A 和 B 均为 600 元，总共 1200 元）。 隔离性（Isolation）：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致，因为多个事务同时使用相同的数据时，不会相互干扰，每个事务都有一个完整的数据空间，对其他并发事务是隔离的。也就是说，消费者购买商品这个事务，是不影响其他消费者购买的。 持久性（Durability）：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。 2.并行事务会出现哪些问题？2.1脏读如果一个事务「读到」了另一个「未提交事务修改过的数据」，就意味着发生了「脏读」现象。 2.2不可重复读在一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况，就意味着发生了「不可重复读」现象。 2.3幻读在一个事务内多次查询某个符合查询条件的「记录数量」，如果出现前后两次查询到的记录数量不一样的情况，就意味着发生了「幻读」现象。 总结来说： 脏读：读到其他事务未提交的数据； 不可重复读：前后读取的数据不一致； 幻读：前后读取的记录数量不一致。 三种问题的严重性： 脏读 &gt; 不可重复读 &gt; 幻读 3.四种隔离级别3.1四种隔离级别分别有哪些？ 读未提交（read uncommitted），指一个事务还没提交时，它做的变更就能被其他事务看到； 读提交（read committed），指一个事务提交之后，它做的变更才能被其他事务看到； 可重复读（repeatable read），指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，MySQL InnoDB 引擎的默认隔离级别； 串行化（serializable ）；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行； 四种隔离级别的隔离能力： 3.2四种隔离级别下可能发生的问题？ 3.3Innodb采用哪种事务隔离方式？MySQL InnoDB 引擎的默认隔离级别是「可重复读」，但是它很大程度上避免幻读现象（并不是完全解决了），解决的方案有两种： 针对快照读（普通 select 语句），是通过 MVCC 方式解决了幻读，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。 针对当前读（select … for update 等语句），是通过 next-key lock（记录锁+间隙锁）方式解决了幻读，因为当执行 select … for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。 3.4读提交和可重复读有哪些共同点和不同点？二者都是通过 Read View 来实现的，它们的区别在于创建 Read View 的时机不同， Read View 称之为数据快照，「读提交」隔离级别是在「每个语句执行前」都会重新生成一个 Read View，而「可重复读」隔离级别是「启动事务时」生成一个 Read View，然后整个事务期间都在用这个 Read View。 3.5Read View 在 MVCC 中的工作状态MVCC：多版本并发控制 3.5.1 Read View 的结构 Read View 有四个重要的字段： m_ids ：指的是在创建 Read View 时，当前数据库中「活跃事务」的事务 id 列表，注意是一个列表，“活跃事务”指的就是，启动了但还没提交的事务。 min_trx_id ：指的是在创建 Read View 时，当前数据库中「活跃事务」中事务 id 最小的事务，也就是 m_ids 的最小值。 max_trx_id ：这个并不是 m_ids 的最大值，而是创建 Read View 时当前数据库中应该给下一个事务的 id 值，也就是全局事务中最大的事务 id 值 + 1； creator_trx_id ：指的是创建该 Read View 的事务的事务 id。 隐藏列： 对于使用 InnoDB 存储引擎的数据库表，它的聚簇索引记录中都包含下面两个隐藏列： trx_id，当一个事务对某条聚簇索引记录进行改动时，就会把该事务的事务 id 记录在 trx_id 隐藏列里； roll_pointer，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后这个隐藏列是个指针，指向每一个旧版本记录，于是就可以通过它找到修改前的记录。 事务处于不同情况的结果： 一个事务去访问记录的时候，除了自己的更新记录总是可见之外，还有这几种情况： 如果记录的 trx_id 值小于 Read View 中的 min_trx_id 值，表示这个版本的记录是在创建 Read View 前已经提交的事务生成的，所以该版本的记录对当前事务可见。 如果记录的 trx_id 值大于等于 Read View 中的 max_trx_id 值，表示这个版本的记录是在创建 Read View 后才启动的事务生成的，所以该版本的记录对当前事务不可见。 如果记录的 trx_id 值在 Read View 的 min_trx_id和max_trx_id之间，需要判断 trx_id 是否在 m_ids 列表中： 如果记录的 trx_id 在 m_ids 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务不可见。 如果记录的 trx_id 不在 m_ids列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务可见。 3.5.2可重复读如何实现可重复读隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View。 由于隔离级别时「可重复读」，所以当事务 A 修改数据并提交记录之后，事务 B 再次读取记录时，还是基于启动事务时创建的 Read View 来判断当前版本的记录是否可见。也就是说，事务 id = 51 仍然在 m_ids 中，因此读取的数据依旧是事务 A 提交之前的值。 3.5.3读提交如何实现读提交隔离级别是在每次读取数据时，都会生成一个新的 Read View。 也就是在第三次读取数据的时候，m_ids 中已经不含 id = 51，即读取到的是事务 A 处理之后的结果。 4.小结事务隔离级别 事务是在 MySQL 引擎层实现的，我们常见的 InnoDB 引擎是支持事务的，事务的四大特性是原子性、一致性、隔离性、持久性。 当多个事务并发执行的时候，会引发脏读、不可重复读、幻读这些问题，那为了避免这些问题，SQL 提出了四种隔离级别，分别是读未提交、读已提交、可重复读、串行化，从左往右隔离级别顺序递增，隔离级别越高，意味着性能越差，InnoDB 引擎的默认隔离级别是可重复读。 要解决脏读现象，就要将隔离级别升级到读已提交以上的隔离级别，要解决不可重复读现象，就要将隔离级别升级到可重复读以上的隔离级别。而对于幻读现象，不建议将隔离级别升级为串行化，因为这会导致数据库并发时性能很差。 MySQL InnoDB 引擎的默认隔离级别虽然是「可重复读」，但是它很大程度上避免幻读现象（并不是完全解决了），解决的方案有两种： 针对快照读（普通 select 语句），是通过 MVCC 方式解决了幻读，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。 针对当前读（select … for update 等语句），是通过 next-key lock（记录锁+间隙锁）方式解决了幻读，因为当执行 select … for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。 对于「读提交」和「可重复读」隔离级别的事务来说，它们是通过 Read View 来实现的，它们的区别在于创建 Read View 的时机不同： 「读提交」隔离级别是在每个 select 都会生成一个新的 Read View，也意味着，事务期间的多次读取同一条数据，前后两次读的数据可能会出现不一致，因为可能这期间另外一个事务修改了该记录，并提交了事务。 「可重复读」隔离级别是启动事务时生成一个 Read View，然后整个事务期间都在用这个 Read View，这样就保证了在事务期间读到的数据都是事务启动前的记录。 这两个隔离级别实现是通过「事务的 Read View 里的字段」和「记录中的两个隐藏列」的比对，来控制并发事务访问同一个记录时的行为，这就叫 MVCC（多版本并发控制）。 在可重复读隔离级别中，普通的 select 语句就是基于 MVCC 实现的快照读，也就是不会加锁的。而 select .. for update 语句就不是快照读了，而是当前读了，也就是每次读都是拿到最新版本的数据，但是它会对读到的记录加上 next-key lock 锁。 追问：InnoDB 在很大程度上避免了幻读现象的出现，那么，完全避免了吗？哪些情况下会出现幻读？ 答：没有完全避免，出现幻读主要有两种情况。 对于快照读解决幻读问题， MVCC 并不能完全避免幻读现象。因为当事务 A 更新了一条事务 B 插入的记录，那么事务 A 前后两次查询的记录条目就不一样了，所以就发生幻读。 对于当前读，如果事务开启后，并没有执行当前读，而是先快照读，然后这期间如果其他事务插入了一条记录，那么事务后续使用当前读进行查询的时候，就会发现两次查询的记录条目就不一样了，所以就发生幻读。 T1 时刻：事务 A 先执行「快照读语句」：select * from t_test where id &gt; 100 得到了 3 条记录。 T2 时刻：事务 B 往插入一个 id= 200 的记录并提交； T3 时刻：事务 A 再执行「当前读语句」 select * from t_test where id &gt; 100 for update 就会得到 4 条记录，此时也发生了幻读现象。 要避免这类特殊场景下发生幻读的现象的话，就是尽量在开启事务之后，马上执行 select … for update 这类当前读的语句，因为它会对记录加 next-key lock，从而避免其他事务插入一条新记录。 锁篇1.锁的分类1.1全局锁全局锁指的是，当打开之后，数据库进入只读状态。全局锁主要应用于做全库逻辑备份，这样在备份数据库期间，不会因为数据或表结构的更新，而出现备份文件的数据与预期的不一样。 缺点： 如果数据库里有很多数据，备份就会花费很多的时间，关键是备份期间，业务只能读数据，而不能更新数据，这样会造成业务停滞。 解决办法： 如果数据库的引擎支持的事务支持可重复读的隔离级别，那么在备份数据库之前先开启事务，会先创建 Read View，然后整个事务执行期间都在用这个 Read View，而且由于 MVCC 的支持，备份期间业务依然可以对数据进行更新操作。 1.2表级锁1.2.1表锁当添加共享表锁之后，本线程与其他线程对表进行的写操作都会被阻塞。但是，表锁的颗粒度太大，应该使用其他颗粒度比较小的锁。 1.2.2元数据锁MDL 是为了保证当用户对表执行 CRUD 操作时，防止其他线程对这个表结构做了变更。我们不需要显示的使用 MDL，因为当我们对数据库表进行操作时，会自动给这个表加上 MDL： 对一张表进行 CRUD 操作时，加的是 MDL 读锁； 对一张表做结构变更操作的时候，加的是 MDL 写锁； 当有线程在执行 select 语句（ 加 MDL 读锁）的期间，如果有其他线程要更改该表的结构（ 申请 MDL 写锁），那么将会被阻塞，直到执行完 select 语句（ 释放 MDL 读锁）。 反之，当有线程对表结构进行变更（ 加 MDL 写锁）的期间，如果有其他线程执行了 CRUD 操作（ 申请 MDL 读锁），那么就会被阻塞，直到表结构变更完成（ 释放 MDL 写锁）。 追问：MDL 不需要显示调用，那它是在什么时候释放的? MDL 是在事务提交后才会释放，这意味着事务执行期间，MDL 是一直持有的。 这种形式有什么缺点？ 1234那如果数据库有一个长事务（所谓的长事务，就是开启了事务，但是一直还没提交），那在对表结构做变更操作的时候，可能会发生意想不到的事情，比如下面这个顺序的场景：1. 首先，线程 A 先启用了事务（但是一直不提交），然后执行一条 select 语句，此时就先对该表加上 MDL 读锁；2. 然后，线程 B 也执行了同样的 select 语句，此时并不会阻塞，因为「读读」并不冲突；3. 接着，线程 C 修改了表字段，此时由于线程 A 的事务并没有提交，也就是 MDL 读锁还在占用着，这时线程 C 就无法申请到 MDL 写锁，就会被阻塞，那么在线程 C 阻塞后，后续有对该表的 select 语句，就都会被阻塞，如果此时有大量该表的 select 语句的请求到来，就会有大量的线程被阻塞住，这时数据库的线程很快就会爆满了。 原因：（为什么线程 C 因为申请不到 MDL 写锁，而导致后续的申请读锁的查询操作也会被阻塞？） 这是因为申请 MDL 锁的操作会形成一个队列，队列中写锁获取优先级高于读锁，一旦出现 MDL 写锁等待，会阻塞后续该表的所有 CRUD 操作。 1.2.3意向锁 在使用 InnoDB 引擎的表里对某些记录加上「共享锁」之前，需要先在表级别加上一个「意向共享锁」； 在使用 InnoDB 引擎的表里对某些纪录加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」； 也就是，当执行插入、更新、删除操作，需要先对表加上「意向独占锁」，然后对该记录加独占锁。 意向共享锁和意向独占锁是表级锁，不会和行级的共享锁和独占锁发生冲突，而且意向锁之间也不会发生冲突，只会和共享表锁（lock tables … read）和独占表锁（lock tables … write）发生冲突。 如果没有「意向锁」，那么加「独占表锁」时，就需要遍历表里所有记录，查看是否有记录存在独占锁，这样效率会很慢。 那么有了「意向锁」，由于在对记录加独占锁前，先会加上表级别的意向独占锁，那么在加「独占表锁」时，直接查该表是否有意向独占锁，如果有就意味着表里已经有记录被加了独占锁，这样就不用去遍历表里的记录。 所以，意向锁的目的是为了快速判断表里是否有记录被加锁。 1.2.4AUTO-INC锁在插入数据的时候，会为被 AUTO_INCREMENT 修饰的字段加上轻量级锁，然后给该字段赋值一个自增的值，就把这个轻量级锁释放了，而不需要等待整个插入语句执行完后才释放锁。 1.3行级锁共享锁（S锁）满足读读共享，读写互斥。独占锁（X锁）满足写写互斥、读写互斥。 在读已提交隔离级别下，行级锁的种类只有记录锁，也就是仅仅把一条记录锁上。 在可重复读隔离级别下，行级锁的种类除了有记录锁，还有间隙锁（目的是为了避免幻读），所以行级锁的种类主要有三类： Record Lock，记录锁，也就是仅仅把一条记录锁上；例如锁定 id=1 这个数据。（有 X 型和 S 型的区别）。当事务加入记录锁之后，其他事务对该数据进行删除和修改的时候会发生阻塞；但是插入 id=1 这条数据时不会发生阻塞，但是会主键冲突。 Gap Lock，间隙锁，锁定一个范围，但是不包含记录本身；例如锁定 (3,5) 之间的数据。当事务加入这样一个间隙锁之后，其他事务不能对 id=4 进行插入修改和删除。 Next-Key Lock：Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。例如锁定 (3,5] 数据。当事务加入这样一个间隙锁之后，其他事务不能对 id=4 5 进行插入修改和删除。 插入意向锁 一个事务在插入一条记录的时候，需要判断插入位置是否已被其他事务加了间隙锁（next-key lock 也包含间隙锁）。 如果有的话，插入操作就会发生阻塞，直到拥有间隙锁的那个事务提交为止（释放间隙锁的时刻），在此期间会生成一个插入意向锁，表明有事务想在某个区间插入新记录，但是现在处于等待状态。 插入意向锁名字虽然有意向锁，但是它并不是意向锁，它是一种特殊的间隙锁，属于行级别锁。 如果说间隙锁锁住的是一个区间，那么「插入意向锁」锁住的就是一个点。因而从这个角度来说，插入意向锁确实是一种特殊的间隙锁。 插入意向锁与间隙锁的另一个非常重要的差别是：尽管「插入意向锁」也属于间隙锁，但两个事务却不能在同一时间内，一个拥有间隙锁，另一个拥有该间隙区间内的插入意向锁（当然，插入意向锁如果不在间隙锁区间内则是可以的）。 2.什么 SQL 语句会加行级锁？ 普通的 select 语句是不会对记录加锁的（除了串行化隔离级别），因为它属于快照读，是通过 MVCC（多版本并发控制）实现的。 如果要在查询时对记录加行级锁，可以使用下面这两个方式，这两种查询会加锁的语句称为锁定读。 1234//对读取的记录加共享锁(S型锁)select ... lock in share mode;//对读取的记录加独占锁(X型锁)select ... for update; **update 和 delete 操作都会加行级锁，且锁的类型都是独占锁(X型锁)**。 3.MySQL 加锁规则唯一索引等值查询： 当查询的记录是「存在」的，在索引树上定位到这一条记录后，将该记录的索引中的 next-key lock 会退化成「记录锁」。 当查询的记录是「不存在」的，在索引树找到第一条大于该查询记录的记录后，将该记录的索引中的 next-key lock 会退化成「间隙锁」。 为什么唯一索引等值查询并且查询记录存在的场景下，该记录的索引中的 next-key lock 会退化成记录锁？ 原因就是在唯一索引等值查询并且查询记录存在的场景下，仅靠记录锁也能避免幻读的问题。 由于主键具有唯一性，所以其他事务插入 id = 1 的时候，会因为主键冲突，导致无法插入 id = 1 的新记录。这样事务 A 在多次查询 id = 1 的记录的时候，不会出现前后两次查询的结果集不同，也就避免了幻读的问题。 由于对 id = 1 加了记录锁，其他事务无法删除该记录，这样事务 A 在多次查询 id = 1 的记录的时候，不会出现前后两次查询的结果集不同，也就避免了幻读的问题。 为什么唯一索引等值查询并且查询记录「不存在」的场景下，在索引树找到第一条大于该查询记录的记录后，要将该记录的索引中的 next-key lock 会退化成「间隙锁」？ 原因就是在唯一索引等值查询并且查询记录不存在的场景下，仅靠间隙锁就能避免幻读的问题。 为什么 id = 5 记录上的主键索引的锁不可以是 next-key lock？如果是 next-key lock，就意味着其他事务无法删除 id = 5 这条记录，但是这次的案例是查询 id = 2 的记录，只要保证前后两次查询 id = 2 的结果集相同，就能避免幻读的问题了，所以即使 id =5 被删除，也不会有什么影响，那就没必须加 next-key lock，因此只需要在 id = 5 加间隙锁，避免其他事务插入 id = 2 的新记录就行了。 为什么不可以针对不存在的记录加记录锁？锁是加在索引上的，而这个场景下查询的记录是不存在的，自然就没办法锁住这条不存在的记录。 非唯一索引等值查询： 当查询的记录「存在」时，由于不是唯一索引，所以肯定存在索引值相同的记录，于是非唯一索引等值查询的过程是一个扫描的过程，直到扫描到第一个不符合条件的二级索引记录就停止扫描，然后在扫描的过程中，对扫描到的二级索引记录加的是 next-key 锁，而对于第一个不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。同时，在符合查询条件的记录的主键索引上加记录锁。（例如条件式查找age = 22，那么就会在(21, 22]创建next-key锁，在(22，下一个值)创建间隙锁） 当查询的记录「不存在」时，扫描到第一条不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。因为不存在满足查询条件的记录，所以不会对主键索引加锁。 非唯一索引和主键索引的范围查询的加锁规则不同之处在于： 唯一索引在满足一些条件的时候，索引的 next-key lock 退化为间隙锁或者记录锁。 非唯一索引范围查询，索引的 next-key lock 不会退化为间隙锁和记录锁。 其实理解 MySQL 为什么要这样加锁，主要要以避免幻读角度去分析，这样就很容易理解这些加锁的规则了。 还有一件很重要的事情，在线上在执行 update、delete、select … for update 等具有加锁性质的语句，一定要检查语句是否走了索引，如果是全表扫描的话，会对每一个索引加 next-key 锁，相当于把整个表锁住了，这是挺严重的问题。 唯一索引范围查询当唯一索引进行范围查询时，会对每一个扫描到的索引加 next-key 锁，然后如果遇到下面这些情况，会退化成记录锁或者间隙锁： 情况一：针对「大于等于」的范围查询，因为存在等值查询的条件，那么如果等值查询的记录是存在于表中，那么该记录的索引中的 next-key 锁会退化成记录锁。其余地方还是 next-key 锁。（如：id = 15 (15,20] (20,∞]）。 情况二：针对「大于」的范围查询，不会退化，依旧是 next-key 锁，按照表中记录分段为多个 next-key 锁。（如：(15,20] (20,∞]） 情况二：针对「小于或者小于等于」的范围查询，要看条件值的记录是否存在于表中： 当条件值的记录不在表中，那么不管是「小于」还是「小于等于」条件的范围查询，扫描到终止范围查询的记录时，该记录的索引的 next-key 锁会退化成间隙锁，其他扫描到的记录，都是在这些记录的索引上加 next-key 锁。 当条件值的记录在表中，如果是「小于」条件的范围查询，扫描到终止范围查询的记录时，该记录的索引的 next-key 锁会退化成间隙锁，其他扫描到的记录，都是在这些记录的索引上加 next-key 锁；如果「小于等于」条件的范围查询，扫描到终止范围查询的记录时，该记录的索引 next-key 锁不会退化成间隙锁。其他扫描到的记录，都是在这些记录的索引上加 next-key 锁。 非唯一索引范围查询不同之处在于非唯一索引范围查询，索引的 next-key lock 不会有退化为间隙锁和记录锁的情况，也就是非唯一索引进行范围查询时，对二级索引记录加锁都是加 next-key 锁。 没有加索引的查询如果锁定读查询语句，没有使用索引列作为查询条件，或者查询语句没有走索引查询，导致扫描是全表扫描。那么，每一条记录的索引上都会加 next-key 锁，这样就相当于锁住的全表，这时如果其他事务对该表进行增、删、改操作的时候，都会被阻塞。 不只是锁定读查询语句不加索引才会导致这种情况，update 和 delete 语句如果查询条件不加索引，那么由于扫描的方式是全表扫描，于是就会对每一条记录的索引上都会加 next-key 锁，这样就相当于锁住的全表。 因此，在线上在执行 update、delete、select … for update 等具有加锁性质的语句，一定要检查语句是否走了索引，如果是全表扫描的话，会对每一个索引加 next-key 锁，相当于把整个表锁住了，这是挺严重的问题。 4.update 语句锁全表情况说明：在执行一条 update 语句修改数据库数据的时候，where 条件没有带上索引，就会将数据库全表上锁。 原因： 在 update 语句的 where 条件没有使用索引，就会全表扫描，于是就会对所有记录加上 next-key 锁（记录锁 + 间隙锁），相当于把整个表锁住了。 追问：如果使用了 where 索引，就不会加锁了吗？ 不一定。关键还得看这条语句在执行过程种，优化器最终选择的是索引扫描，还是全表扫描，如果走了全表扫描，就会对全表的记录加锁了。 如何避免这种情况的出现？ 我们可以将 MySQL 里的 sql_safe_updates 参数设置为 1，开启安全更新模式。 当 sql_safe_updates 设置为 1 时。 update 语句必须满足如下条件之一才能执行成功： 使用 where，并且 where 条件中必须有索引列； 使用 limit； 同时使用 where 和 limit，此时 where 条件中可以没有索引列； delete 语句必须满足以下条件能执行成功： 同时使用 where 和 limit，此时 where 条件中可以没有索引列； 5.MySQL 记录锁+间隙锁可以防止删除操作而导致的幻读吗？在 MySQL 的可重复读隔离级别下，针对当前读的语句会对索引加记录锁+间隙锁，这样可以避免其他事务执行增、删、改时导致幻读的问题。 6.MySQL 中的死锁6.1死锁情况的产生假设这时有两事务，一个事务要插入订单 1007 ，另外一个事务要插入订单 1008，因为需要对订单做幂等性校验，所以两个事务先要查询该订单是否存在，不存在才插入记录，过程如下： 事务 A 在二级索引（INDEX_NAME : index_order）上加的是 X 型的 next-key 锁，锁范围是(1006, +∞]。 当事务 B 往事务 A next-key 锁的范围 (1006, +∞] 里插入 id = 1008 的记录就会被锁住。此时会在插入间隙上获取插入意向锁，而插入意向锁与间隙锁是冲突的，所以当其它事务持有该间隙的间隙锁时，需要等待其它事务释放间隙锁之后，才能获取到插入意向锁。而间隙锁与间隙锁之间是兼容的，所以所以两个事务中 select ... for update 语句并不会相互影响。 案例中的事务 A 和事务 B 在执行完后 select ... for update 语句后都持有范围为(1006,+∞]的next-key 锁，而接下来的插入操作为了获取到插入意向锁，都在等待对方事务的间隙锁释放，于是就造成了循环等待，导致死锁。 追问：为什么此时事务 A 和事务 B 都持有 next-key 锁？ 首先在此之前，先看官网上对于间隙锁的描述。间隙锁的意义只在于阻止区间被插入，因此是可以共存的。一个事务获取的间隙锁不会阻止另一个事务获取同一个间隙范围的间隙锁，共享和排他的间隙锁是没有区别的，他们相互不冲突，且功能相同，即两个事务可以同时持有包含共同间隙的间隙锁。 这里的共同间隙包括两种场景： 其一是两个间隙锁的间隙区间完全一样； 其二是一个间隙锁包含的间隙区间是另一个间隙锁包含间隙区间的子集。 next-key lock 是包含间隙锁+记录锁的，如果一个事务获取了 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，是会被阻塞的。对于这种范围为 (1006, +∞] 的 next-key lock，两个事务是可以同时持有的，不会冲突。因为 +∞ 并不是一个真实的记录，自然就不需要考虑 X 型与 S 型关系。 6.1.1插入意向锁插入意向锁是一种特殊的间隙锁，但不同于间隙锁的是，该锁只用于并发插入操作。 如果说间隙锁锁住的是一个区间，那么「插入意向锁」锁住的就是一个点。因而从这个角度来说，插入意向锁确实是一种特殊的间隙锁。 插入意向锁与间隙锁的另一个非常重要的差别是：尽管「插入意向锁」也属于间隙锁，但两个事务却不能在同一时间内，一个拥有间隙锁，另一个拥有该间隙区间内的插入意向锁（当然，插入意向锁如果不在间隙锁区间内则是可以的）。 另外，我补充一点，插入意向锁的生成时机： 每插入一条新记录，都需要看一下待插入记录的下一条记录上是否已经被加了间隙锁，如果已加间隙锁，此时会生成一个插入意向锁，然后锁的状态设置为等待状态（PS：MySQL 加锁时，是先生成锁结构，然后设置锁的状态，如果锁状态是等待状态，并不是意味着事务成功获取到了锁，只有当锁状态为正常状态时，才代表事务成功获取到了锁），现象就是 Insert 语句会被阻塞。 6.2如何避免死锁？死锁的四个必要条件：互斥、占有且等待、不可强占用、循环等待。只要系统发生死锁，这些条件必然成立，但是只要破坏任意一个条件就死锁就不会成立。 在数据库层面，有两种策略通过「打破循环等待条件」来解除死锁状态： 设置事务等待锁的超时时间。当一个事务的等待时间超过该值后，就对这个事务进行回滚，于是锁就释放了，另一个事务就可以继续执行了。在 InnoDB 中，参数 innodb_lock_wait_timeout 是用来设置超时时间的，默认值时 50 秒。 开启主动死锁检测。主动死锁检测在发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑，默认就开启。 7.Insert 如何加锁Insert 语句在正常执行时是不会生成锁结构的，它是靠聚簇索引记录自带的 trx_id 隐藏列来作为隐式锁来保护记录的。 什么是隐式锁？ 当事务需要加锁的时，如果这个锁不可能发生冲突，InnoDB会跳过加锁环节，这种机制称为隐式锁。隐式锁是 InnoDB 实现的一种延迟加锁机制，其特点是只有在可能发生冲突时才加锁，从而减少了锁的数量，提高了系统整体性能。 追问：隐式锁就是在 Insert 过程中不加锁，只有在特殊情况下，才会将隐式锁转换为显示锁，列举两个显示锁的场景。 如果记录之间加有间隙锁，为了避免幻读，此时是不能插入记录的； 假设首先事务 A 对 (1005,+∞] 加锁；此时事务 B 想要添加 order = 1010 的数据，因为向事务 A 生成的 next-key 锁（记录锁+间隙锁）范围（1005, +∞] 中插入了一条记录，所以事务 B 的插入操作生成了一个插入意向锁（LOCK_MODE: ,INSERT_INTENTION），锁的状态是等待状态，意味着事务 B 并没有成功获取到插入意向锁，因此事务 B 发生阻塞。 如果 Insert 的记录和已有记录存在唯一键冲突，此时也不能插入记录； 主键唯一索引。在隔离级别是「可重复读」的情况下，如果在插入数据的时候，发生了主键索引冲突，插入新记录的事务会给已存在的主键值重复的聚簇索引记录添加 S 型记录锁。 唯一二级索引。 表中的 order_no 字段为唯一二级索引，并且已经存在 order_no 值为 1001 的记录，此时事务 A，插入了 order_no 为 1001 的记录，就出现了报错。除了报错之外，还做一个很重要的事情，就是对 order_no 值为 1001 这条记录加上了 S 型的 next-key 锁。**范围是(-∞, 1001]**。 分析两个事务执行过程中，执行了相同的 insert 语句的场景。 在隔离级别可重复读的情况下，开启两个事务，前后执行相同的 Insert 语句，此时事务 B 的 Insert 语句会发生阻塞。 两个事务的加锁过程： 事务 A 先插入 order_no 为 1006 的记录，可以插入成功，此时对应的唯一二级索引记录被「隐式锁」保护，此时还没有实际的锁结构（执行完这里的时候，你可以看查 performance_schema.data_locks 信息，可以看到这条记录是没有加任何锁的）； 接着，事务 B 也插入 order_no 为 1006 的记录，由于事务 A 已经插入 order_no 值为 1006 的记录，所以事务 B 在插入二级索引记录时会遇到重复的唯一二级索引列值，此时事务 B 想获取一个 S 型 next-key 锁，但是事务 A 并未提交，事务 A 插入的 order_no 值为 1006 的记录上的「隐式锁」会变「显示锁」且锁类型为 X 型的记录锁，所以事务 B 向获取 S 型 next-key 锁时会遇到锁冲突，事务 B 进入阻塞状态。 注意：如果不是二级索引，那么是可以insert相同记录的 日志篇1.执行一条 update 语句会发生什么？ 客户端先通过连接器建立连接，连接器自会判断用户身份； 因为这是一条 update 语句，所以不需要经过查询缓存，但是表上有更新语句，是会把整个表的查询缓存清空的，所以说查询缓存很鸡肋，在 MySQL 8.0 就被移除这个功能了； 解析器会通过词法分析识别出关键字 update，表名等等，构建出语法树，接着做语法分析，判断输入的语句是否符合 MySQL 语法； 预处理器会判断表和字段是否存在； 优化器确定执行计划，因为 where 条件中的 id 是主键索引，所以决定要使用 id 这个索引； 执行器负责具体执行，找到这一行，然后更新。 2.执行 update 会涉及到哪些日志？ undo log（回滚日志）：是 Innodb 存储引擎层生成的日志，实现了事务中的原子性，主要用于事务回滚和 MVCC。 redo log（重做日志）：是 Innodb 存储引擎层生成的日志，实现了事务中的持久性，主要用于掉电等故障恢复； binlog （归档日志）：是 Server 层生成的日志，主要用于数据备份和主从复制； 2.1 undo log 有哪些作用？ 实现事务回滚，保障事务的原子性。事务处理过程中，如果出现了错误或者用户执 行了 ROLLBACK 语句，MySQL 可以利用 undo log 中的历史数据将数据恢复到事务开始之前的状态。 实现 MVCC（多版本并发控制）关键因素之一。MVCC 是通过 ReadView + undo log 实现的。undo log 为每条记录保存多份历史数据，MySQL 在执行快照读（普通 select 语句）的时候，会根据事务的 Read View 里的信息，顺着 undo log 的版本链找到满足其可见性的记录。 2.2 为什么需要 Buffer Pool？ 当修改数据时，如果数据存在于 Buffer Pool 中，那直接修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页（该页的内存数据和磁盘上的数据已经不一致），为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。 当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。 在 MySQL 启动的时候，InnoDB 会为 Buffer Pool 申请一片连续的内存空间，然后按照默认的16KB的大小划分出一个个的页， Buffer Pool 中的页就叫做缓存页。此时这些缓存页都是空闲的，之后随着程序的运行，才会有磁盘上的页被缓存到 Buffer Pool 中。 2.3 为什么需要 redo log？ 实现事务的持久性，让 MySQL 有 crash-safe 的能力，能够保证 MySQL 在任何时间段突然崩溃，重启后之前已提交的记录都不会丢失； 将写操作从「随机写」变成了「顺序写」，提升 MySQL 写入磁盘的性能。 什么是 redo log？redo log 是物理日志，记录了某个数据页做了什么修改，比如对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新，每当执行一个事务就会产生这样的一条或者多条物理日志。 在事务提交时，只要先将 redo log 持久化到磁盘即可，可以不需要等到将缓存在 Buffer Pool 里的脏页数据持久化到磁盘。 当系统崩溃时，虽然脏页数据没有持久化，但是 redo log 已经持久化，接着 MySQL 重启后，可以根据 redo log 的内容，将所有数据恢复到最新的状态。 追问：redo log 和 undo log 有什么区别？ redo log 记录了此次事务「完成后」的数据状态，记录的是更新之后的值； undo log 记录了此次事务「开始前」的数据状态，记录的是更新之前的值； 事务提交之前发生了崩溃，重启后会通过 undo log 回滚事务 事务提交之后发生了崩溃，重启后会通过 redo log 恢复事务， redo log 要写到磁盘，数据也要写磁盘，为什么要多此一举？ 写入 redo log 的方式使用了追加操作， 所以磁盘操作是顺序写，而写入数据需要先找到写入位置，然后才写到磁盘，所以磁盘操作是随机写。 磁盘的「顺序写 」比「随机写」 高效的多，因此 redo log 写入磁盘的开销更小。 针对「顺序写」为什么比「随机写」更快这个问题，可以比喻为你有一个本子，按照顺序一页一页写肯定比写一个字都要找到对应页写快得多。 可以说这是 WAL 技术的另外一个优点：MySQL 的写操作从磁盘的「随机写」变成了「顺序写」，提升语句的执行性能。这是因为 MySQL 的写操作并不是立刻更新到磁盘上，而是先记录在日志上，然后在合适的时间再更新到磁盘上 。 产生的 redo log 是直接写入磁盘的吗？ 不是的。 执行一个事务的过程中，产生的 redo log 也不是直接写入磁盘的，因为这样会产生大量的 I/O 操作，而且磁盘的运行速度远慢于内存。 所以，redo log 也有自己的缓存—— redo log buffer，每当产生一条 redo log 时，会先写入到 redo log buffer，后续在持久化到磁盘 缓存在 redo log buffer 里的 redo log 还是在内存中，它什么时候刷新到磁盘？ MySQL 正常关闭时； 当 redo log buffer 中记录的写入量大于 redo log buffer 内存空间的一半时，会触发落盘； InnoDB 的后台线程每隔 1 秒，将 redo log buffer 持久化到磁盘。 每次事务提交时都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘（由参数 innodb_flush_log_at_trx_commit 控制） innodb_flush_log_at_trx_commit 参数控制的是什么？ 当设置该参数为 0 时，表示每次事务提交时 ，还是将 redo log 留在 redo log buffer 中 ，该模式下在事务提交时不会主动触发写入磁盘的操作。 当设置该参数为 1 时，表示每次事务提交时，都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘，这样可以保证 MySQL 异常重启之后数据不会丢失。 当设置该参数为 2 时，表示每次事务提交时，都只是缓存在 redo log buffer 里的 redo log 写到 redo log 文件，注意写入到「 redo log 文件」并不意味着写入到了磁盘，因为操作系统的文件系统中有个 Page Cache 专门用来缓存文件数据的，所以写入「 redo log文件」意味着写入到了操作系统的文件缓存。 针对参数 0 ：会把缓存在 redo log buffer 中的 redo log ，通过调用 write() 写到操作系统的 Page Cache，然后调用 fsync() 持久化到磁盘。所以参数为 0 的策略，MySQL 进程的崩溃会导致上一秒钟所有事务数据的丢失; 针对参数 2 ：调用 fsync，将缓存在操作系统中 Page Cache 里的 redo log 持久化到磁盘。所以参数为 2 的策略，较取值为 0 情况下更安全，因为 MySQL 进程的崩溃并不会丢失数据，只有在操作系统崩溃或者系统断电的情况下，上一秒钟所有事务数据才可能丢失。 数据安全性：参数 1 &gt; 参数 2 &gt; 参数 0 写入性能：参数 0 &gt; 参数 2&gt; 参数 1 redo log满了怎么办？ 这时 MySQL 不能再执行新的更新操作，也就是说 MySQL 会被阻塞（因此所以针对并发量大的系统，适当设置 redo log 的文件大小非常重要），此时会停下来将 Buffer Pool 中的脏页刷新到磁盘中，然后标记 redo log 哪些记录可以被擦除，接着对旧的 redo log 记录进行擦除，等擦除完旧记录腾出了空间，checkpoint 就会往后移动（图中顺时针），然后 MySQL 恢复正常运行，继续执行新的更新操作。 2.4 为什么需要 binlog？MySQL 在完成一条更新操作后，Server 层还会生成一条 binlog，等之后事务提交的时候，会将该事物执行过程中产生的所有 binlog 统一写 入 binlog 文件。 binlog 文件是记录了所有数据库表结构变更和表数据修改的日志，不会记录查询类的操作，比如 SELECT 和 SHOW 操作。 为什么有了 binlog， 还要有 redo log？ 这个问题跟 MySQL 的时间线有关系。 最开始 MySQL 里并没有 InnoDB 引擎，MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用 redo log 来实现 crash-safe 能力。 那么binlog和redo log有什么区别？ 1、适用对象不同： binlog 是 MySQL 的 Server 层实现的日志，所有存储引擎都可以使用； redo log 是 Innodb 存储引擎实现的日志； 2、文件格式不同： binlog 有 3 种格式类型，分别是 STATEMENT（默认格式）、ROW、 MIXED，区别如下： STATEMENT：每一条修改数据的 SQL 都会被记录到 binlog 中（相当于记录了逻辑操作，所以针对这种格式， binlog 可以称为逻辑日志），主从复制中 slave 端再根据 SQL 语句重现。但 STATEMENT 有动态函数的问题，比如你用了 uuid 或者 now 这些函数，你在主库上执行的结果并不是你在从库执行的结果，这种随时在变的函数会导致复制的数据不一致； ROW：记录行数据最终被修改成什么样了（这种格式的日志，就不能称为逻辑日志了），不会出现 STATEMENT 下动态函数的问题。但 ROW 的缺点是每行数据的变化结果都会被记录，比如执行批量 update 语句，更新多少行数据就会产生多少条记录，使 binlog 文件过大，而在 STATEMENT 格式下只会记录一个 update 语句而已； MIXED：包含了 STATEMENT 和 ROW 模式，它会根据不同的情况自动使用 ROW 模式和 STATEMENT 模式； redo log 是物理日志，记录的是在某个数据页做了什么修改，比如对 XXX 表空间中的 YYY 数据页 ZZZ 偏移量的地方做了AAA 更新； 3、写入方式不同： binlog 是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志。 redo log 是循环写，日志空间大小是固定，全部写满就从头开始，保存未被刷入磁盘的脏页日志。 4、用途不同： binlog 用于备份恢复、主从复制； redo log 用于掉电等故障恢复。 如果不小心整个数据库的数据被删除了，能使用 redo log 文件恢复数据吗？ 不可以使用 redo log 文件恢复，只能使用 binlog 文件恢复。 因为 redo log 文件是循环写，是会边写边擦除日志的，只记录未被刷入磁盘的数据的物理日志，已经刷入磁盘的数据都会从 redo log 文件里擦除。 binlog 文件保存的是全量的日志，也就是保存了所有数据变更的情况，理论上只要记录在 binlog 上的数据，都可以恢复，所以如果不小心整个数据库的数据被删除了，得用 binlog 文件恢复数据。 binlog 如何刷盘？ 事务执行过程中，先把日志写到 binlog cache（Server 层的 cache），事务提交的时候，再把 binlog cache 写到 binlog 文件中，并且清空 binlog cache。 一个事务的 binlog 是不能被拆开的，因此无论这个事务有多大（比如有很多条语句），也要保证一次性写入。这是因为有一个线程只能同时有一个事务在执行的设定，所以每当执行一个 begin/start transaction 的时候，就会默认提交上一个事务，这样如果一个事务的 binlog 被拆开的时候，在备库执行就会被当做多个事务分段自行，这样破坏了原子性，是有问题的。 MySQL 给每个线程分配了一片内存用于缓冲 binlog ，该内存叫 binlog cache，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。 虽然每个线程有自己 binlog cache，但是最终都写到同一个 binlog 文件： 图中的 write，指的就是指把日志写入到 binlog 文件，但是并没有把数据持久化到磁盘，因为数据还缓存在文件系统的 page cache 里，write 的写入速度还是比较快的，因为不涉及磁盘 I/O。 图中的 fsync，才是将数据持久化到磁盘的操作，这里就会涉及磁盘 I/O，所以频繁的 fsync 会导致磁盘的 I/O 升高。 MySQL提供一个 sync_binlog 参数来控制数据库的 binlog 刷到磁盘上的频率： sync_binlog = 0 的时候，表示每次提交事务都只 write，不 fsync，后续交由操作系统决定何时将数据持久化到磁盘； sync_binlog = 1 的时候，表示每次提交事务都会 write，然后马上执行 fsync； sync_binlog =N(N&gt;1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。 在MySQL中系统默认的设置是 sync_binlog = 0，也就是不做任何强制性的磁盘刷新指令，这时候的性能是最好的，但是风险也是最大的。因为一旦主机发生异常重启，还没持久化到磁盘的数据就会丢失。 而当 sync_binlog 设置为 1 的时候，是最安全但是性能损耗最大的设置。因为当设置为 1 的时候，即使主机发生异常重启，最多丢失一个事务的 binlog，而已经持久化到磁盘的数据就不会有影响，不过就是对写入性能影响太大。 如果能容少量事务的 binlog 日志丢失的风险，为了提高写入的性能，一般会 sync_binlog 设置为 100~1000 中的某个数值。 2.5执行一个 update 语句，会发生什么？ 三个日志讲完了，至此我们可以先小结下，update 语句的执行过程。 当优化器分析出成本最小的执行计划后，执行器就按照执行计划开始进行更新操作。 具体更新一条记录 UPDATE t_user SET name = 'xiaolin' WHERE id = 1; 的流程如下: 执行器负责具体执行，会调用存储引擎的接口，通过主键索引树搜索获取 id = 1 这一行记录： 如果 id=1 这一行所在的数据页本来就在 buffer pool 中，就直接返回给执行器更新； 如果记录不在 buffer pool，将数据页从磁盘读入到 buffer pool，返回记录给执行器。 执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样： 如果一样的话就不进行后续更新流程； 如果不一样的话就把更新前的记录和更新后的记录都当作参数传给 InnoDB 层，让 InnoDB 真正的执行更新记录的操作； 开启事务， InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面，不过在内存修改该 Undo 页面后，需要记录对应的 redo log。 InnoDB 层开始更新记录，会先更新内存（同时标记为脏页），然后将记录写到 redo log 里面，这个时候更新就算完成了。为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。这就是 WAL 技术，MySQL 的写操作并不是立刻写到磁盘上，而是先写 redo 日志，然后在合适的时间再将修改的行数据写到磁盘上。 至此，一条记录更新完了。 在一条更新语句执行完成后，然后开始记录该语句对应的 binlog，此时记录的 binlog 会被保存到 binlog cache，并没有刷新到硬盘上的 binlog 文件，在事务提交时才会统一将该事务运行过程中的所有 binlog 刷新到硬盘。 事务提交（为了方便说明，这里不说组提交的过程，只说两阶段提交）： prepare 阶段：将 redo log 对应的事务状态设置为 prepare，然后将 redo log 刷新到硬盘； commit 阶段：将 binlog 刷新到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为 commit（将事务设置为 commit 状态后，刷入到磁盘 redo log 文件）； 3.主从复制如何实现的？MySQL 的主从复制依赖于 binlog ，也就是记录 MySQL 上的所有变化并以二进制形式保存在磁盘上。复制的过程就是将 binlog 中的数据从主库传输到从库上。 这个过程一般是异步的，也就是主库上执行事务操作的线程不会等待复制 binlog 的线程同步完成。 MySQL 主库在收到客户端提交事务的请求之后，会先写入 binlog，再提交事务，更新存储引擎中的数据，事务提交完成后，返回给客户端“操作成功”的响应。 从库会创建一个专门的 I/O 线程，连接主库的 log dump 线程，来接收主库的 binlog 日志，再把 binlog 信息写入 relay log 的中继日志里，再返回给主库“复制成功”的响应。 从库会创建一个用于回放 binlog 的线程，去读 relay log 中继日志，然后回放 binlog 更新存储引擎中的数据，最终实现主从的数据一致性。 追问：从库的数量是不是越多越好？ 不是的。 因为从库数量增加，从库连接上来的 I/O 线程也比较多，主库也要创建同样多的 log dump 线程来处理复制的请求，对主库资源消耗比较高，同时还受限于主库的网络带宽。 所以在实际使用中，一个主库一般跟 2～3 个从库（1 套数据库，1 主 2 从 1 备主），这就是一主多从的 MySQL 集群结构。 追问：MySQL 主从复制还有哪些模型？ 同步复制：MySQL 主库提交事务的线程要等待所有从库的复制成功响应，才返回客户端结果。这种方式在实际项目中，基本上没法用，原因有两个：一是性能很差，因为要复制到所有节点才返回响应；二是可用性也很差，主库和所有从库任何一个数据库出问题，都会影响业务。 异步复制（默认模型）：MySQL 主库提交事务的线程并不会等待 binlog 同步到各从库，就返回客户端结果。这种模式一旦主库宕机，数据就会发生丢失。 半同步复制：MySQL 5.7 版本之后增加的一种复制方式，介于两者之间，事务线程不用等待所有的从库复制成功响应，只要一部分复制成功响应回来就行，比如一主二从的集群，只要数据成功复制到任意一个从库上，主库的事务线程就可以返回给客户端。这种半同步复制的方式，兼顾了异步复制和同步复制的优点，即使出现主库宕机，至少还有一个从库有最新的数据，不存在数据丢失的风险。 4.两阶段提交如何实现？ 为什么需要两阶段提交？（两阶段提交会解决什么问题？） 举个例子，假设 id = 1 这行数据的字段 name 的值原本是 ‘jay’，然后执行 UPDATE t_user SET name = 'xiaolin' WHERE id = 1; 如果在持久化 redo log 和 binlog 两个日志的过程中，出现了半成功状态，那么就有两种情况： 如果在将 redo log 刷入到磁盘之后， MySQL 突然宕机了，而 binlog 还没有来得及写入。MySQL 重启后，通过 redo log 能将 Buffer Pool 中 id = 1 这行数据的 name 字段恢复到新值 xiaolin，但是 binlog 里面没有记录这条更新语句，在主从架构中，binlog 会被复制到从库，由于 binlog 丢失了这条更新语句，从库的这一行 name 字段是旧值 jay，与主库的值不一致性； 如果在将 binlog 刷入到磁盘之后， MySQL 突然宕机了，而 redo log 还没有来得及写入。由于 redo log 还没写，崩溃恢复以后这个事务无效，所以 id = 1 这行数据的 name 字段还是旧值 jay，而 binlog 里面记录了这条更新语句，在主从架构中，binlog 会被复制到从库，从库执行了这条更新语句，那么这一行 name 字段是新值 xiaolin，与主库的值不一致性； 可以看到，在持久化 redo log 和 binlog 这两份日志的时候，如果出现半成功的状态，就会造成主从环境的数据不一致性。这是因为 redo log 影响主库的数据，binlog 影响从库的数据，所以 redo log 和 binlog 必须保持一致才能保证主从数据一致 事务的提交过程有两个阶段，就是将 redo log 的写入拆成了两个步骤：prepare 和 commit，中间再穿插写入binlog，具体如下： prepare 阶段：将 XID（内部 XA 事务的 ID） 写入到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然后将 redo log 持久化到磁盘（innodb_flush_log_at_trx_commit = 1 的作用）； commit 阶段：把 XID 写入到 binlog，然后将 binlog 持久化到磁盘（sync_binlog = 1 的作用），接着调用引擎的提交事务接口，将 redo log 状态设置为 commit，此时该状态并不需要持久化到磁盘，只需要 write 到文件系统的 page cache 中就够了，因为只要 binlog 写磁盘成功，就算 redo log 的状态还是 prepare 也没有关系，一样会被认为事务已经执行成功； 如果发生异常重启，会出现哪些现象？ 不管是时刻 A（redo log 已经写入磁盘， binlog 还没写入磁盘），还是时刻 B （redo log 和 binlog 都已经写入磁盘，还没写入 commit 标识）崩溃，此时的 redo log 都处于 prepare 状态。 在 MySQL 重启后会按顺序扫描 redo log 文件，碰到处于 prepare 状态的 redo log，就拿着 redo log 中的 XID 去 binlog 查看是否存在此 XID： 如果 binlog 中没有当前内部 XA 事务的 XID，说明 redolog 完成刷盘，但是 binlog 还没有刷盘，则回滚事务。对应时刻 A 崩溃恢复的情况。 如果 binlog 中有当前内部 XA 事务的 XID，说明 redolog 和 binlog 都已经完成了刷盘，则提交事务。对应时刻 B 崩溃恢复的情况。 可以看到，对于处于 prepare 阶段的 redo log，即可以提交事务，也可以回滚事务，这取决于是否能在 binlog 中查找到与 redo log 相同的 XID，如果有就提交事务，如果没有就回滚事务。这样就可以保证 redo log 和 binlog 这两份日志的一致性了。 所以说，两阶段提交是以 binlog 写成功为事务提交成功的标识，因为 binlog 写成功了，就意味着能在 binlog 中查找到与 redo log 相同的 XID。 两阶段提交有什么缺点？ 磁盘 I/O 次数高：对于“双1”配置，每个事务提交都会进行两次 fsync（刷盘），一次是 redo log 刷盘，另一次是 binlog 刷盘。 锁竞争激烈：两阶段提交虽然能够保证「单事务」两个日志的内容一致，但在「多事务」的情况下，却不能保证两者的提交顺序一致，因此，在两阶段提交的流程基础上，还需要加一个锁来保证提交的原子性，从而保证多事务的情况下，两个日志的提交顺序一致。 5.MySQL 磁盘 I/O 很高，有什么优化的方法？现在我们知道事务在提交的时候，需要将 binlog 和 redo log 持久化到磁盘，那么如果出现 MySQL 磁盘 I/O 很高的现象，我们可以通过控制以下参数，来 “延迟” binlog 和 redo log 刷盘的时机，从而降低磁盘 I/O 的频率： 设置组提交的两个参数： binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，延迟 binlog 刷盘的时机，从而减少 binlog 的刷盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但即使 MySQL 进程中途挂了，也没有丢失数据的风险，因为 binlog 早被写入到 page cache 了，只要系统没有宕机，缓存在 page cache 里的 binlog 就会被持久化到磁盘。 将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000），表示每次提交事务都 write，但累积 N 个事务后才 fsync，相当于延迟了 binlog 刷盘的时机。但是这样做的风险是，主机掉电时会丢 N 个事务的 binlog 日志。 将 innodb_flush_log_at_trx_commit 设置为 2。表示每次事务提交时，都只是缓存在 redo log buffer 里的 redo log 写到 redo log 文件，注意写入到「 redo log 文件」并不意味着写入到了磁盘，因为操作系统的文件系统中有个 Page Cache，专门用来缓存文件数据的，所以写入「 redo log文件」意味着写入到了操作系统的文件缓存，然后交由操作系统控制持久化到磁盘的时机。但是这样做的风险是，主机掉电的时候会丢数据。 内存篇1.为什么要有 Buffer Pool？ MySQL 的数据是存储在磁盘里，每次都从磁盘里面读取数据的话性能是很差。 所以，要想提升查询性能，需要添加缓存。当数据从磁盘中取出后，缓存内存中，下次查询同样的数据的时候，直接从内存中读取。 因此，Innodb 存储引擎设计了一个缓冲池（Buffer Pool），来提高数据库的读写性能。 2.缓存池有什么作用？ 当读取数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。 当修改数据时，首先是修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页，最后由后台线程将脏页写入到磁盘。 3.Buffer Pool 缓存什么？在 MySQL 启动的时候，InnoDB 会为 Buffer Pool 申请一片连续的内存空间，然后按照默认的16KB的大小划分出一个个的页， Buffer Pool 中的页就叫做缓存页。此时这些缓存页都是空闲的，之后随着程序的运行，才会有磁盘上的页被缓存到 Buffer Pool 中。 Buffer Pool 除了缓存「索引页」和「数据页」，还包括了 undo 页，插入缓存、自适应哈希索引、锁信息等等。 为了更好的管理这些在 Buffer Pool 中的缓存页，InnoDB 为每一个缓存页都创建了一个控制块，控制块信息包括「缓存页的表空间、页号、缓存页地址、链表节点」等等。 控制块也是占有内存空间的，它是放在 Buffer Pool 的最前面，接着才是缓存页。 上图中控制块和缓存页之间灰色部分称为碎片空间。 为什么会有碎片空间呢？ 你想想啊，每一个控制块都对应一个缓存页，那在分配足够多的控制块和缓存页后，可能剩余的那点儿空间不够一对控制块和缓存页的大小，自然就用不到喽，这个用不到的那点儿内存空间就被称为碎片了。 当然，如果你把 Buffer Pool 的大小设置的刚刚好的话，也可能不会产生碎片。 查询一条记录，就只需要缓冲一条记录吗？ 不是的。 当我们查询一条记录时，InnoDB 是会把整个页的数据加载到 Buffer Pool 中，因为，通过索引只能定位到磁盘中的页，而不能定位到页中的一条记录。将页加载到 Buffer Pool 后，再通过页里的页目录去定位到某条具体的记录。 4.如何管理空闲页？Buffer Pool 是一片连续的内存空间，当 MySQL 运行一段时间后，这片连续的内存空间中的缓存页既有空闲的，也有被使用的。 当我们从磁盘读取数据的时候，如果遍历这一片连续的内存空间来找到空闲的缓存页，效率太低。 所以，为了能够快速找到空闲的缓存页，可以使用链表结构，将空闲缓存页的「控制块」作为链表的节点，这个链表称为 Free 链表（空闲链表）。 Free 链表节点是一个一个的控制块，而每个控制块包含着对应缓存页的地址，所以相当于 Free 链表节点都对应一个空闲的缓存页。 有了 Free 链表后，每当需要从磁盘中加载一个页到 Buffer Pool 中时，就从 Free链表中取一个空闲的缓存页，并且把该缓存页对应的控制块的信息填上，然后把该缓存页对应的控制块从 Free 链表中移除。 5.如何管理脏页？设计 Buffer Pool 除了能提高读性能，还能提高写性能，也就是更新数据的时候，不需要每次都要写入磁盘，而是将 Buffer Pool 对应的缓存页标记为脏页，然后再由后台线程将脏页写入到磁盘。 那为了能快速知道哪些缓存页是脏的，于是就设计出 Flush 链表，它跟 Free 链表类似的，链表的节点也是控制块，区别在于 Flush 链表的元素都是脏页。有了 Flush 链表后，后台线程就可以遍历 Flush 链表，将脏页写入到磁盘。 6.如何提高缓存命中率？使用改进的 LRU 算法。普通的 LRU 算法通常是将最近查询的数据放到 LRU 链表的头部，而 InnoDB 做 2 点优化： 将 LRU 链表 分为young 和 old 两个区域，加入缓冲池的页，优先插入 old 区域；页被访问时，才进入 young 区域，目的是为了解决预读失效的问题。 当「页被访问」且「 old 区域停留时间超过 innodb_old_blocks_time 阈值（默认为1秒）」时，才会将页插入到 young 区域，否则还是插入到 old 区域，目的是为了解决批量数据访问，大量热数据淘汰的问题。 什么是预读失效？ 6.1该算法是否解决了 Buffer Pool 污染问题？ 当某一个 SQL 语句扫描了大量的数据时，在 Buffer Pool 空间比较有限的情况下，可能会将 Buffer Pool 里的所有页都替换出去，导致大量热数据被淘汰了，等这些热数据又被再次访问的时候，由于缓存未命中，就会产生大量的磁盘 IO，MySQL 性能就会急剧下降，这个过程被称为 Buffer Pool 污染。 注意， Buffer Pool 污染并不只是查询语句查询出了大量的数据才出现的问题，即使查询出来的结果集很小，也会造成 Buffer Pool 污染。 怎么解决出现 Buffer Pool 污染而导致缓存命中率下降的问题？ 像全表扫描的查询，很多缓冲页只会被访问一次，但是它却只因为被访问了一次而进入到 young 区域，从而导致热点数据被替换了。 LRU 链表中 young 区域就是热点数据，只要我们提高进入 young 区域的门槛，就能有效地保证 young 区域里的热点数据不会被替换。 MySQL 是这样做的，进入到 young 区域条件增加了一个停留在 old 区域的时间判断。 具体是这样做的，在对某个处在 old 区域的缓存页进行第一次访问时，就在它对应的控制块中记录下来这个访问时间： 如果后续的访问时间与第一次访问的时间在某个时间间隔内，那么该缓存页就不会被从 old 区域移动到 young 区域的头部； 如果后续的访问时间与第一次访问的时间不在某个时间间隔内，那么该缓存页移动到 young 区域的头部； 这个间隔时间是由 innodb_old_blocks_time 控制的，默认是 1000 ms。 也就说，只有同时满足「被访问」与「在 old 区域停留时间超过 1 秒」两个条件，才会被插入到 young 区域头部，这样就解决了 Buffer Pool 污染的问题 。 另外，MySQL 针对 young 区域其实做了一个优化，为了防止 young 区域节点频繁移动到头部。young 区域前面 1/4 被访问不会移动到链表头部，只有后面的 3/4被访问了才会。 7.脏页什么时候刷新到磁盘？ 当 redo log 日志满了的情况下，会主动触发脏页刷新到磁盘； Buffer Pool 空间不足时，需要将一部分数据页淘汰掉，如果淘汰的是脏页，需要先将脏页同步到磁盘； MySQL 认为空闲时，后台线程会定期将适量的脏页刷入到磁盘； MySQL 正常关闭之前，会把所有的脏页刷入到磁盘； 在开启了慢 SQL 监控后，如果你发现「偶尔」会出现一些用时稍长的 SQL，这可因为脏页在刷新到磁盘时导致数据库性能抖动。如果在很短的时间出现这种现象，就需要调大 Buffer Pool 空间或 redo log 日志的大小。","link":"/2023/07/03/MySQL/"},{"title":"计算机基础——计算机网络","text":"本篇内容： 计算机网络的学习，包括基础知识和HTTP、TCP、IP 等基础知识点的介绍 在使用中可能出现的问题的探讨与研究 基础知识篇1.TCP/IP 模型有几层 答：TCP/IP模型分为应用层、传输层、网络层和网络接口层四层。各部分的作用是： 应用层专注于为用户提供应用功能，比如 HTTP、FTP、Telnet、DNS、SMTP等。 应用层的数据包会传给传输层，传输层（Transport Layer）是为应用层提供网络支持的。在该层主要有两个传输协议：TCP和UDP。网络层只是根据网络地址将源结点发出的数据包传送到目的结点，而传输层则负责将数据可靠地传送到相应的端口。 网络层主要实现的是传输功能。该层的传输协议是 IP 协议。网络层负责对子网间的数据包进行路由选择。 网络接口层主要为网络层提供链路级别传输的服务，负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次，使用 MAC 地址来标识网络上的设备。 1.1追问：OSI七层模型 1.2追问：两种模型的对应关系？ 2.为什么既需要传输层，也需要网络层？ 实际场景中的网络环节是错综复杂的，中间有各种各样的线路和分叉路口，如果一个设备的数据要传输给另一个设备，就需要在各种各样的路径和节点进行选择，而传输层的设计理念是简单、高效、专注，如果传输层还负责这一块功能就有点违背设计原则了。 也就是说，我们不希望传输层协议处理太多的事情，只需要服务好应用即可，让其作为应用间数据传输的媒介，帮助实现应用到应用的通信，而实际的传输功能就交给下一层，也就是网络层。 3.为什么需要网络接口层？ 以太网在判断网络包目的地时和 IP 的方式不同，因此必须采用相匹配的方式才能在以太网中将包发往目的地，而 MAC 头部就是干这个用的，所以，在以太网进行通讯要用到 MAC 地址。 MAC 头部是以太网使用的头部，它包含了接收方和发送方的 MAC 地址等信息，我们可以通过 ARP 协议获取对方的 MAC 地址。 所以说，网络接口层主要为网络层提供「链路级别」传输的服务，负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次，使用 MAC 地址来标识网络上的设备。 4.键入网址到网页显示，期间发生了什么？ 对 URL 进行解析，从而生成发送给 Web 服务器的请求信息（即 HTTP 请求信息）。 在发送之前，需要使用 DNS 查询服务器域名对应的 IP 地址，因为委托操作系统发送消息时，必须提供通信对象的 IP 地址。 通过 DNS 获取到 IP 后，就可以把 HTTP 的传输工作交给操作系统中的协议栈。 在 HTTP 传输数据之前，首先需要 TCP 建立连接，TCP 连接的建立，通常称为三次握手。 TCP 分割传输数据，生成 TCP 报文。 IP 模块包装数据，生成 IP 报文。 添加 MAC 包，在 MAC 包头里需要发送方 MAC 地址和接收方目标 MAC 地址，用于两点之间的传输。 网卡驱动获取网络包之后，会将其复制到网卡内的缓存区中，接着会在其开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列。最后网卡会将包转为电信号，通过网线发送出去。 到达交换机之后，交换机根据 MAC 地址表查找 MAC 地址，然后将信号发送到相应的端口。 网络包经过交换机之后，现在到达了路由器，并在此被转发到下一个路由器或目标设备。这一步转发的工作原理和交换机类似，也是通过查表判断包转发的目标。 经过不断地路由器转换操作，到达目标路由器。完成包接收操作之后，路由器就会去掉包开头的 MAC 头部。之后根据 MAC 头部后方的 IP 头部中的内容进行包的转发操作。 数据包抵达服务器后，服务器会一层层将数据包进行去皮操作，最终将 HTTP 中的请求进行返回。返回操作类似发送。 5.DNS 如何进行查询？ 层级查询，从根节点进行查询。 6.什么是 MTU 和 MSS？ MTU：一个网络包的最大长度，以太网中一般为 1500 字节。 MSS：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度 追问：既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？ 如果只采用 IP 层进行分片，那么当如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传。 经过 TCP 层分片后，如果一个 TCP 分片丢失后，进行重发时也是以 MSS 为单位，而不用重传所有的分片，大大增加了重传的效率。 7.如何获取对方的 MAC 地址呢？ 首先在 ARP缓存中寻找是否有目标路由的MAC地址。 使用ARP 协议帮我们找到路由器的 MAC 地址。 ARP 协议会在以太网中以广播的形式，对以太网所有的设备进行广播，从而得到目标路由器的 MAC 地址。 把本次查询结果放到一块叫做 ARP 缓存的内存空间留着以后用，不过缓存的时间就几分钟。 追问：如果不在同一子网，那么如何找 MAC 地址？ 在发送数据包时，如果目标主机不是本地局域网，填入的 MAC 地址是路由器，也就是把数据包转发给路由器，路由器一直转发下一个路由器，直到转发到目标主机的路由器，发现目标 IP 地址是自己局域网内的主机，就会 ARP 请求获取目标主机的 MAC 地址，从而转发到这个服务器主机。 8.在交换机中，当 MAC 地址表找不到指定的 MAC 地址会怎么样？ 地址表中找不到指定的 MAC 地址。这可能是因为具有该地址的设备还没有向交换机发送过包，或者这个设备一段时间没有工作导致地址被从地址表中删除了。 这种情况下，交换机无法判断应该把包转发到哪个端口，只能将包转发到除了源端口之外的所有端口上，无论该设备连接在哪个端口上都能收到这个包。 这样做不会产生什么问题，因为以太网的设计本来就是将包发送到整个网络的，然后只有相应的接收者才接收包，而其他设备则会忽略这个包。 9.路由器的基本原理？ 路由器的端口具有 MAC 地址，因此它就能够成为以太网的发送方和接收方；同时还具有 IP 地址，从这个意义上来说，它和计算机的网卡是一样的。 当转发包时，首先路由器端口会接收发给自己的以太网包，然后路由表查询转发目标，再由相应的端口作为发送方将以太网包发送出去。 10.路由器接收包的操作？ 首先，电信号到达网线接口部分，路由器中的模块会将电信号转成数字信号，然后通过包末尾的 FCS 进行错误校验。 如果没问题则检查 MAC 头部中的接收方 MAC 地址，看看是不是发给自己的包，如果是就放到接收缓冲区中，否则就丢弃这个包。 总的来说，路由器的端口都具有 MAC 地址，只接收与自身地址匹配的包，遇到不匹配的包则直接丢弃。 11.路由器发送包的操作？ 首先，我们需要根据路由表的网关列判断对方的地址。 如果网关是一个 IP 地址，则这个IP 地址就是我们要转发到的目标地址，还未抵达终点，还需继续需要路由器转发。 如果网关为空，则 IP 头部中的接收方 IP 地址就是要转发到的目标地址，也是就终于找到 IP 包头里的目标地址了，说明已抵达终点。 知道对方的 IP 地址之后，接下来需要通过 ARP 协议根据 IP 地址查询 MAC 地址，并将查询的结果作为接收方 MAC 地址。 路由器也有 ARP 缓存，因此首先会在 ARP 缓存中查询，如果找不到则发送 ARP 查询请求。 接下来是发送方 MAC 地址字段，这里填写输出端口的 MAC 地址。还有一个以太类型字段，填写 0800 （十六进制）表示 IP 协议。 网络包完成后，接下来会将其转换成电信号并通过端口发送出去。这一步的工作过程和计算机也是相同的。 发送出去的网络包会通过交换机到达下一个路由器。由于接收方 MAC 地址就是下一个路由器的地址，所以交换机会根据这一地址将包传输到下一个路由器。 接下来，下一个路由器会将包转发给再下一个路由器，经过层层转发之后，网络包就到达了最终的目的地。 12.小林读者提问1.笔记本的是自带交换机的吗？交换机现在我还不知道是什么笔记本不是交换机，交换机通常是2个网口以上。 现在家里的路由器其实有了交换机的功能了。交换机可以简单理解成一个设备，三台电脑网线接到这个设备，这三台电脑就可以互相通信了，交换机嘛，交换数据这么理解就可以。 2.是不是有了MAC地址就能给你发消息了？Mac 地址只能是两个设备之间传递时使用的，如果你要从大老远给我发消息，是离不开 IP 地址的。 13.Linux 接收网络包的流程 首先，应用程序会调用 Socket 发送数据包的接口，从用户态陷入到内核态中的 Socket 层，内核会申请一个内核态的 sk_buff 内存，将用户待发送的数据拷贝到 sk_buff 内存，并将其加入到发送缓冲区。 接下来，网络协议栈从 Socket 发送缓冲区中取出 sk_buff，并按照 TCP/IP 协议栈从上到下逐层处理。 如果使用的是 TCP 传输协议发送数据，那么先拷贝一个新的 sk_buff 副本 ，（这是因为 sk_buff 后续在调用网络层，最后到达网卡发送完成的时候，这个 sk_buff 会被释放掉。而 TCP 协议是支持丢失重传的，在收到对方的 ACK 之前，这个 sk_buff 不能被删除。所以内核的做法就是每次调用网卡发送的时候，实际上传递出去的是 sk_buff 的一个拷贝，等收到 ACK 再真正删除。） 接着，对 sk_buff 填充 TCP 头。（这里提一下，sk_buff 可以表示各个层的数据包，在应用层数据包叫 data，在 TCP 层我们称为 segment，在 IP 层我们叫 packet，在数据链路层称为 frame。） 然后交给网络层，在网络层里会做这些工作：选取路由（确认下一跳的 IP）、填充 IP 头、netfilter 过滤、对超过 MTU 大小的数据包进行分片。处理完这些工作后会交给网络接口层处理。 网络接口层会通过 ARP 协议获得下一跳的 MAC 地址，然后对 sk_buff 填充帧头和帧尾，接着将 sk_buff 放到网卡的发送队列中。 这一些工作准备好后，会触发「软中断」告诉网卡驱动程序，这里有新的网络包需要发送，驱动程序会从发送队列中读取 sk_buff，将这个 sk_buff 挂到 RingBuffer 中，接着将 sk_buff 数据映射到网卡可访问的内存 DMA 区域，最后触发真实的发送。 当数据发送完成以后，其实工作并没有结束，因为内存还没有清理。当发送完成的时候，网卡设备会触发一个硬中断来释放内存，主要是释放 sk_buff 内存和清理 RingBuffer 内存。 最后，当收到这个 TCP 报文的 ACK 应答时，传输层就会释放原始的 sk_buff 。 13.1 为什么全部数据包只用一个结构体来描述呢？协议栈采用的是分层结构，上层向下层传递数据时需要增加包头，下层向上层数据时又需要去掉包头，如果每一层都用一个结构体，那在层之间传递数据的时候，就要发生多次拷贝，这将大大降低 CPU 效率。 于是，为了在层级之间传递数据时，不发生拷贝，只用 sk_buff 一个结构体来描述所有的网络包，那它是如何做到的呢？是通过调整 sk_buff 中 data 的指针，比如： 当接收报文时，从网卡驱动开始，通过协议栈层层往上传送数据报，通过增加 skb-&gt;data 的值，来逐步剥离协议首部。 当要发送报文时，创建 sk_buff 结构体，数据缓存区的头部预留足够的空间，用来填充各层首部，在经过各下层协议时，通过减少 skb-&gt;data 的值来增加协议首部。 13.2 怎么告诉操作系统这个网络包已经到达了呢？最简单的一种方式就是触发中断，也就是每当网卡收到一个网络包，就触发一个中断告诉操作系统。 追问：这种方式的缺点是什么？ 在高性能网络场景下，网络包的数量会非常多，那么就会触发非常多的中断，要知道当 CPU 收到了中断，就会停下手里的事情，而去处理这些网络包，处理完毕后，才会回去继续其他事情，那么频繁地触发中断，则会导致 CPU 一直没完没了的处理中断，而导致其他任务可能无法继续前进，从而影响系统的整体效率。 追问：那么Linux采取了哪种解决办法来解决这个问题？ Linux 内核在 2.6 版本中引入了 NAPI 机制，它是混合「中断和轮询」的方式来接收网络包，它的核心概念就是不采用中断的方式读取数据，而是首先采用中断唤醒数据接收的服务程序，然后 poll 的方法来轮询数据。 当有网络包到达时，会通过 DMA 技术，将网络包写入到指定的内存地址，接着网卡向 CPU 发起硬件中断，当 CPU 收到硬件中断请求后，根据中断表，调用已经注册的中断处理函数。 硬件中断处理函数会做如下的事情： 需要先「暂时屏蔽中断」，表示已经知道内存中有数据了，告诉网卡下次再收到数据包直接写内存就可以了，不要再通知 CPU 了，这样可以提高效率，避免 CPU 不停的被中断。 接着，发起「软中断」，然后恢复刚才屏蔽的中断。 具体流程： 网络包到达：当网络包到达网卡时，网卡会将数据包存储在其接收缓冲区中。 DMA传输：使用DMA控制器，网卡通过总线（如PCI或PCIe）将数据包的内容直接传输到内存中，而无需CPU的介入。DMA控制器负责管理数据传输过程，将数据包写入内存指定的地址。 硬件中断请求：在数据包写入完成后，网卡会向CPU发起硬件中断请求。这是通过向CPU发送中断信号（如IRQ）来触发的。 中断处理函数调用：当CPU接收到硬件中断请求后，它会根据中断表中的配置，确定对应的中断处理函数。CPU会保存当前的上下文，并跳转到预先注册的中断处理函数的地址。 中断处理函数执行：中断处理函数会被执行，它负责处理接收到的网络包。处理函数会读取DMA传输的数据包内容，并进行相应的操作，如解析网络协议、进行数据处理、触发事件等。 中断处理完成：中断处理函数执行完毕后，CPU会恢复之前保存的上下文，并继续执行之前的任务。 好处： 通过使用DMA技术，将网络包的数据直接写入内存，可以减少CPU的负载，因为数据传输的过程不需要CPU直接参与每个数据字节的传输。 13.3发送网络数据的时候，涉及几次内存拷贝操作？ 第一次，调用发送数据的系统调用的时候，内核会申请一个内核态的 sk_buff 内存，将用户待发送的数据拷贝到 sk_buff 内存，并将其加入到发送缓冲区。 第二次，在使用 TCP 传输协议的情况下，从传输层进入网络层的时候，每一个 sk_buff 都会被克隆一个新的副本出来。副本 sk_buff 会被送往网络层，等它发送完的时候就会释放掉，然后原始的 sk_buff 还保留在传输层，目的是为了实现 TCP 的可靠传输，等收到这个数据包的 ACK 时，才会释放原始的 sk_buff 。 第三次，当 IP 层发现 sk_buff 大于 MTU 时才需要进行。会再申请额外的 sk_buff，并将原来的 sk_buff 拷贝为多个小的 sk_buff HTTP篇1.HTTP是什么？HTTP 全称是超文本传输协议。HTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」。 2.HTTP 常见状态码有哪些？ 1xx 类状态码属于提示信息，是协议处理中的一种中间状态，实际用到的比较少。 2xx 类状态码表示服务器成功处理了客户端的请求，也是我们最愿意看到的状态。 「200 OK」是最常见的成功状态码，表示一切正常。如果是非 HEAD 请求，服务器返回的响应头都会有 body 数据。 「204 No Content」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。 「206 Partial Content」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。 3xx 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是重定向。 「301 Moved Permanently」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。 「302 Found」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。 「304 Not Modified」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。 ​ 301 和 302 都会在响应头里使用字段 Location，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。 4xx 类状态码表示客户端发送的报文有误，服务器无法处理，也就是错误码的含义。 「400 Bad Request」表示客户端请求的报文有错误，但只是个笼统的错误。 「403 Forbidden」表示服务器禁止访问资源，并不是客户端的请求出错。 「404 Not Found」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。 5xx 类状态码表示客户端请求报文正确，但是服务器处理时内部发生了错误，属于服务器端的错误码。 「500 Internal Server Error」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。 「501 Not Implemented」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。 「502 Bad Gateway」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。 「503 Service Unavailable」表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思。 3.HTTP 常见字段有哪些？ Host 字段 1Host: www.A.com Content-Length 字段 服务器在返回数据时，会有 Content-Length 字段，表明本次回应的数据长度。 HTTP 协议通过设置回车符、换行符作为 HTTP header 的边界，通过 Content-Length 字段作为 HTTP body 的边界，这两个方式都是为了解决“粘包”的问题。 Connection 字段 用于请求复用，常见的字段值——Keep-Alive（长连接） Content-Type 字段 Content-Type 字段用于服务器回应时，告诉客户端，本次数据是什么格式。 例如： 1Content-Type: text/html; Charset=utf-8 上面的类型表明，发送的是网页，而且编码是UTF-8。 客户端请求的时候，可以使用 Accept 字段声明自己可以接受哪些数据格式。 1Accept: */* 上面代码中，客户端声明自己可以接受任何格式的数据。 Content-Encoding 字段 Content-Encoding 字段说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式。 1Content-Encoding: gzip 上面表示服务器返回的数据采用了 gzip 方式压缩，告知客户端需要用此方式解压。 客户端在请求时，用 Accept-Encoding 字段说明自己可以接受哪些压缩方法。 1Accept-Encoding: gzip, deflate 4.在HTTP请求中，GET 和 POST 有什么区别？ GET 的语义是从服务器获取指定的资源 POST 的语义是根据请求负荷（报文body）对指定的资源做出处理 追问：GET 和 POST 方法都是安全和幂等的吗？ 答：GET 的语义是请求获取指定的资源。GET 方法是安全、幂等、可被缓存的。 POST 的语义是根据请求负荷（报文主体）对指定的资源做出处理，具体的处理方式视资源类型而不同。POST 不安全，不幂等，（大部分实现）不可缓存。 但是实际过程中，开发者不一定会按照 RFC 规范定义的语义来实现 GET 和 POST 方法。比如： 可以用 GET 方法实现新增或删除数据的请求，这样实现的 GET 方法自然就不是安全和幂等。 可以用 POST 方法实现查询数据的请求，这样实现的 POST 方法自然就是安全和幂等。 5.HTTP 缓存有哪些实现方式？HTTP 缓存有两种实现方式，分别是强制缓存和协商缓存。 简述一下强制缓存？ 只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边。控制强制缓存有两个字段，分别是Cache-Control和Expires，其中 Cache-Control， 是一个相对时间； Expires，是一个绝对时间； Cache-control 选项更多，设置更加精细，所以一般使用 Cache-Control 来实现强缓存。使用该方式实现流程如下： 当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小； 浏览器再次请求访问服务器中的该资源时，会先通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期，如果没有，则使用该缓存，否则重新请求服务器； 服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。 简述一下协商缓存？ 协商缓存就是与服务端协商之后，通过协商结果来判断是否使用本地缓存。 该方法也有两种控制方式，现在一般使用请求头部中的 If-None-Match 字段与响应头部中的 ETag 字段进行标识与判断。 其中， 响应头部中 Etag：唯一标识响应资源； 请求头部中的 If-None-Match：当资源过期时，浏览器发现响应头里有 Etag，则再次向服务器发起请求时，会将请求头 If-None-Match 值设置为 Etag 的值。服务器收到请求后进行比对，如果资源没有变化返回 304，如果资源变化了返回 200。 两种缓存有什么关系？ 协商缓存这两个字段都需要配合强制缓存中 Cache-Control 字段来使用，只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求。 6.HTTP 的特性6.1 HTTP有哪些优点？ 简单：HTTP 基本的报文格式就是 header + body，头部信息也是 key-value 简单文本的形式，易于理解 灵活且易于扩展：各类请求方法、URI/URL、状态码、头字段等都可以自定义组成和扩充 应用广泛和跨平台 6.2 HTTP/1.1相比于HTTP/1.0有哪些优势？自身还有哪些不足？HTTP/1.1 相比 HTTP/1.0 性能上的改进： 使用长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。 支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。 HTTP/1.1 还存在的不足有： 头部信息冗长。请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 Body 的部分； 发送冗长的首部。每次互相发送相同的首部造成的浪费较多； 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞； 没有请求优先级控制； 请求只能从客户端开始，服务器只能被动响应。 6.2.1 如何优化 HTTP/1.1？ 尽量避免发送 HTTP 请求； 通过缓存技术来避免发送 HTTP 请求。客户端收到第一个请求的响应后，可以将其缓存在本地磁盘，下次请求的时候，如果缓存没过期，就直接读取本地缓存的响应数据。如果缓存过期，客户端发送请求的时候带上响应数据的摘要，服务器比对后发现资源没有变化，就发出不带包体的 304 响应，告诉客户端缓存的响应仍然有效。 在需要发送 HTTP 请求时，考虑如何减少请求次数； 减少重定向请求次数；将原本由客户端处理的重定向请求，交给代理服务器处理，这样可以减少重定向请求的次数； 合并请求；将多个小资源合并成一个大资源再传输，能够减少 HTTP 请求次数以及 头部的重复传输，再来减少 TCP 连接数量，进而省去 TCP 握手和慢启动的网络消耗；（这种方法的缺陷：当大资源中的某一个小资源发生变化后，客户端必须重新下载整个完整的大资源文件，这显然带来了额外的网络消耗。） 延迟发送请求；请求网页的时候，没必要把全部资源都获取到，而是只获取当前用户所看到的页面资源 减少服务器的 HTTP 响应的数据大小；对响应的资源进行压缩，这样就可以减少响应的数据大小，从而提高网络传输的效率。 6.3 HTTP/2 进行了哪些改进？还存在哪些不足？那 HTTP/2 相比 HTTP/1.1 性能上的改进： 基于HTTPS，具有安全性 头部压缩：采用HPACK 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。 二进制格式：全面采用了二进制格式，头信息和数据体都是二进制，并且统称为帧（frame）：头信息帧（Headers Frame）和数据帧（Data Frame）。 并发传输：针对不同的 HTTP 请求用独一无二的 Stream ID 来区分，接收端可以通过 Stream ID 有序组装成 HTTP 消息，不同 Stream 的帧是可以乱序发送的，因此可以并发不同的 Stream ，也就是 HTTP/2 可以并行交错地发送请求和响应。 服务器主动推送资源：服务端不再是被动地响应，可以主动向客户端发送消息。 客户端和服务器双方都可以建立 Stream， Stream ID 也是有区别的，客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号。 HTTP/2 还存在的不足： 没有真正解决队头阻塞问题。HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题。 追问：两种队头阻塞有什么不同？ HTTP/1.1 中的管道（ pipeline）虽然解决了请求的队头阻塞，但是没有解决响应的队头阻塞，因为服务端需要按顺序响应收到的请求，如果服务端处理某个请求消耗的时间比较长，那么只能等响应完这个请求后， 才能处理下一个请求，这属于 HTTP 层队头阻塞。 HTTP/2 虽然通过多个请求复用一个 TCP 连接解决了 HTTP 的队头阻塞 ，但是一旦发生丢包，就会阻塞住所有的 HTTP 请求，这属于 TCP 层队头阻塞。 6.3.1 如何优化 HTTP/2？ 头部压缩。常见的 HTTP 头部通过静态表和 Huffman 编码的方式进行压缩，而且针对后续的请求头部，还可以建立动态表，大大提高了编码效率，同时节约了带宽资源。 不过，动态表并非可以无限增大， 因为动态表是会占用内存的，动态表越大，内存也越大，容易影响服务器总体的并发能力，因此服务器需要限制 HTTP/2 连接时长或者请求次数。 HTTP/2 实现了 Stream 并发，多个 Stream 只需复用 1 个 TCP 连接，节约了 TCP 和 TLS 握手时间，以及减少了 TCP 慢启动阶段对流量的影响。不同的 Stream ID 可以并发，即使乱序发送帧也没问题，但是同一个 Stream 里的帧必须严格有序。 另外，可以根据资源的渲染顺序来设置 Stream 的优先级，从而提高用户体验。 服务器支持主动推送资源，大大提升了消息的传输性能，（服务器推送资源时，会先发送 PUSH_PROMISE 帧，告诉客户端接下来在哪个 Stream 发送资源，然后用偶数号 Stream 发送资源给客户端。） 6.4 HTTP/3 进行了哪些改进？还存在哪些不足？HTTP/3采用基于 UDP 的 QUIC 协议 相比于HTTP/2，存在的优势： 无队头阻塞：当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题。 更快的连接建立：对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手，再 TLS 握手。 HTTP/3 在传输数据前虽然需要 QUIC 协议握手，但是这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的。 但是 HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是 QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS/1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商。 在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果。 连接迁移：在HTTP/2和HTTP/1.1中，一条TCP连接是通过源 IP、源端口、目的 IP、目的端口来进行确定，因此，有时只是切换网络就会造成IP地址发生变化，从而断开连接再重新建立连接，造成网络卡顿。QUIC 协议通过连接 ID 来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使网络变化导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了连接迁移的功能。 7. HTTP 与 HTTPS 具有哪些区别？ HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。 HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。 两者的默认端口不一样，HTTP 默认端口号是 80，HTTPS 默认端口号是 443。 HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。 7.1 HTTPS 解决了 HTTP哪些问题？ 窃听风险，比如通信链路上可以获取通信内容，用户号容易没。 篡改风险，比如强制植入垃圾广告，视觉污染，用户眼容易瞎。 冒充风险，比如冒充淘宝网站，用户钱容易没。 如何解决的？ 混合加密的方式实现信息的机密性，解决了窃听的风险。 摘要算法的方式来实现完整性，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。 将服务器公钥放入到数字证书中，解决了冒充的风险。 追问 混合加密如何实现？ 在通信建立前采用非对称加密的方式交换「会话秘钥」，后续就不再使用非对称加密。 在通信过程中全部使用对称加密的「会话秘钥」的方式加密明文数据。 对称加密和非对称加密分别具有哪些特性？ 对称加密只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。 非对称加密使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。 摘要算法 + 数字签名是如何实现的？ 在计算机里会用摘要算法（哈希函数）来计算出内容的哈希值，也就是内容的「指纹」，这个哈希值是唯一的，且无法通过哈希值推导出内容。 通过「私钥加密，公钥解密」的方式，来确认消息的身份 公钥加密、私钥解密和私钥加密、公钥解密有什么区别？ 公钥加密，私钥解密。这个目的是为了保证内容传输的安全，因为被公钥加密的内容，其他人是无法解密的，只有持有私钥的人，才能解密出实际的内容； 私钥加密，公钥解密。这个目的是为了保证消息不会被冒充，因为私钥是不可泄露的，如果公钥能正常解密出私钥加密的内容，就能证明这个消息是来源于持有私钥身份的人发送的。 7.2 HTTPS 是如何建立连接的？其间交互了什么？有两种算法：RSA 和 ECDHE 使用 RSA 密钥协商算法的最大问题是不支持前向保密。 7.2.1 RSA 算法和 ECDHE 算法有什么区别？ RSA 密钥协商算法「不支持」前向保密，ECDHE 密钥协商算法「支持」前向保密； 若服务器端私钥泄露，则可以用其来解密所有的过去的会话信息；不断拦截公钥以及协商数据，可能破解出私钥 ECDHE 的临时私钥是每个会话独特的，即使服务端私钥丢失，也不会造成过去会话全部被破解；不断拦截也无法破解（目前计算机无法做到） 使用了 RSA 密钥协商算法，TLS 完成四次握手后，才能进行应用数据传输，而对于 ECDHE 算法，客户端可以不用等服务端的最后一次 TLS 握手，就可以提前发出加密的 HTTP 数据，节省了一个消息的往返时间（这个是 RFC 文档规定的，具体原因文档没有说明，所以这点我也不太明白）； 使用 ECDHE， 在 TLS 第 2 次握手中，会出现服务器端发出的「Server Key Exchange」消息，而 RSA 握手过程没有该消息； 7.2.2 为什么 TLS1.3只需要1RTT？客户端在 Client Hello 消息里带上了支持的椭圆曲线，以及这些椭圆曲线对应的公钥。 服务端收到后，选定一个椭圆曲线等参数，然后返回消息时，带上服务端这边的公钥。经过这 1 个 RTT，双方手上已经有生成会话密钥的材料了，于是客户端计算出会话密钥，就可以进行应用数据的加密传输了。 而且，TLS1.3 对于密钥交换算法，废除了不支持前向安全性的 RSA 和 DH 算法，只支持 ECDHE 算法。 7.2.3客户端校验数字证书的流程是怎样的？ CA 签发证书的过程，如上图左边部分： 首先 CA 会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包，然后对这些信息进行 Hash 计算，得到一个 Hash 值； 然后 CA 会使用自己的私钥将该 Hash 值加密，生成 Certificate Signature，也就是 CA 对证书做了签名； 最后将 Certificate Signature 添加在文件证书上，形成数字证书； 客户端校验服务端的数字证书的过程，如上图右边部分： 首先客户端会使用同样的 Hash 算法获取该证书的 Hash 值 H1； 通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使用 CA 的公钥解密 Certificate Signature 内容，得到一个 Hash 值 H2 ； 最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。 7.3 HTTPS 的应用数据是如何保证完整性的？ 首先，消息被分割成多个较短的片段,然后分别对每个片段进行压缩。 接下来，经过压缩的片段会被加上消息认证码（MAC 值，这个是通过哈希算法生成的），这是为了保证完整性，并进行数据的认证。通过附加消息认证码的 MAC 值，可以识别出篡改。与此同时，为了防止重放攻击，在计算消息认证码时，还加上了片段的编码。 再接下来，经过压缩的片段再加上消息认证码会一起通过对称密码进行加密。 最后，上述经过加密的数据再加上由数据类型、版本号、压缩后的长度组成的报头就是最终的报文数据。 7.4 HTTPS 一定是安全可靠的吗？HTTPS 协议本身到目前为止还是没有任何漏洞的，即使你成功进行中间人攻击，本质上是利用了客户端的漏洞（用户点击继续访问或者被恶意导入伪造的根证书），并不是 HTTPS 不够安全。 7.5 为什么抓包工具能截取 HTTPS 数据？使用抓包工具进行 HTTPS 抓包的时候，需要在客户端安装 Fiddler 的根证书，这里实际上起认证中心（CA）的作用 7.6 HTTPS 可以如何优化？对于硬件优化的方向，因为 HTTPS 是属于计算密集型，应该选择计算力更强的 CPU，而且最好选择支持 AES-NI 特性的 CPU，这个特性可以在硬件级别优化 AES 对称加密算法，加快应用数据的加解密。 对于软件优化的方向，如果可以，把软件升级成较新的版本，比如将 Linux 内核 2.X 升级成 4.X，将 openssl 1.0.1 升级到 1.1.1，因为新版本的软件不仅会提供新的特性，而且还会修复老版本的问题。 对于协议优化的方向： 密钥交换算法应该选择 ECDHE 算法，而不用 RSA 算法，因为 ECDHE 算法具备前向安全性，而且客户端可以在第三次握手之后，就发送加密应用数据，节省了 1 RTT。 将 TLS1.2 升级 TLS1.3，因为 TLS1.3 的握手过程只需要 1 RTT，而且安全性更强。 对于证书优化的方向： 服务器应该选用 ECDSA 证书，而非 RSA 证书，因为在相同安全级别下，ECC 的密钥长度比 RSA 短很多，这样可以提高证书传输的效率； 服务器应该开启 OCSP Stapling 功能，由服务器预先获得 OCSP 的响应，并把响应结果缓存起来，这样 TLS 握手的时候就不用再访问 CA 服务器，减少了网络通信的开销，提高了证书验证的效率；（服务器向 CA 周期性地查询证书状态，获得一个带有时间戳和签名的响应结果并缓存它。） 对于重连 HTTPS 时，我们可以使用一些技术让客户端和服务端使用上一次 HTTPS 连接使用的会话密钥，直接恢复会话，而不用再重新走完整的 TLS 握手过程。 常见的会话重用技术有 Session ID 和 Session Ticket，用了会话重用技术，当再次重连 HTTPS 时，只需要 1 RTT 就可以恢复会话。对于 TLS1.3 使用 Pre-shared Key 会话重用技术，只需要 0 RTT 就可以恢复会话。 这些会话重用技术虽然好用，但是存在一定的安全风险，它们不仅不具备前向安全，而且有重放攻击的风险，所以应当对会话密钥设定一个合理的过期时间。 追问：简述一下 Session ID 、 Session Ticket 和 Pre-shared Key 会话重用技术，以及各自的优缺点？ Session ID 的工作原理是，客户端和服务器首次 TLS 握手连接后，双方会在内存缓存会话密钥，并用唯一的 Session ID 来标识，Session ID 和会话密钥相当于 key-value 的关系。当客户端再次连接时，hello 消息里会带上 Session ID，服务器收到后就会从内存找，如果找到就直接用该会话密钥恢复会话状态，跳过其余的过程，只用一个消息往返就可以建立安全通信。当然为了安全性，内存中的会话密钥会定期失效。 该方法的缺点是： 服务器必须保持每一个客户端的会话密钥，随着客户端的增多，服务器的内存压力也会越大。 现在网站服务一般是由多台服务器通过负载均衡提供服务的，客户端再次连接不一定会命中上次访问过的服务器，于是还要走完整的 TLS 握手过程； Session Ticket 的工作原理是服务器不再缓存每个客户端的会话密钥，而是把缓存的工作交给了客户端，类似于 HTTP 的 Cookie。 客户端与服务器首次建立连接时，服务器会加密「会话密钥」作为 Ticket 发给客户端，交给客户端缓存该 Ticket。客户端再次连接服务器时，客户端会发送 Ticket，服务器解密后就可以获取上一次的会话密钥，然后验证有效期，如果没问题，就可以恢复会话了，开始加密通信。对于集群服务器的话，要确保每台服务器加密 「会话密钥」的密钥是一致的，这样客户端携带 Ticket 访问任意一台服务器时，都能恢复会话。 Session ID 和 Session Ticket 都不具备前向安全性，因为一旦加密「会话密钥」的密钥被破解或者服务器泄漏「会话密钥」，前面劫持的通信密文都会被破解。 Pre-shared Key 原理与 Ticket 原理类似，只不过在重连时，客户端会把 Ticket 和 HTTP 请求一同发送给服务端，这种方式叫 Pre-shared Key。对于重连只需要 0RTT 即可。 追问：上述三种方法是否存在重放攻击？ 上述三种方法都存在重放攻击。 简述重放攻击：假设 Alice 想向 Bob 证明自己的身份。 Bob 要求 Alice 的密码作为身份证明，爱丽丝应尽全力提供（可能是在经过如哈希函数的转换之后）。与此同时，Eve 窃听了对话并保留了密码（或哈希）。 交换结束后，Eve（冒充 Alice ）连接到 Bob。当被要求提供身份证明时，Eve 发送从 Bob 接受的最后一个会话中读取的 Alice 的密码（或哈希），从而授予 Eve 访问权限。 重放攻击的危险之处在于，如果中间人截获了某个客户端的 Session ID 或 Session Ticket 以及 POST 报文，而一般 POST 请求会改变数据库的数据，中间人就可以利用此截获的报文，不断向服务器发送该报文，这样就会导致数据库的数据被中间人改变了，而客户是不知情的。 避免重放攻击的方式就是需要对会话密钥设定一个合理的过期时间。 8.既然已经存在 HTTP 协议，那么为何还需要 RPC 协议？ 纯裸 TCP 是能收发数据，但它是个无边界的数据流，上层需要定义消息格式用于定义消息边界。于是就有了各种协议，HTTP 和各类 RPC 协议就是在 TCP 之上定义的应用层协议。 RPC 本质上不算是协议，而是一种调用方式，而像 gRPC 和 Thrift 这样的具体实现，才是协议，它们是实现了 RPC 调用的协议。目的是希望程序员能像调用本地方法那样去调用远端的服务方法。同时 RPC 有很多种实现方式，不一定非得基于 TCP 协议。 从发展历史来说，HTTP 主要用于 B/S 架构，而 RPC 更多用于 C/S 架构。但现在其实已经没分那么清了，B/S 和 C/S 在慢慢融合。很多软件同时支持多端，所以对外一般用 HTTP 协议，而内部集群的微服务之间则采用 RPC 协议进行通讯。 RPC 其实比 HTTP 出现的要早，且比目前主流的 HTTP/1.1 性能要更好，所以大部分公司内部都还在使用 RPC。 HTTP/2.0 在 HTTP/1.1 的基础上做了优化，性能可能比很多 RPC 协议都要好，但由于是这几年才出来的，所以也不太可能取代掉 RPC。 9.既然有 HTTP 协议，为什么还要有 WebSocket？ TCP 协议本身是全双工的，但我们最常用的 HTTP/1.1，虽然是基于 TCP 的协议，但它是半双工的，对于大部分需要服务器主动推送数据到客户端的场景，都不太友好，因此我们需要使用支持全双工的 WebSocket 协议。 在 HTTP/1.1 里，只要客户端不问，服务端就不答。基于这样的特点，对于登录页面这样的简单场景，可以使用定时轮询或者长轮询的方式实现服务器推送(comet)的效果。 对于客户端和服务端之间需要频繁交互的复杂场景，比如网页游戏，都可以考虑使用 WebSocket 协议。 WebSocket 和 socket 几乎没有任何关系，只是叫法相似。 正因为各个浏览器都支持 HTTP协议，所以 WebSocket 会先利用HTTP协议加上一些特殊的 header 头进行握手升级操作，升级成功后就跟 HTTP 没有任何关系了，之后就用 WebSocket 的数据格式进行收发数据。 TCP篇1.什么是 TCP ？为什么需要 TCP 协议？ TCP 是面向连接的、可靠的、基于字节流的传输层通信协议。 IP 层是「不可靠」的，它不保证网络包的交付、不保证网络包的按序交付、也不保证网络包中的数据的完整性。如果需要保障网络数据包的可靠性，那么就需要由上层（传输层）的 TCP 协议来负责。因为 TCP 是一个工作在传输层的可靠数据传输的服务，它能确保接收端接收的网络包是无损坏、无间隔、非冗余和按序的。 追问：简述 TCP 的三个特性？ 面向连接：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的； 可靠的：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端； 字节流：用户消息通过 TCP 协议传输时，消息可能会被操作系统「分组」成多个的 TCP 报文，如果接收方的程序如果不知道「消息的边界」，是无法读出一个有效的用户消息的。并且 TCP 报文是「有序的」，当「前一个」TCP 报文没有收到的时候，即使它先收到了后面的 TCP 报文，那么也不能扔给应用层去处理，同时对「重复」的 TCP 报文会自动丢弃。 什么是 TCP 连接？ 用于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括 Socket、序列号和窗口大小称为连接。 2.UDP 和 TCP 有什么区别呢？分别的应用场景是？TCP 和 UDP 区别： 1. 连接 TCP 是面向连接的传输层协议，传输数据前先要建立连接。 UDP 是不需要连接，即刻传输数据。 2. 服务对象 TCP 是一对一的两点服务，即一条连接只有两个端点。 UDP 支持一对一、一对多、多对多的交互通信 3. 可靠性 TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按序到达。 UDP 是尽最大努力交付，不保证可靠交付数据。但是我们可以基于 UDP 传输协议实现一个可靠的传输协议，比如 QUIC 协议。 4. 拥塞控制、流量控制 TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。 UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。 5. 首部开销 TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」字段则会变长的。 UDP 首部只有 8 个字节，并且是固定不变的，开销较小。 6. 传输方式 TCP 是流式传输，没有边界，但保证顺序和可靠。 UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。 7. 分片不同 TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。 UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。 TCP 和 UDP 应用场景： 由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于： FTP 文件传输； HTTP / HTTPS； 由于 UDP 面向无连接，它可以随时发送数据，再加上 UDP 本身的处理既简单又高效，因此经常用于： 包总量较少的通信，如 DNS 、SNMP 等； 视频、音频等多媒体通信； 广播通信； 2.1为什么 UDP 头部没有「首部长度」字段，而 TCP 头部有「首部长度」字段呢？原因是 TCP 有可变长的「选项」字段，而 UDP 头部长度则是不会变化的，无需多一个字段去记录 UDP 的首部长度。 2.2为什么 UDP 头部有「包长度」字段，而 TCP 头部则没有「包长度」字段呢？因为为了网络设备硬件设计和处理方便，首部长度需要是 4 字节的整数倍。如果去掉 UDP 的「包长度」字段，那 UDP 首部长度就不是 4 字节的整数倍了，所以我觉得这可能是为了补全 UDP 首部长度是 4 字节的整数倍，才补充了「包长度」字段。 2.3TCP 和 UDP 可以使用同一个端口吗？可以。 TCP 和 UDP 传输协议，在内核中是由两个完全独立的软件模块实现的。 当主机收到数据包后，可以在 IP 包头的「协议号」字段知道该数据包是 TCP/UDP，所以可以根据这个信息确定送给哪个模块（TCP/UDP）处理，送给 TCP/UDP 模块的报文根据「端口号」确定送给哪个应用程序处理。 因此， TCP/UDP 各自的端口号也相互独立，互不影响。 2.4追问:多个TCP可以绑定同一个端口吗?如果两个 TCP 服务进程同时绑定的 IP 地址和端口都相同，那么执行 bind() 时候就会出错，错误是“Address already in use”。 如果两个 TCP 服务进程绑定的端口都相同，而 IP 地址不同，那么执行 bind() 不会出错。 追问:重启 TCP 服务进程时，为什么会有“Address in use”的报错信息？ TIME_WAIT 状态还未结束。要解决这个问题，我们可以对 socket 设置 SO_REUSEADDR 属性。 2.5客户端的端口可以重复使用吗？在客户端执行 connect 函数的时候，只要客户端连接的服务器不是同一个，内核允许端口重复使用。 TCP 连接是由四元组（源IP地址，源端口，目的IP地址，目的端口）唯一确认的，那么只要四元组中其中一个元素发生了变化，那么就表示不同的 TCP 连接的。 3.简述 TCP 三次握手？ 一开始，客户端和服务端都处于 CLOSE 状态。先是服务端主动监听某个端口，处于 LISTEN 状态 客户端会随机初始化序号（client_isn），将此序号置于 TCP 首部的「序号」字段中，同时把 SYN 标志位置为 1，表示 SYN 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 SYN-SENT 状态。 服务端收到客户端的 SYN 报文后，首先服务端也随机初始化自己的序号（server_isn），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 client_isn + 1, 接着把 SYN 和 ACK 标志位置为 1。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 SYN-RCVD 状态。 客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 ACK 标志位置为 1 ，其次「确认应答号」字段填入 server_isn + 1 ，最后把报文发送给服务端，这次报文可以携带客户到服务端的数据，之后客户端处于 ESTABLISHED 状态。 服务端收到客户端的应答报文后，也进入 ESTABLISHED 状态。 3.1为什么使用三次握手，而不是两次或者四次？ 三次握手才可以阻止重复历史连接的初始化（主要原因） 如果采用两次握手建立 TCP 连接的场景下，服务端在向客户端发送数据前，并没有阻止掉历史连接，导致服务端建立了一个历史连接，又白白发送了数据，妥妥地浪费了服务端的资源。 因此，要解决这种现象，最好就是在服务端发送数据前，也就是建立连接之前，要阻止掉历史连接，这样就不会造成资源浪费，而要实现这个功能，就需要三次握手。 所以，TCP 使用三次握手建立连接的最主要原因是防止「历史连接」初始化了连接。 三次握手才可以同步双方的初始序列号 TCP 协议的通信双方， 都必须维护一个「序列号」， 序列号是可靠传输的一个关键因素，它的作用： 接收方可以去除重复的数据； 接收方可以根据数据包的序列号按序接收； 可以标识发送出去的数据包中， 哪些是已经被对方收到的（通过 ACK 报文中的序列号知道）； 可见，序列号在 TCP 连接中占据着非常重要的作用，所以当客户端发送携带「初始序列号」的 SYN 报文的时候，需要服务端回一个 ACK 应答报文，表示客户端的 SYN 报文已被服务端成功接收，那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，这样一来一回，才能确保双方的初始序列号能被可靠的同步。 三次握手才可以避免资源浪费 如果只有「两次握手」，当客户端发生的 SYN 报文在网络中阻塞，客户端没有接收到 ACK 报文，就会重新发送 SYN ，由于没有第三次握手，服务端不清楚客户端是否收到了自己回复的 ACK 报文，所以服务端每收到一个 SYN 就只能先主动建立一个连接，那么服务端在收到请求后就会建立多个冗余的无效链接，造成不必要的资源浪费。 因此，通过三次握手能防止历史连接的建立，能减少双方不必要的资源开销，能帮助双方同步初始化序列号。序列号能够保证数据包不重复、不丢弃和按序传输。 3.2为什么每次建立 TCP 连接时，初始化的序列号都要求不一样呢？ 为了防止历史报文被下一个相同四元组的连接接收（主要方面）； 为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收； 3.3第一次握手丢失了，会发生什么？ 如果客户端迟迟收不到服务端的 SYN-ACK 报文（第二次握手），就会触发「超时重传」机制，重传 SYN 报文，而且重传的 SYN 报文的序列号都是一样的。 客户端的 SYN 报文最大重传次数由 tcp_syn_retries内核参数控制，这个参数是可以自定义的，默认值一般是 5。第二次重传超时时间是前一次的二倍。 在达到最大重传次数之后，再等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到服务端的第二次握手（SYN-ACK 报文），那么客户端就会断开连接。 3.4第二次握手丢失了，会发生什么？ 如果客户端迟迟没有收到第二次握手，那么客户端就觉得可能自己的 SYN 报文（第一次握手）丢失了，于是客户端就会触发超时重传机制，重传 SYN 报文。 如果第二次握手丢失了，服务端就收不到第三次握手，于是服务端这边会触发超时重传机制，重传 SYN-ACK 报文。 因此，当第二次握手丢失了，客户端和服务端都会重传： 客户端会重传 SYN 报文，也就是第一次握手，最大重传次数由 tcp_syn_retries内核参数决定； 服务端会重传 SYN-ACK 报文，也就是第二次握手，最大重传次数由 tcp_synack_retries 内核参数决定。 如果达到各自最大重传次数之后，等待一段时间之后就会断开连接。 3.5第三次握手丢失了，会发生什么？因为这个第三次握手的 ACK 是对第二次握手的 SYN 的确认报文，所以当第三次握手丢失了，如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数。 注意，ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文。 3.6什么是 SYN 攻击？如何避免 SYN 攻击？我们都知道 TCP 连接建立是需要三次握手，假设攻击者短时间伪造不同 IP 地址的 SYN 报文，服务端每接收到一个 SYN 报文，就进入SYN_RCVD 状态，但服务端发送出去的 ACK + SYN 报文，无法得到未知 IP 主机的 ACK 应答，久而久之就会占满服务端的半连接队列，使得服务端不能为正常用户服务。 避免 SYN 攻击可以采用以下四种方法： 调大 netdev_max_backlog；（当网卡接收数据包的速度大于内核处理的速度时，会有一个队列保存这些数据包。控制该队列的最大值） 增大 TCP 半连接队列； 开启 tcp_syncookies；在不使用 SYN 半连接队列的情况下成功建立连接，相当于绕过了 SYN 半连接来建立连接。 减少 SYN+ACK 重传次数，加快处于 SYN_REVC 状态的 TCP 连接断开。 什么是半连接队列和全连接队列？ 在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是： 半连接队列，也称 SYN 队列； 全连接队列，也称 accept 队列； SYN 攻击方式最直接的表现就会把 TCP 半连接队列打满，这样当 TCP 半连接队列满了，后续再在收到 SYN 报文就会丢弃，导致客户端无法和服务端建立连接。 如果SYN半连接队列满了，那么连接只能丢弃吗？ 并不是这样，开启 syncookies 功能就可以在不使用 SYN 半连接队列的情况下成功建立连接，在前面我们源码分析也可以看到这点，当开启了 syncookies 功能就不会丢弃连接。 syncookies 参数主要有以下三个值： 0 值，表示关闭该功能； 1 值，表示仅当 SYN 半连接队列放不下时，再启用它； 2 值，表示无条件开启功能； 4.简述 TCP 四次挥手？ 客户端打算关闭连接，此时会发送一个 TCP 首部 FIN 标志位被置为 1 的报文，也即 FIN 报文，之后客户端进入 FIN_WAIT_1 状态。 服务端收到该报文后，就向客户端发送 ACK 应答报文，接着服务端进入 CLOSE_WAIT 状态。在收到 FIN 报文的时候，TCP 协议栈会为 FIN 包插入一个文件结束符 EOF 到接收缓冲区中，服务端应用程序可以通过 read 调用来感知这个 FIN 包，这个 EOF 会被放在已排队等候的其他已接收的数据之后，所以必须要得继续 read 接收缓冲区已接收的数据 客户端收到服务端的 ACK 应答报文后，之后进入 FIN_WAIT_2 状态。 等待服务端处理完数据后，也向客户端发送 FIN 报文，之后服务端进入 LAST_ACK 状态。 客户端收到服务端的 FIN 报文后，回一个 ACK 应答报文，之后进入 TIME_WAIT 状态 服务端收到了 ACK 应答报文后，就进入了 CLOSE 状态，至此服务端已经完成连接的关闭。 客户端在经过 2MSL 一段时间后，自动进入 CLOSE 状态，至此客户端也完成连接的关闭。 你可以看到，每个方向都需要一个 FIN 和一个 ACK，因此通常被称为四次挥手。 这里一点需要注意是：主动关闭连接的，才有 TIME_WAIT 状态。 4.1为什么挥手需要四次？ 关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。 服务端收到客户端的 FIN 报文时，先回一个 ACK 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 FIN 报文给客户端来表示同意现在关闭连接。 从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 ACK 和 FIN 一般都会分开发送，因此是需要四次挥手。 4.2第一次挥手丢失会发生什么？ 如果第一次挥手丢失了，那么客户端迟迟收不到被动方的 ACK 的话，也就会触发超时重传机制，重传 FIN 报文，重发次数由 tcp_orphan_retries 参数控制。 当客户端重传 FIN 报文的次数超过 tcp_orphan_retries 后，就不再发送 FIN 报文，则会在等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到第二次挥手，那么直接进入到 close 状态。 4.3第二次挥手丢失了，会发生什么？ 当服务端收到客户端的第一次挥手后，就会先回一个 ACK 确认报文，此时服务端的连接进入到 CLOSE_WAIT 状态。 ACK 报文是不会重传的，所以如果服务端的第二次挥手丢失了，客户端就会触发超时重传机制，重传 FIN 报文，直到收到服务端的第二次挥手，或者达到最大的重传次数。 当客户端重传 FIN 报文的次数超过 tcp_orphan_retries 后，就不再发送 FIN 报文，则会在等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到第二次挥手，那么直接进入到 close 状态。 注意点： 如果采用的是 close 方法调用关闭的话，那么客户端处于 FIN_WAIT_2 的时间有限，超出时间限制则直接进行关闭。 如果采用的是 shutdown方法调用关闭的话，就会一直进行等待。 4.4第三次挥手丢失了，会发生什么？ 服务端重传第三次挥手报文、 当服务端重传第三次挥手报文的次数达到了 3 次后，由于 tcp_orphan_retries 为 3，达到了重传最大次数，于是再等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到客户端的第四次挥手（ACK报文），那么服务端就会断开连接。 客户端因为是通过 close 函数关闭连接的，处于 FIN_WAIT_2 状态是有时长限制的，如果 tcp_fin_timeout 时间内还是没能收到服务端的第三次挥手（FIN 报文），那么客户端就会断开连接。 如果采用的是shutdown的话呢？ 个人认为会死等 4.5第四次挥手丢失了，会发生什么？ 如果第四次挥手的 ACK 报文没有到达服务端，服务端就会重发 FIN 报文，重发次数仍然由前面介绍过的 tcp_orphan_retries 参数控制。 达到了最大重传次数，于是再等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到客户端的第四次挥手（ACK 报文），那么服务端就会断开连接。 客户端在收到第三次挥手后，就会进入 TIME_WAIT 状态，开启时长为 2MSL 的定时器，如果途中再次收到第三次挥手（FIN 报文）后，就会重置定时器，当等待 2MSL 时长后，客户端就会断开连接。 4.5为什么 TIME_WAIT 等待的时间是 2MSL？ MSL 是 Maximum Segment Lifetime，报文最大生存时间，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。 TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是： 网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以一来一回需要等待 2 倍的时间。 相当于至少允许报文丢失一次。比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。 如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 2MSL 时间将重新计时。 简述MSL和TLL的区别？ MSL 是 Maximum Segment Lifetime，报文最大生存时间，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。 TTL 字段，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。 MSL 与 TTL 的区别： MSL 的单位是时间，而 TTL 是经过路由跳数。所以 MSL 应该要大于等于 TTL 消耗为 0 的时间，以确保报文已被自然消亡。 TTL 的值一般是 64，Linux 将 MSL 设置为 30 秒，意味着 Linux 认为数据报文经过 64 个路由器的时间不会超过 30 秒，如果超过了，就认为报文已经消失在网络中了。 4.6为什么需要 TIME_WAIT 状态？需要 TIME-WAIT 状态，主要是两个原因： 防止历史连接中的数据，被后面相同四元组的连接错误的接收； 为了防止历史连接中的数据，被后面相同四元组的连接错误的接收，因此 TCP 设计了 TIME_WAIT 状态，状态会持续 2MSL 时长，这个时间足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。 保证「被动关闭连接」的一方，能被正确的关闭； TIME-WAIT 作用是等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。也就是当 ACK 报文丢失的时候，进行重传，恰好最大时间为 2MSL。 4.7TIME_WAIT 过多有什么危害？ 如果客户端（主动发起关闭连接方）的 TIME_WAIT 状态过多，占满了所有端口资源，那么就无法对「目的 IP+ 目的 PORT」都一样的服务端发起连接了，但是被使用的端口，还是可以继续对另外一个服务端发起连接的。 如果服务端（主动发起关闭连接方）的 TIME_WAIT 状态过多，并不会导致端口资源受限，因为服务端只监听一个端口，而且由于一个四元组唯一确定一个 TCP 连接，因此理论上服务端可以建立很多连接，但是 TCP 连接过多，会占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等。 追问：简述客户端的端口可否重复使用？ 在客户端执行 connect 函数的时候，只要客户端连接的服务器不是同一个，内核允许端口重复使用。 TCP 连接是由四元组（源IP地址，源端口，目的IP地址，目的端口）唯一确认的，那么只要四元组中其中一个元素发生了变化，那么就表示不同的 TCP 连接的。 所以，如果客户端已使用端口 64992 与服务端 A 建立了连接，那么客户端要与服务端 B 建立连接，还是可以使用端口 64992 的，因为内核是通过四元祖信息来定位一个 TCP 连接的，并不会因为客户端的端口号相同，而导致连接冲突的问题。 4.8如何优化 TIME_WAIT？ 打开 net.ipv4.tcp_tw_reuse 和 net.ipv4.tcp_timestamps 选项； 打开 net.ipv4.tcp_tw_reuse则可以复用处于 TIME_WAIT 的 socket 为新的连接所用。 有一点需要注意的是，tcp_tw_reuse 功能只能用客户端（连接发起方），因为开启了该功能，在调用 connect() 函数时，内核会随机找一个 time_wait 状态超过 1 秒的连接给新的连接复用。 net.ipv4.tcp_timestamps 用于 TCP 时间戳的支持 net.ipv4.tcp_max_tw_buckets 这个值默认为 18000，当系统中处于 TIME_WAIT 的连接一旦超过这个值时，系统就会将后面的 TIME_WAIT 连接状态重置 程序中使用 SO_LINGER TCP 连接将跳过四次挥手，也就跳过了TIME_WAIT状态，直接关闭。 如果服务端要避免过多的 TIME_WAIT 状态的连接，就永远不要主动断开连接，让客户端去断开，由分布在各处的客户端去承受 TIME_WAIT。 追问:为什么一般不开启tcp_tw_reuse tcp_tw_reuse 的作用是让客户端快速复用处于 TIME_WAIT 状态的端口，相当于跳过了 TIME_WAIT 状态，这可能会出现这样的两个问题： 历史 RST 报文可能会终止后面相同四元组的连接，因为 PAWS 检查到即使 RST 是过期的，也不会丢弃。 如果第四次挥手的 ACK 报文丢失了，有可能被动关闭连接的一方不能被正常的关闭; 虽然 TIME_WAIT 状态持续的时间是有一点长，显得很不友好，但是它被设计来就是用来避免发生乱七八糟的事情。 4.9什么场景下服务端会主动断开连接呢？ HTTP 没有使用长连接 根据大多数 Web 服务的实现，不管哪一方禁用了 HTTP Keep-Alive，都是由服务端主动关闭连接，那么此时服务端上就会出现 TIME_WAIT 状态的连接。 HTTP 长连接超时 假设设置了 HTTP 长连接的超时时间是 60 秒，nginx 就会启动一个「定时器」，如果客户端在完后一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，定时器的时间一到，nginx 就会触发回调函数来关闭该连接，那么此时服务端上就会出现 TIME_WAIT 状态的连接。 HTTP 长连接的请求数量达到上限 Web 服务端通常会有个参数，来定义一条 HTTP 长连接上最大能处理的请求数量，当超过最大限制时，就会主动关闭连接。 对于一些 QPS 比较高的场景，比如超过 10000 QPS，甚至达到 30000 , 50000 甚至更高，如果 keepalive_requests 参数值是 100，这时候就 nginx 就会很频繁地关闭连接，那么此时服务端上就会出大量的 TIME_WAIT 状态。 解决方法是调大 keepalive_requests 追问：不管哪一方禁用了 HTTP Keep-Alive，都是由服务端主动关闭连接 当客户端禁用了 HTTP Keep-Alive，这时候 HTTP 请求的 header 就会有 Connection:close 信息，这时服务端在发完 HTTP 响应后，就会主动关闭连接。HTTP 是请求-响应模型，发起方一直是客户端，HTTP Keep-Alive 的初衷是为客户端后续的请求重用连接，如果我们在某次 HTTP 请求-响应模型中，请求的 header 定义了 connection：close 信息，那不再重用这个连接的时机就只有在服务端了，所以我们在 HTTP 请求-响应这个周期的「末端」关闭连接是合理的。 当客户端开启了 HTTP Keep-Alive，而服务端禁用了 HTTP Keep-Alive，这时服务端在发完 HTTP 响应后，服务端也会主动关闭连接。在服务端主动关闭连接的情况下，只要调用一次 close() 就可以释放连接，剩下的工作由内核 TCP 栈直接进行了处理，整个过程只有一次 syscall；如果是要求 客户端关闭，则服务端在写完最后一个 response 之后需要把这个 socket 放入 readable 队列，调用 select / epoll 去等待事件；然后调用一次 read() 才能知道连接已经被关闭，这其中是两次 syscall，多一次用户态程序被激活执行，而且 socket 保持时间也会更长。 4.10如何应对服务端出现大量 CLOSE_WAIT 状态？当服务端出现大量 CLOSE_WAIT 状态的连接的时候，通常都是代码的问题，这时候我们需要针对具体的代码一步一步的进行排查和定位，主要分析的方向就是服务端为什么没有调用 close。 5.TCP 异常断开的几种可能5.1如果已经建立了连接，但是客户端突然出现故障了怎么办？TCP 保活机制。原理是定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。 追问：保活机制可能的三种情况 第一种，对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 TCP 保活时间会被重置，等待下一个 TCP 保活时间的到来。 第二种，对端主机宕机并重启。当 TCP 保活的探测报文发送给对端后，对端是可以响应的，但由于没有该连接的有效信息，会产生一个 RST 报文，这样很快就会发现 TCP 连接已经被重置。 第三种，是对端主机宕机（注意不是进程崩溃，进程崩溃后操作系统在回收进程资源的时候，会发送 FIN 报文，而主机宕机则是无法感知的，所以需要 TCP 保活机制来探测对方是不是发生了主机宕机），或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，TCP 会报告该 TCP 连接已经死亡。 5.2如果已经建立了连接，但是服务端的进程崩溃会发生什么？TCP 的连接信息是由内核维护的，所以当服务端的进程崩溃后，内核需要回收该进程的所有 TCP 连接资源，于是内核会发送第一次挥手 FIN 报文，后续的挥手过程也都是在内核完成，并不需要进程的参与，所以即使服务端的进程退出了，还是能与客户端完成 TCP 四次挥手的过程。 5.3TCP 连接，一端断电和进程崩溃有什么区别？5.4已建立连接的TCP，收到SYN会发生什么？即一个已经建立的 TCP 连接，客户端中途宕机了，而服务端此时也没有数据要发送，一直处于 Established 状态，客户端恢复后，向服务端建立连接，此时服务端会怎么处理？ 客户端的 SYN 报文里的端口号与历史连接不相同。此时服务端会认为是新的连接要建立，于是就会通过三次握手来建立新的连接。旧的连接有两种情况。 服务端发消息发现宕机，则断开连接 服务器不发消息，等待保活机制发现 客户端的 SYN 报文里的端口号与历史连接相同 处于 Established 状态的服务端，如果收到了客户端的 SYN 报文（注意此时的 SYN 报文其实是乱序的，因为 SYN 报文的初始化序列号其实是一个随机数），会回复一个携带了正确序列号和确认号的 ACK 报文，这个 ACK 被称之为 Challenge ACK。 接着，客户端收到这个 Challenge ACK，发现确认号（ack num）并不是自己期望收到的，于是就会回 RST 报文，服务端收到后，就会释放掉该连接。 5.5客户端主机宕机，又迅速重启在客户端主机宕机后，服务端向客户端发送的报文会得不到任何的响应，在一定时长后，服务端就会触发超时重传机制，重传未得到响应的报文。 服务端重传报文的过程中，客户端主机重启完成后，客户端的内核就会接收重传的报文，然后根据报文的信息传递给对应的进程： 如果客户端主机上没有进程绑定该 TCP 报文的目标端口号，那么客户端内核就会回复 RST 报文，重置该 TCP 连接； 如果客户端主机上有进程绑定该 TCP 报文的目标端口号，由于客户端主机重启后，之前的 TCP 连接的数据结构已经丢失了，客户端内核里协议栈会发现找不到该 TCP 连接的 socket 结构体，于是就会回复 RST 报文，重置该 TCP 连接。 所以，只要有一方重启完成后，收到之前 TCP 连接的报文，都会回复 RST 报文，以断开连接。 5.6客户端主机宕机，一直没有重启这种情况，服务端超时重传报文的次数达到一定阈值后，内核就会判定出该 TCP 有问题，然后通过 Socket 接口告诉应用程序该 TCP 连接出问题了，于是服务端的 TCP 连接就会断开。 5.7拔掉网线几秒，再插回去，原本的 TCP 连接还存在吗？有数据传输的情况： 在客户端拔掉网线后，如果服务端发送了数据报文，那么在服务端重传次数没有达到最大值之前，客户端就插回了网线，那么双方原本的 TCP 连接还是能正常存在，就好像什么事情都没有发生。 在客户端拔掉网线后，如果服务端发送了数据报文，在客户端插回网线之前，服务端重传次数达到了最大值时，服务端就会断开 TCP 连接。等到客户端插回网线后，向服务端发送了数据，因为服务端已经断开了与客户端相同四元组的 TCP 连接，所以就会回 RST 报文，客户端收到后就会断开 TCP 连接。至此， 双方的 TCP 连接都断开了。 没有数据传输的情况： 如果双方都没有开启 TCP keepalive 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，那么客户端和服务端的 TCP 连接状态将会一直保持存在。 如果双方都开启了 TCP keepalive 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，TCP keepalive 机制会探测到对方的 TCP 连接没有存活，于是就会断开 TCP 连接。而如果在 TCP 探测期间，客户端插回了网线，那么双方原本的 TCP 连接还是能正常存在。 6.为什么说TCP是可靠的？ TCP 的乱序重排、应答确认、报文重传和流量控制四种机制。 基于数据块传输：应用数据被分割成 TCP 认为最适合发送的数据块，再传输给网络层，数据块被称为报文段或段。 对失序数据包重新排序以及去重：TCP 为了保证不发生丢包，就给每个包一个序列号，有了序列号能够将接收到的数据根据序列号排序，并且去掉重复序列号的数据就可以实现数据包去重。 校验和 : TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。 超时重传 : 当发送方发送数据之后，它启动一个定时器，等待目的端确认收到这个报文段。接收端实体对已成功收到的包发回一个相应的确认信息（ACK）。如果发送端实体在合理的往返时延（RTT）内未收到确认消息，那么对应的数据包就被假设为丢失并进行重传。 流量控制 : TCP 连接的每一方都有固定大小的缓冲空间，TCP 的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议（TCP 利用滑动窗口实现流量控制）。 拥塞控制 : 当网络拥塞时，减少数据的发送。 6.1追问：重传机制有哪几种？ 超时重传。超时时间RTO一般通过数据往返一次的时间RTT来进行函数求得，每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。 快速重传。不以时间为驱动，而是以数据驱动重传。 缺点：如果Seq2和Seq3均发生丢失，那么如何告知将二者均进行重传 SACK。这种方式需要在 TCP 头部「选项」字段里加一个 SACK 的东西，它可以将已收到的数据的信息发送给「发送方」，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以只重传丢失的数据。 D-SACK。主要使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。 可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了; 可以知道是不是「发送方」的数据包被网络延迟了; 可以知道网络中是不是把「发送方」的数据包给复制了; 6.2追问：窗口大小怎么确定？所以，通常窗口的大小是由接收方的窗口大小来决定的。发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。 6.3追问：接收窗口和发送窗口的大小是相等的吗？ 并不是完全相等，接收窗口的大小是约等于发送窗口的大小的。在引入拥塞控制之后，发送窗口等于接收窗口和拥塞窗口的最小值。 因为滑动窗口并不是一成不变的。比如，当接收方的应用进程读取数据的速度非常快的话，这样的话接收窗口可以很快的就空缺出来。那么新的接收窗口大小，是通过 TCP 报文中的 Windows 字段来告诉发送方。那么这个传输过程是存在时延的，所以接收窗口和发送窗口是约等于的关系。 6.4追问：窗口关闭是什么？有哪些风险？如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是窗口关闭。 窗口关闭潜在的危险：接收方向发送方通告窗口大小时，是通过 ACK 报文来通告的。那么，当发生窗口关闭时，接收方处理完数据后，会向发送方通告一个窗口非 0 的 ACK 报文，如果这个通告窗口的 ACK 报文在网络中丢失了，这会导致发送方一直等待接收方的非 0 窗口通知，接收方也一直等待发送方的数据，如不采取措施，这种相互等待的过程，会造成了死锁的现象。。 6.5追问：TCP 是如何解决窗口关闭时，潜在的死锁现象呢？ TCP 为每个连接设有一个持续定时器，只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。 如果持续计时器超时，就会发送窗口探测 ( Window probe ) 报文，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。 如果接收窗口仍然为 0，那么收到这个报文的一方就会重新启动持续计时器； 如果接收窗口不是 0，那么死锁的局面就可以被打破了。 窗口探测的次数一般为 3 次，每次大约 30-60 秒（不同的实现可能会不一样）。如果 3 次过后接收窗口还是 0 的话，有的 TCP 实现就会发 RST 报文来中断连接。 6.6追问：简述糊涂窗口综合症 如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节，这就是糊涂窗口综合症。 要知道，我们的 TCP + IP 头有 40 个字节，为了传输那几个字节的数据，要搭上这么大的开销，这太不经济了。 解决办法： 让接收方不通告小窗口给发送方 当「窗口大小」小于 min( MSS，缓存空间/2 ) ，也就是小于 MSS 与 1/2 缓存大小中的最小值时，就会向发送方通告窗口为 0，也就阻止了发送方再发数据过来。 等到接收方处理了一些数据后，窗口大小 &gt;= MSS，或者接收方缓存空间有一半可以使用，就可以把窗口打开让发送方发送数据过来。 让发送方避免发送小数据 使用 Nagle 算法，该算法的思路是延时处理，只有满足下面两个条件中的任意一个条件，才可以发送数据： 条件一：要等到窗口大小 &gt;= MSS 并且 数据大小 &gt;= MSS； 条件二：收到之前发送数据的 ack 回包； 因此，接收方得满足「不通告小窗口给发送方」+ 发送方开启 Nagle 算法，才能避免糊涂窗口综合症。 6.7为什么要有拥塞控制，不是有流量控制了吗？ 前流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络的中发生了什么。 一般来说，计算机网络都处在一个共享的环境。因此也有可能会因为其他主机之间的通信使得网络拥堵。 在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大…. 所以，TCP 定义了拥塞控制，控制的目的就是避免「发送方」的数据填满整个网络。 6.8什么是拥塞窗口？和发送窗口有什么关系呢？拥塞窗口 cwnd是发送方维护的一个的状态变量，它会根据网络的拥塞程度动态变化的。 我们在前面提到过发送窗口 swnd 和接收窗口 rwnd 是约等于的关系，那么由于加入了拥塞窗口的概念后，此时发送窗口的值是swnd = min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的最小值。 拥塞窗口 cwnd 变化的规则： 只要网络中没有出现拥塞，cwnd 就会增大； 但网络中出现了拥塞，cwnd 就减少； 6.9如何定义当前网络是否出现了拥塞？其实只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是发生了超时重传，就会认为网络出现了拥塞。 6.10拥塞控制有哪些控制算法？ 慢启动 慢启动的算法记住一个规则就行：当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。 当 cwnd &lt; ssthresh 时，使用慢启动算法。 当 cwnd &gt;= ssthresh 时，就会使用「拥塞避免算法」。一般来说 ssthresh 的大小是 65535 字节。 拥塞避免 拥塞避免算法就是将原本慢启动算法的指数增长变成了线性增长，还是增长阶段，但是增长速度缓慢了一些。 就这么一直增长着后，网络就会慢慢进入了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进行重传。 当触发了重传机制，也就进入了「拥塞发生算法」。 拥塞发生 当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种： 超时重传 当发生了「超时重传」，则就会使用拥塞发生算法。这个时候，ssthresh 和 cwnd 的值会发生变化： ssthresh 设为 cwnd/2， cwnd 重置为 1 （是恢复为 cwnd 初始化值，我这里假定 cwnd 初始化值 1） 快速重传 还有更好的方式，前面我们讲过「快速重传算法」。当接收方发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传。TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 ssthresh 和 cwnd 变化如下： cwnd = cwnd/2 ，也就是设置为原来的一半; ssthresh = cwnd; 进入快速恢复算法 快速恢复 拥塞窗口 cwnd = ssthresh + 3 （ 3 的意思是确认有 3 个数据包被收到了）； 重传丢失的数据包； 如果再收到重复的 ACK，那么 cwnd 增加 1； 如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态； 7.如何优化 TCP？TCP三次握手性能优化： 客户端的优化：当客户端发起 SYN 包时，可以通过 tcp_syn_retries 控制其重传的次数。 服务端的优化： 当服务端 SYN 半连接队列溢出后，会导致后续连接被丢弃，可以调整 SYN 半连接队列的大小。 把 tcp_syncookies 参数设置为 1，表示在 SYN 队列满后开启 syncookie 功能，保证正常的连接成功建立。 把 tcp_abort_on_overflow 设置为 1 ，当全连接队列满了之后用 RST 通知客户端连接建立失败。 如果 accpet 队列溢出严重，可以提高队列的大小。 附录：调整的参数表 绕过三次握手：TCP Fast Open 功能可以绕过三次握手，使得 HTTP 请求减少了 1 个 RTT 的时间，Linux 下可以通过 tcp_fastopen 开启该功能，同时必须保证服务端和客户端同时支持。 TCP四次挥手性能优化： 减少重传次数 防止 TIME_WAIT 状态占用太多的资源，定义处于该状态的最大数量，超过数量则直接释放连接。 将 TIME_WAIT 状态的端口复用于作为客户端的新连接。 8.TCP 是面向字节流的协议，UDP 是面向报文的协议？这是因为操作系统对 TCP 和 UDP 协议的发送方的机制不同。 当用户消息通过 UDP 协议传输时，操作系统不会对消息进行拆分，在组装好 UDP 头部后就交给网络层来处理，所以发出去的 UDP 报文中的数据部分就是完整的用户消息，也就是每个 UDP 报文就是一个用户消息的边界，这样接收方在接收到 UDP 报文后，读一个 UDP 报文就能读取到完整的用户消息。 当用户消息通过 TCP 协议传输时，消息可能会被操作系统分组成多个的 TCP 报文，也就是一个完整的用户消息被拆分成多个 TCP 报文进行传输。这时，接收方的程序如果不知道发送方发送的消息的长度，也就是不知道消息的边界时，是无法读出一个有效的用户消息的，因为用户消息被拆分成多个 TCP 报文后，并不能像 UDP 那样，一个 UDP 报文就能代表一个完整的用户消息。 如何解决TCP粘包问题？ 一般有三种方式分包的方式： 固定长度的消息； 特殊字符作为边界； 自定义消息结构。 9.为什么 TCP 每次建立连接时，初始化序列号都要不一样呢？主要原因是为了防止历史报文被下一个相同四元组的连接接收。 追问：可以完全避免吗？ 不可以，因为序列号和初始化序列号并不是无限递增的，会发生回绕为初始值的情况。 追问：那么如何解决这个问题？ 引入时间戳，如果发现收到的数据包中时间戳不是递增的，则表示该数据包是过期的，就会直接丢弃这个数据包。 追问：如果时间戳也回绕了怎么办？ 这种情况发生的可能性比较小，但是也不能完全排除。那么可以采用增大时间戳的方法来解决。 10.SYN 报文什么时候情况下会被丢弃？TCP 两个队列满了（半连接队列和全连接队列），造成 SYN 报文被丢弃 在未开启 syncookies 时，当半连接队列满了，就会造成 SYN 报文丢失。 accpet 队列满了 ，后续的连接就会被丢弃 11.如何断开一个TCP连接？最简单的方法就是杀掉进程。 追问：有什么坏处？ 在客户端杀掉进程的话，就会发送 FIN 报文，来断开这个客户端进程与服务端建立的所有 TCP 连接，这种方式影响范围只有这个客户端进程所建立的连接，而其他客户端或进程不会受影响。 而在服务端杀掉进程影响就大了，此时所有的 TCP 连接都会被关闭，服务端无法继续提供访问服务。 那还有其他办法吗？ killcx： 用 Challenge ACK 里的确认号伪造 RST 报文发送给服务端，服务端收到 RST 报文后就会释放连接。 用 Challenge ACK 里的序列号伪造 RST 报文发送给客户端，客户端收到 RST 也会释放连接。 tcpkill： tcpkill 工具是在双方进行 TCP 通信时，拿到对方下一次期望收到的序列号，然后将序列号填充到伪造的 RST 报文，并将其发送给对方，达到关闭 TCP 连接的效果。（不适用于不活跃的TCP连接） killcx 工具是主动发送一个 SYN 报文，对方收到后会回复一个携带了正确序列号和确认号的 ACK 报文，这个 ACK 被称之为 Challenge ACK，这时就可以拿到对方下一次期望收到的序列号，然后将序列号填充到伪造的 RST 报文，并将其发送给对方，达到关闭 TCP 连接的效果。 12.在 TCP 正常挥手过程中，处于 TIME_WAIT 状态的连接，收到相同四元组的 SYN 后会发生什么？ 如果客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要大，并且SYN 的「时间戳」比服务端「最后收到的报文的时间戳」要大。那么就会重用该四元组连接，跳过 2MSL 而转变为 SYN_RECV 状态，接着就能进行建立连接过程。 如果客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要小，或者SYN 的「时间戳」比服务端「最后收到的报文的时间戳」要小。那么就会再回复一个第四次挥手的 ACK 报文，客户端收到后，发现并不是自己期望收到确认号，就回 RST 报文给服务端。 在 TIME_WAIT 状态，收到 RST 会断开连接吗？ 如果 net.ipv4.tcp_rfc1337 参数为 0，则提前结束 TIME_WAIT 状态，释放连接。 如果 net.ipv4.tcp_rfc1337 参数为 1，则会丢掉该 RST 报文。 13.HTTP的Keep-Alive和TCP的Keepalive的区别 HTTP 的 Keep-Alive 也叫 HTTP 长连接，该功能是由「应用程序」实现的，可以使得用同一个 TCP 连接来发送和接收多个 HTTP 请求/应答，减少了 HTTP 短连接带来的多次 TCP 连接建立和释放的开销。 TCP 的 Keepalive 也叫 TCP 保活机制，该功能是由「内核」实现的，当客户端和服务端长达一定时间没有进行数据交互时，内核为了确保该连接是否还有效，就会发送探测报文，来检测对方是否还在线，然后来决定是否要关闭该连接。 14.目前TCP协议存在哪些缺陷? 升级 TCP 的工作很困难； TCP 建立连接的延迟； TCP 存在队头阻塞问题； 网络迁移需要重新建立 TCP 连接； 15.建立TCP连接的几种情况 15.1不使用 listen ，可以建立 TCP 连接吗？是可以的，客户端是可以自己连自己的形成连接（TCP自连接），也可以两个客户端同时向对方发出请求建立连接（TCP同时打开），这两个情况都有个共同点，就是没有服务端参与，也就是没有listen，就能建立连接。 15.2那没有listen，还有半连接队列吗？为什么还能建立连接？ 显然没有，因为客户端没有执行listen，因为半连接队列和全连接队列都是在执行 listen 方法时，内核自动创建的。 我们知道执行 listen 方法时，会创建半连接队列和全连接队列。三次握手的过程中会在这两个队列中暂存连接信息。所以形成连接，前提是你得有个地方存放着，方便握手的时候能根据 IP + 端口等信息找到对应的 socket。但内核还有个全局 hash 表，可以用于存放 sock 连接的信息。 15.3没有 accept，能建立 TCP 连接吗？ 每一个socket执行listen时，内核都会自动创建一个半连接队列和全连接队列。 第三次握手前，TCP连接会放在半连接队列中，直到第三次握手到来，才会被放到全连接队列中。 accept方法只是为了从全连接队列中拿出一条连接，本身跟三次握手几乎毫无关系。 出于效率考虑，虽然都叫队列，但半连接队列其实被设计成了哈希表，而全连接队列本质是链表。 全连接队列满了，再来第三次握手也会丢弃，此时如果tcp_abort_on_overflow=1，还会直接发RST给客户端。 半连接队列满了，可能是因为受到了SYN Flood攻击，可以设置tcp_syncookies，绕开半连接队列。 客户端没有半连接队列和全连接队列，但有一个全局hash，可以通过它实现自连接或TCP同时打开。 16.用了 TCP 协议，数据一定不会丢吗？ 数据从发送端到接收端，链路很长，任何一个地方都可能发生丢包，几乎可以说丢包不可避免。 平时没事也不用关注丢包，大部分时候TCP的重传机制保证了消息可靠性。 当你发现服务异常的时候，比如接口延时很高，总是失败的时候，可以用ping或者mtr命令看下是不是中间链路发生了丢包。 TCP只保证传输层的消息可靠性，并不保证应用层的消息可靠性。如果我们还想保证应用层的消息可靠性，就需要应用层自己去实现逻辑做保证。 17.TCP 四次挥手中，能不能把第二次的 ACK 报文， 放到第三次 FIN 报文一起发送？结论：在一些情况下， TCP 四次挥手是可以变成 TCP 三次挥手的。 服务器收到客户端的 FIN 报文时，内核会马上回一个 ACK 应答报文，但是服务端应用程序可能还有数据要发送，所以并不能马上发送 FIN 报文，而是将发送 FIN 报文的控制权交给服务端应用程序： 如果服务端应用程序有数据要发送的话，就发完数据后，才调用关闭连接的函数； 如果服务端应用程序没有数据要发送的话，可以直接调用关闭连接的函数， 当被动关闭方（上图的服务端）在 TCP 挥手过程中，「没有数据要发送」并且「开启了 TCP 延迟确认机制」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手。 追问：什么是 TCP 延迟确认机制？当发送没有携带数据的 ACK，它的网络效率也是很低的，因为它也有 40 个字节的 IP 头 和 TCP 头，但却没有携带数据报文。 为了解决 ACK 传输效率低问题，所以就衍生出了 TCP 延迟确认。 TCP 延迟确认的策略： 当有响应数据要发送时，ACK 会随着响应数据一起立刻发送给对方 当没有响应数据要发送时，ACK 将会延迟一段时间，以等待是否有响应数据可以一起发送 如果在延迟等待发送 ACK 期间，对方的第二个数据报文又到达了，这时就会立刻发送 ACK 18.TCP 序列号和确认号是如何变化的？发送的 TCP 报文： 公式一：序列号 = 上一次发送的序列号 + len（数据长度）。特殊情况，如果上一次发送的报文是 SYN 报文或者 FIN 报文，则改为 上一次发送的序列号 + 1。 公式二：确认号 = 上一次收到的报文中的序列号 + len（数据长度）。特殊情况，如果收到的是 SYN 报文或者 FIN 报文，则改为上一次收到的报文中的序列号 + 1。 19.如何基于UDP协议实现可靠传输？QUIC 通过单向递增的 Packet Number，配合 Stream ID 与 Offset 字段信息，可以支持乱序确认而不影响数据包的正确组装，摆脱了TCP 必须按顺序确认应答 ACK 的限制，解决了 TCP 因某个数据包重传而阻塞后续所有待发送数据包的问题。 Packet Number 单调递增，有两个好处： 可以更加精确计算 RTT，没有 TCP 重传的歧义性问题； 可以支持乱序确认，因为丢包重传将当前窗口阻塞在原地，而 TCP 必须是顺序确认的，丢包时会导致窗口不滑动； 19.1QUIC 是如何解决 TCP 队头阻塞问题的？QUIC 给每一个 Stream 都分配了一个独立的滑动窗口，这样使得一个连接上的多个 Stream 之间没有依赖关系，都是相互独立的，各自控制的滑动窗口。 19.2QUIC 是如何做流量控制的？QUIC 实现了两种级别的流量控制，分别为 Stream 和 Connection 两种级别： Stream 级别的流量控制：Stream 可以认为就是一条 HTTP 请求，每个 Stream 都有独立的滑动窗口，所以每个 Stream 都可以做流量控制，防止单个 Stream 消耗连接（Connection）的全部接收缓冲。 Connection 流量控制：限制连接中所有 Stream 相加起来的总字节数，防止发送方超过连接的缓冲容量。 19.3QUIC对拥塞控制的改进？QUIC 协议当前默认使用了 TCP 的 Cubic 拥塞控制算法（我们熟知的慢开始、拥塞避免、快重传、快恢复策略），同时也支持 CubicBytes、Reno、RenoBytes、BBR、PCC 等拥塞控制算法，相当于将 TCP 的拥塞控制算法照搬过来了。 QUIC 是如何改进 TCP 的拥塞控制算法的呢？ QUIC 是处于应用层的，应用程序层面就能实现不同的拥塞控制算法，不需要操作系统，不需要内核支持。这是一个飞跃，因为传统的 TCP 拥塞控制，必须要端到端的网络协议栈支持，才能实现控制效果。而内核和操作系统的部署成本非常高，升级周期很长，所以 TCP 拥塞控制算法迭代速度是很慢的。而 QUIC 可以随浏览器更新，QUIC 的拥塞控制算法就可以有较快的迭代速度。 TCP 更改拥塞控制算法是对系统中所有应用都生效，无法根据不同应用设定不同的拥塞控制策略。但是因为 QUIC 处于应用层，所以就可以针对不同的应用设置不同的拥塞控制算法，这样灵活性就很高了。 19.4QUIC的连接迁移？QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果。 QUIC 协议没有用四元组的方式来“绑定”连接，而是通过连接 ID来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了连接迁移的功能。 IP篇1.网络层（IP）与数据链路层（MAC）有什么关系呢？ IP 的作用是主机之间通信用的，而 MAC 的作用则是实现「直连」的两个设备之间通信，而 IP 则负责在「没有直连」的两个网络之间进行通信传输。 在传输过程中源IP地址和目标IP地址在传输过程中是不会变化的（前提：没有使用 NAT 网络），只有源 MAC 地址和目标 MAC 一直在变化。 一个小问题：现在不仅电脑配了 IP 地址， 手机、IPad 等电子设备都配了 IP 呀，照理来说肯定会超过 43 亿啦，那是怎么能够支持这么多 IP 的呢？ 因为会根据一种可以更换 IP 地址的技术 NAT，使得可连接计算机数超过 43 亿台。 2.IP地址基础知识 2.1如何计算最大主机数？最大主机个数，就是要看主机号的位数，如 C 类地址的主机号占 8 位，那么 C 类地址的最大主机个数： 为什么要减 2 呢？ 因为在 IP 地址中，有两个 IP 是特殊的，分别是主机号全为 1 和 全为 0 地址。 主机号全为 1 指定某个网络下的所有主机，用于广播 主机号全为 0 指定某个网络 2.2广播地址用于什么？广播地址用于在同一个链路中相互连接的主机之间发送数据包。广播地址可以分为本地广播和直接广播两种。 在本网络内广播的叫做本地广播。例如网络地址为 192.168.0.0/24 的情况下，广播地址是 192.168.0.255 。因为这个广播地址的 IP 包会被路由器屏蔽，所以不会到达 192.168.0.0/24 以外的其他链路上。 在不同网络之间的广播叫做直接广播。例如网络地址为 192.168.0.0/24 的主机向 192.168.1.255/24 的目标地址发送 IP 包。收到这个包的路由器，将数据转发给 192.168.1.0/24，从而使得所有 192.168.1.1~192.168.1.254 的主机都能收到这个包（由于直接广播有一定的安全问题，多数情况下会在路由器上设置为不转发。） 。 2.3什么是 D、E 类地址？D 类和 E 类地址是没有主机号的，所以不可用于主机 IP，D 类常被用于多播，E 类是预留的分类，暂时未使用。 2.4多播地址用于什么？多播用于将包发送给特定组内的所有主机。 2.5IP 分类的优点和缺点优点： 通过IP分类，可以很快找到网络地址和主机地址。 缺点： 同一网络下没有地址层次，比如一个公司里用了 B 类地址，但是可能需要根据生产环境、测试环境、开发环境来划分地址层次，而这种 IP 分类是没有地址层次划分的功能，所以这就缺少地址的灵活性。 A、B、C类有个尴尬处境，就是不能很好的与现实网络匹配。 C 类地址能包含的最大主机数量实在太少了，只有 254 个，估计一个网吧都不够用。 而 B 类地址能包含的最大主机数量又太多了，6 万多台机器放在一个网络下面，一般的企业基本达不到这个规模，闲着的地址就是浪费。 这两个缺点，都可以在 CIDR 无分类地址解决。 2.6什么是无分类地址 CIDR？表示形式 a.b.c.d/x，其中 /x 表示前 x 位属于网络号， x 的范围是 0 ~ 32，这就使得 IP 地址更加具有灵活性。 2.7为什么要分离网络号和主机号？因为两台计算机要通讯，首先要判断是否处于同一个广播域内，即网络地址是否相同。如果网络地址相同，表明接受方在本网络上，那么可以把数据包直接发送到目标主机。 2.9环回地址是不会流向网络 环回地址是在同一台计算机上的程序之间进行网络通信时所使用的一个默认地址。 计算机使用一个特殊的 IP 地址 127.0.0.1 作为环回地址。与该地址具有相同意义的是一个叫做 localhost 的主机名。使用这个 IP 或主机名时，数据包不会流向网络。 3. IPv63.1IPv6 的亮点 IPv6 可自动配置，即使没有 DHCP 服务器也可以实现自动分配IP地址，真是便捷到即插即用啊。 IPv6 包头包首部长度采用固定的值 40 字节，去掉了包头校验和，简化了首部结构，减轻了路由器负荷，大大提高了传输的性能。 IPv6 有应对伪造 IP 地址的网络安全功能以及防止线路窃听的功能，大大提升了安全性。 4.一些协议4.1DNS4.2APR上述两个协议看之前的笔记 补充RAPR：APR是根据IP地址找MAC地址；RAPR是根据MAC地址找IP地址。 4.3DHCP通过 DHCP 动态获取 IP 地址。 4.4NAT网络地址转换方法，将私有IP转换为公有IP。 缺点： 外部无法主动与 NAT 内部服务器建立连接，因为 NAPT 转换表没有转换记录。 转换表的生成与转换操作都会产生性能开销。 通信过程中，如果 NAT 路由器重启了，所有的 TCP 连接都将被重置。 解决： 第一种就是改用 IPv6 NAT穿透技术：就是客户端主动从 NAT 设备获取公有 IP 地址，然后自己建立端口映射条目，然后用这个条目对外通信，就不需要 NAT 设备来进行转换了。 4.5ICMP互联网控制报文协议。在网络包遇到各种问题时，传出消息，报告遇到了什么问题，这样才可以调整传输策略，以此来控制整个局面。 4.5.1ICMP 功能都有啥？确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。 4.5.2ICMP类型ICMP 大致可以分为两大类： 一类是用于诊断的查询消息，也就是「查询报文类型」 另一类是通知出错原因的错误消息，也就是「差错报文类型」 4.6IGMP在前面我们知道了组播地址，也就是 D 类地址，既然是组播，那就说明是只有一组的主机能收到数据包，不在一组的主机不能收到数组包，怎么管理是否是在一组呢？那么，就需要 IGMP 协议了。 5.ping的工作原理 ping 命令执行的时候，源主机首先会构建一个 ICMP 回送请求消息数据包。ICMP 数据包内包含多个字段，最重要的是两个： 第一个是类型，对于回送请求消息而言该字段为 8； 另外一个是序号，主要用于区分连续 ping 的时候发出的多个数据包。 然后，由 ICMP 协议将这个数据包连同地址 192.168.1.2 一起交给 IP 层。IP 层将以 192.168.1.2 作为目的地址，本机 IP 地址作为源地址，协议字段设置为 1 表示是 ICMP 协议，再加上一些其他控制信息，构建一个 IP 数据包。 接下来，需要加入 MAC 头。如果在本地 ARP 映射表中查找出 IP 地址 192.168.1.2 所对应的 MAC 地址，则可以直接使用；如果没有，则需要发送 ARP 协议查询 MAC 地址，获得 MAC 地址后，由数据链路层构建一个数据帧，目的地址是 IP 层传过来的 MAC 地址，源地址则是本机的 MAC 地址；还要附加上一些控制信息，依据以太网的介质访问规则，将它们传送出去。 主机 B 收到这个数据帧后，先检查它的目的 MAC 地址，并和本机的 MAC 地址对比，如符合，则接收，否则就丢弃。 接收后检查该数据帧，将 IP 数据包从帧中提取出来，交给本机的 IP 层。同样，IP 层检查后，将有用的信息提取后交给 ICMP 协议。 主机 B 会构建一个 ICMP 回送响应消息数据包，回送响应数据包的类型字段为 0，序号为接收到的请求数据包中的序号，然后再发送出去给主机 A。 在规定的时候间内，源主机如果没有接到 ICMP 的应答包，则说明目标主机不可达；如果接收到了 ICMP 回送响应消息，则说明目标主机可达。 此时，源主机会检查，用当前时刻减去该数据包最初从源主机上发出的时刻，就是 ICMP 数据包的时间延迟。 追问：断网了，还能 ping 通 127.0.0.1 吗？答案是可以的。ping 本机地址的时候，走的是本地回环接口，即”假网卡”，都会经过网络层和数据链路层等逻辑，最后在快要出网卡前狠狠拐了个弯， 将数据插入到一个链表后就软中断通知 ksoftirqd 来进行收数据的逻辑，压根就不出网络。所以断网了也能 ping 通回环地址。 追问：TCP发数据和Ping差别大吗？差别不大。程序基本一样。可以把Ping看做是自己组建了一个数据包进行发送。 追问：ping回环地址和ping本机地址有什么区别？ ping 本机IP 跟 ping 回环地址一样，相关的网络数据，都是走的本地回环接口，只要走了本地回环接口，那数据都不会发送到网络中，在本机网络协议栈中兜一圈，就发回来了。因此 ping回环地址和ping本机地址没有区别。 追问：127.0.0.1 和 localhost 有区别吗 127.0.0.1 是回环地址。localhost是域名，但默认等于 127.0.0.1。 6.traceroute —— 差错报文类型的使用有一款充分利用 ICMP 差错报文类型的应用叫做 traceroute（在UNIX、MacOS中是这个命令，而在Windows中对等的命令叫做 tracert ）。 作用： 第一个作用就是故意设置特殊的 TTL，来追踪去往目的地时沿途经过的路由器。 作用如何实现？ 它的原理就是利用 IP 包的生存期限 从 1 开始按照顺序递增的同时发送 UDP 包，强制接收 ICMP 超时消息的一种方法。 比如，将 TTL 设置 为 1，则遇到第一个路由器，就牺牲了，接着返回 ICMP 差错报文网络包，类型是时间超时。 接下来将 TTL 设置为 2，第一个路由器过了，遇到第二个路由器也牺牲了，也同时返回了 ICMP 差错报文数据包，如此往复，直到到达目的主机。 这样的过程，traceroute 就可以拿到了所有的路由器 IP。 发送方如何知道发出的 UDP 包是否到达了目的主机呢？ traceroute 在发送 UDP 包时，会填入一个不可能的端口号值作为 UDP 目标端口号：33434。然后对于每个下一个探针，它都会增加一个，这些端口都是通常认为不会被使用，不过，没有人知道当某些应用程序监听此类端口时会发生什么。 当目的主机，收到 UDP 包后，会返回 ICMP 差错报文消息，但这个差错报文消息的类型是「端口不可达」。 所以，当差错报文类型是端口不可达时，说明发送方发出的 UDP 包到达了目的主机。 traceroute 还有一个作用是故意设置不分片，从而确定路径的 MTU。 这样做的目的： 这样做的目的是为了路径MTU发现。 因为有的时候我们并不知道路由器的 MTU 大小，以太网的数据链路上的 MTU 通常是 1500 字节，但是非以太网的 MTU 值就不一样了，所以我们要知道 MTU 的大小，从而控制发送的包大小。 原理： 首先在发送端主机发送 IP 数据报时，将 IP 包首部的分片禁止标志位设置为 1。根据这个标志位，途中的路由器不会对大数据包进行分片，而是将包丢弃。 随后，通过一个 ICMP 的不可达消息将数据链路上 MTU 的值一起给发送主机，不可达消息的类型为「需要进行分片但设置了不分片位」。 发送主机端每次收到 ICMP 差错报文时就减少包的大小，以此来定位一个合适的 MTU 值，以便能到达目标主机。","link":"/2023/07/12/%E8%AE%A1%E7%BD%91/"},{"title":"Leetcode","text":"力扣刷题记录 Chapter1-EasyQuestion1: Two Sum题目描述：给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出和为目标值 target 的那两个整数，并返回它们的数组下标。 可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。 可以按任意顺序返回答案。 分析：看到题目第一眼思考就是采用暴力破解的方法，将数组里的全部元素都进行遍历，寻找是否有符合的数字。 解法一：暴力求解 12345678910111213class Solution { public int[] twoSum(int[] nums, int target) { int n = nums.length; for (int i = 0; i &lt; n; ++i) { for (int j = i + 1; j &lt; n; ++j) { if (nums[i] + nums[j] == target) { return new int[]{i, j}; } } } return new int[0]; }} 暴力求解时间复杂度为O(N2) 暴力求解空间复杂度为O(1) 解法二：利用哈希表 12345678910111213141516171819202122class Solution { public int[] twoSum(int[] nums, int target) { //Perhaps the best one of all I have seen. //First create the result set. int[] res = new int[2]; //Judge the set. if(nums == null || nums.length == 0){ return res; } Map&lt;Integer,Integer&gt; map = new HashMap&lt;Integer,Integer&gt;(); for(int i = 0; i &lt; nums.length; i++) { int temp = target - nums[i]; if(map.containsKey(temp)) { res[1] = map.get(temp); res[0] = i; } //Insert into map map.put(nums[i],i); } return res; }} 利用哈希表得到的性能优于暴力求解 时间复杂度为O(N) 空间复杂度为O(N) Question2:Palindrome题目要求：给你一个整数 x ，如果 x 是一个回文整数，返回 true ；否则，返回 false 。 回文数是指正序（从左向右）和倒序（从右向左）读都是一样的整数。 例如，121 是回文，而 123 不是。 分析：最简单的就是转换为一个字符串之后进行一一对比；进一步的思路是，将倒过来的数字求出来，然后进行对比。 解法一： 12345678910111213class Solution { public boolean isPalindrome(int x) { String s = Integer.toString(x); char arr[] = s.toCharArray(); boolean flag = true;//判断是不是回文数 for (int i = 0; i &lt; arr.length / 2; i++) { if (arr[i] != arr[arr.length - 1 - i]) { flag = false; } } return flag; }} 解法二：将数字进行反转之后比较与原有数字是否相同 1234567891011121314151617class Solution { public boolean isPalindrome(int x) { if(x &lt; 0 ||(x % 10 == 0 &amp;&amp; x != 0) ) { return false; } if(x == 0) { return true; } int reverse = 0; int temp = x; while(x &gt; 0) { reverse = reverse * 10 + x % 10; x = x / 10; } return temp == reverse || temp == reverse / 10; }} 解法三：对解法二的拓展（官方解答）相当于只做一半的反转，然后进行比较 1234567891011121314151617181920212223class Solution { public boolean isPalindrome(int x) { // 特殊情况： // 如上所述，当 x &lt; 0 时，x 不是回文数。 // 同样地，如果数字的最后一位是 0，为了使该数字为回文， // 则其第一位数字也应该是 0 // 只有 0 满足这一属性 if (x &lt; 0 || (x % 10 == 0 &amp;&amp; x != 0)) { return false; } int revertedNumber = 0; while (x &gt; revertedNumber) { revertedNumber = revertedNumber * 10 + x % 10; x /= 10; } // 当数字长度为奇数时，我们可以通过 revertedNumber/10 去除处于中位的数字。 // 例如，当输入为 12321 时，在 while 循环的末尾我们可以得到 x = 12，revertedNumber = 123， // 由于处于中位的数字不影响回文（它总是与自己相等），所以我们可以简单地将其去除。 return x == revertedNumber || x == revertedNumber / 10; }} Question3:Roman numerals to integers题目要求： 分析：本题目只要读明白题目是不难的。首先，我们要通过一种方式 ，将罗马数字和整数之间有一个对应（评论区有一个枚举法，就是将所有可能的情况全部进行一一对应，然后在进行判断），对应之后，我们判断this的罗马数字和下一位的比较，如果this&gt;this+1,那么就说明正常加即可，但是this&lt;this_1的时候，就需要进行相减。别忘记判断越界 解答： 123456789101112131415161718192021222324252627282930313233343536373839404142public int romanToInt(String s) { //本题目是为了将罗马数字转化为普通的数字 //我们要进行两个判断，首先判断他是谁，然后判断他与下一位的比较，判断正负 //1.将罗马数字与数字做对应 //{'I':1,'V':5,'X':10,'L':50,'C':100,'D':500,'M':1000 int length = s.length(); int[] nums = new int[length]; for (int i = 0; i &lt; length; i++) { switch (s.charAt(i)){ case 'I': nums[i] = 1; break; case 'V': nums[i] = 5; break; case 'X': nums[i] = 10; break; case 'L': nums[i] = 50; break; case 'C': nums[i] = 100; break; case 'D': nums[i] = 500; break; case 'M': nums[i] = 1000; break; } } int res = 0; for(int i = 0; i &lt; nums.length; i++) { if((i &lt; nums.length - 1) &amp;&amp; nums[i] &lt; nums[i+1]){ res -= nums[i]; } else { res += nums[i]; } } return res; } Question4:The longest identical prefix题目描述： 编写一个函数来查找字符串数组中的最长公共前缀。如果不存在公共前缀，返回空字符串””。 分析：本题我是采用数据结构老师韩顺平的方法，先写出查找第一个字母是否相同，然后进行推断可以得到一个循环来进行判断。 解答： 1234567891011121314151617181920212223242526272829303132333435class Solution { public String longestCommonPrefix(String[] strs) { //先创建一个数组，把长度添加到数组 int len = strs.length; int[] lenSet = new int[len]; int minLen = 200; for (int i = 0; i &lt; len; i++) { lenSet[i] = strs[i].length(); if (strs[i].length() &lt; minLen) { minLen = strs[i].length(); } } StringBuffer res = new StringBuffer(); //把第一步的做法进行循环即可 for (int j = 0; j &lt; minLen; j++) { //我先把第一个字符串的第一个字母取出来 char fir = strs[0].charAt(j); boolean flag = true; for (int i = 0; i &lt; strs.length; i++) { if (strs[i].charAt(j) != fir) { flag = false; break; } } if (flag) { res.append(fir); } else { break; } } String resStr = res.toString(); return resStr; }} 上述个人答案属于纵向对比，时间复杂度为O(mn),空间复杂度为O(1) LeetCode官方还有下述几种算法： 横向扫描：拿最长字串去做对比，对比之后更新最长字串 分治算法：yysy，没看懂，以后再来补吧 二分算法：取mid，判断其前缀是否相同来进行判断 Question5:Valid Brackets题目描述： 给定一个只包括 ‘(‘，’)’，’{‘，’}’，’[‘，’]’ 的字符串 s ，判断字符串是否有效。有效字符串需满足： 左括号必须用相同类型的右括号闭合。 左括号必须以正确的顺序闭合。 每个右括号都有一个对应的相同类型的左括号。 分析： 题目的意思是，在s这个只含有括号的字符串中，只能含有三种情 况，”()” “{}” “[]”，不可以进行嵌套，也就是不可以存在”([)]”，本人做法未考虑这种嵌套。 解答： 解法一： 12345678public boolean isValid(String s) { int length = s.length() / 2; for (int i = 0; i &lt; length; i++) { s = s.replace(&quot;()&quot;, &quot;&quot;).replace(&quot;{}&quot;, &quot;&quot;).replace(&quot;[]&quot;, &quot;&quot;); } return s.length() == 0;} 这种解法只考虑了代码的简洁程度，并没有考虑算法的复杂度。 解法二：使用栈空间进行求解 12345678910111213141516171819Deque&lt;Character&gt; deque = new LinkedList&lt;&gt;(); char ch; for (int i = 0; i &lt; s.length(); i++) { ch = s.charAt(i); //碰到左括号，就把相应的右括号入栈 if (ch == '(') { deque.push(')'); }else if (ch == '{') { deque.push('}'); }else if (ch == '[') { deque.push(']'); } else if (deque.isEmpty() || deque.peek() != ch) { return false; }else {//如果是右括号判断是否和栈顶元素匹配 deque.pop(); } } //最后判断栈中元素是否匹配 return deque.isEmpty(); 123456789101112131415161718192021222324252627class Solution { public boolean isValid(String s) { int n = s.length(); if (n % 2 == 1) { return false; } Map&lt;Character, Character&gt; pairs = new HashMap&lt;Character, Character&gt;() {{ put(')', '('); put(']', '['); put('}', '{'); }}; Deque&lt;Character&gt; stack = new LinkedList&lt;Character&gt;(); for (int i = 0; i &lt; n; i++) { char ch = s.charAt(i); if (pairs.containsKey(ch)) { if (stack.isEmpty() || stack.peek() != pairs.get(ch)) { return false; } stack.pop(); } else { stack.push(ch); } } return stack.isEmpty(); }} 利用栈的特性后进先出，将所有的左括号压入栈内，当遇到一个有括号的时候，判断栈顶的括号是否和它匹配，如果匹配就继续，不匹配的话就return false 本题属于遇到的第一个数据结构题目，对于复习数据结构方面的知识还是很有好处的 Question6:Merge two LinkedLists题目描述： 将两个升序链表合并为一个新的 升序 链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的 解答： 1234567891011121314151617181920212223public ListNode mergeTwoLists(ListNode list1, ListNode list2) { //先创建一个新链表的头节点 ListNode newNode = new ListNode(0); ListNode cur = newNode; while (list1 != null &amp;&amp; list2 != null) { if (list1.val &lt; list2.val) { cur.next = list1; cur = cur.next; list1 = list1.next; } else { cur.next = list2; cur = cur.next; list2 = list2.next; } } //当一个链表为空的时候，就把非空的接在后面就行了 if (list1 == null) { cur.next = list2; } else if(list2 == null){ cur.next = list1; } return newNode.next; } 本题比较简单，没有什么很难的点，但是要注意一下链表的定义。 Question7:Remove duplicate numbers题目描述： 给你一个 升序排列 的数组 nums ，请你 原地 删除重复出现的元素，使每个元素 只出现一次 ，返回删除后数组的新长度。元素的 相对顺序 应该保持 一致 。 由于在某些语言中不能改变数组的长度，所以必须将结果放在数组nums的第一部分。更规范地说，如果在删除重复项之后有 k 个元素，那么 nums 的前 k 个元素应该保存最终结果。 将最终结果插入 nums 的前 k 个位置后返回 k 。 不要使用额外的空间，你必须在 原地 修改输入数组 并在使用 O(1) 额外空间的条件下完成。 测试代码： 123456789int[] nums = [...]; // 输入数组int[] expectedNums = [...]; // 长度正确的期望答案int k = removeDuplicates(nums); // 调用assert k == expectedNums.length;for (int i = 0; i &lt; k; i++) { assert nums[i] == expectedNums[i];} 分析：刚开始想把所有的重复的都通过冒泡挪到最后面，但是对于很多情况不适用。看了评论，学会了双指针与单指针的方法。其实大体就是向后判断，后面的要是没有重复，就把它加到前面判断完的后面就行。 解答： 解法一：双指针 123456789101112131415161718public int removeDuplicates(int[] nums) { //利用双指针 if(nums == null || nums.length == 1) { return nums.length; } //创建双指针 int i = 0, j = 1; while( j &lt; nums.length) { if(nums[i] == nums[j]) { j++; } else { i++; nums[i] = nums[j]; j++; } } return i+1; } 解法二：单指针判断 123456789public int removeDuplicates(int[] nums) { int index = 0; for(int i = 1; i &lt; nums.length; i++) { if(nums[i] != nums[i-1]){ nums[++index] = nums[i]; } } return index+1;} Question8:Remove specified value题目描述： 给你一个数组 nums 和一个值 val，你需要 原地 移除所有数值等于 val 的元素，并返回移除后数组的新长度。 不要使用额外的数组空间，你必须仅使用 O(1) 额外空间并 原地 修改输入数组。 元素的顺序可以改变。你不需要考虑数组中超出新长度后面的元素。 分析： 这道题目和上一个类似，都是要取出元素，也可以用指针来做。本人的做法是，构造一个指针指向最末尾的元素，如果前面出现了与指定数字相同的元素，就将这个位置的元素与最后的元素进行交换，交换之后，还要再继续进行这个位置的遍历。 题解： 解法一： 12345678910111213141516public int removeElement(int[] nums, int val) { //采用指针 int count = nums.length; int last = nums.length - 1; for(int i = 0; i &lt;= last; i++) { if(nums[i] == val) { int temp = nums[i]; nums[i] = nums[last]; nums[last] = temp; last--; i--; count--; } } return count; } 解答二： 123456789public int removeElement(int[] nums, int val) { int k = 0; for(int i = 0; i &lt; nums.length; i++) { if(nums[i] != val) { nums[k++] = nums[i]; } } return k; } Question9:Search target number题目描述： 给定一个排序数组和一个目标值，在数组中找到目标值，并返回其索引。如果目标值不存在于数组中，返回它将会被按顺序插入的位置。 请必须使用时间复杂度为 O(log n) 的算法。 分析： 本题就一个二分遍历就完事了 解答： 解法一：直接遍历 12345678910111213141516public int searchInsert(int[] nums, int target) { if(nums.length ==0 || nums == null) { return 0; } if(target &gt; nums[nums.length - 1]) { return nums.length; } int index = 0; for(int i =0; i &lt; nums.length; i++) { if(nums[i] == target || nums[i] &gt; target) { index = i; break; } } return index; } 解法二：二分法查找 12345678910111213public int searchInsert(int[] nums, int target) { int len = nums.length; int l=0,r=len-1; while(l&lt;=r){ int mid=l+(r-l)/2; if(nums[mid]&lt;target){ l=mid+1; } else { r=mid-1; } } return l; } Question10:Last word count题目描述： 给你一个字符串 s，由若干单词组成，单词前后用一些空格字符隔开。返回字符串中 最后一个 单词的长度。 单词是指仅由字母组成、不包含任何空格字符的最大子字符串。 题解： 123456789101112public int lengthOfLastWord(String s) { String str = s.trim(); int count = 0; for (int i = str.length() - 1; i &gt;= 0; i--) { if (str.charAt(i) != ' ') { count++; } else { break; } } return count;} Question11:Plus one题目描述： 给定一个由 整数 组成的 非空 数组所表示的非负整数，在该数的基础上加一。 最高位数字存放在数组的首位， 数组中每个元素只存储单个数字。 你可以假设除了整数 0 之外，这个整数不会以零开头。 分析： 错误原因是考虑不全面，个人思考的是先将这个数组转换为整数，再将整数加1，然后返回加1之后的数组，没有考虑到整数型溢出的问题。 其实本题思路很简单，从后往前遍历，如果遇到一位不是9，那么直接加一，然后返回即可；如果全是9，那么将所有的i置为0，把首位置为1即可。 题解： 12345678910for (int i = digits.length - 1; i &gt;= 0; i--) { if (digits[i] != 9) { digits[i]++; return digits; } digits[i] = 0; } int[] res = new int[digits.length+1]; res[0] = 1; return res; Question12:Binary addition题目描述： 给你两个二进制字符串 a 和 b ，以二进制字符串的形式返回它们的和。 分析： 本题做法分为三步： 先将二者的长度置为相同，通过对较短的字符串进行补0来实现 设置一个进位数，通过判断当前的值来看是否发生了进位 将判断的结果加入到字符串中，最终对字符串进行反转即可 题解： 123456789101112131415161718public String addBinary(String a, String b) { StringBuffer ans = new StringBuffer(); int n = Math.max(a.length(), b.length()), carry = 0; for (int i = 0; i &lt; n; ++i) { carry += i &lt; a.length() ? (a.charAt(a.length() - 1 - i) - '0') : 0; carry += i &lt; b.length() ? (b.charAt(b.length() - 1 - i) - '0') : 0; ans.append((char) (carry % 2 + '0')); carry /= 2; } if (carry &gt; 0) { ans.append('1'); } ans.reverse(); return ans.toString(); } Question13:Integer multiples of the square root题目描述： 给定一个非负整数 x ，计算并返回 x 的算术平方根 。 由于返回类型是整数，结果只保留整数部分 ，小数部分将被舍去 。 注意：不允许使用任何内置指数函数和算符，例如 pow(x, 0.5) 。 分析： 本题很容易就能想到，你可以找一个数，它的平方小于等于这个给定的数，并且+1之后又大于了这个给定的数，这样就找到了这个数。 题解： 方法一：袖珍计算器法 注意： 由于计算机无法存储浮点数的精确值，而指数函数和对数函数的参数和返回值均为浮点数，因此运算过程中会存在误差。因此在得到结果的整数部分 ans 后，我们应当找出ans 与ans+1 中哪一个是真正的答案。 123456789class Solution { public int mySqrt(int x) { if (x == 0) { return 0; } int ans = (int) Math.exp(0.5 * Math.log(x)); return (long) (ans + 1) * (ans + 1) &lt;= x ? ans + 1 : ans; }} 方法二：二分法 123456789101112131415161718class Solution { public int mySqrt(int x) { if(x==1) { return 1; } int max = x; int min = 0; while(max - min &gt; 1) { int mid = (max + min) / 2; if(x/mid &lt; mid) { max = mid; } else { min = mid; } } return min; }} 方法三：牛顿迭代 牛顿迭代 Question14:Climb stairs题目描述： 一个人爬楼梯，只能爬一个台阶或者两个，问有几种上楼的方法。 分析： 刚开始我认为这是一道迭代的题目，相当于斐波那契数列，但是发现，如果按照迭代来做，超出了时间限制，因此需要用动态规划的思想来看这个题目。 题解： 方法一： 12345678910111213141516public int climbStairs(int n) { if (n == 1) { return 1; } if (n == 2) { return 2; } int i1 = 1; int i2 = 2; for(int i = 3; i &lt;= n; i++) { int temp = i1+i2; i1 = i2; i2 = temp; } return i2; } 方法二：矩阵计算法 1234567891011121314151617181920212223242526272829public class Solution { public int climbStairs(int n) { int[][] q = {{1, 1}, {1, 0}}; int[][] res = pow(q, n); return res[0][0]; } public int[][] pow(int[][] a, int n) { int[][] ret = {{1, 0}, {0, 1}}; while (n &gt; 0) { if ((n &amp; 1) == 1) { ret = multiply(ret, a); } n &gt;&gt;= 1; a = multiply(a, a); } return ret; } public int[][] multiply(int[][] a, int[][] b) { int[][] c = new int[2][2]; for (int i = 0; i &lt; 2; i++) { for (int j = 0; j &lt; 2; j++) { c[i][j] = a[i][0] * b[0][j] + a[i][1] * b[1][j]; } } return c; }} 方法三：利用微分方程的思想 1234567public class Solution { public int climbStairs(int n) { double sqrt5 = Math.sqrt(5); double fibn = Math.pow((1 + sqrt5) / 2, n + 1) - Math.pow((1 - sqrt5) / 2, n + 1); return (int) Math.round(fibn / sqrt5); }} Question15:删除排序链表中的重复数据题目描述： 给定一个已排序的链表的头 head ， 删除所有重复的元素，使每个元素只出现一次 。返回 已排序的链表 。 题解： 个人解法： 123456789101112131415161718192021222324252627/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */class Solution { public ListNode deleteDuplicates(ListNode head) { //先设置一个指针 if(head == null) { return null; } ListNode cur = head; while(cur.next != null) { if(cur.next.val == cur.val) { cur.next = cur.next.next; } else{ cur = cur.next; } } return head; }} 递归法： 如果当前的val和下一个节点的val相等的话，就让当前指针指向下一个节点；不等的话，就处理下一个节点 123456789101112131415161718192021222324/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */class Solution { public ListNode deleteDuplicates(ListNode head) { //先设置一个指针 if(head == null || head.next == null) { return head; } if(head.val == head.next.val) { head = deleteDuplicates(head.next); } else { head.next = deleteDuplicates(head.next); } return head; }} Question16:合并两个有序数组题目描述： 给你两个按 非递减顺序 排列的整数数组 nums1 和 nums2，另有两个整数 m 和 n ，分别表示 nums1 和 nums2 中的元素数目。 请你 合并 nums2 到 nums1 中，使合并后的数组同样按 非递减顺序 排列。 注意：最终，合并后数组不应由函数返回，而是存储在数组 nums1 中。为了应对这种情况，nums1 的初始长度为 m + n，其中前 m 个元素表示应合并的元素，后 n 个元素为 0 ，应忽略。nums2 的长度为 n 。 题解： 方法一：使用最简单的方式，就是把nums2中的所有的数字加到nums1中的空白处，然后对整个数组进行排序 123456public void merge(int[] nums1, int m, int[] nums2, int n) { for (int i = 0; i &lt; n; i++) { nums1[m+i] = nums2[i]; } Arrays.sort(nums1); } 方法二：利用双指针（逆向的就不用考虑后面的移位问题了） 123456789101112class Solution { public void merge(int[] nums1, int m, int[] nums2, int n) { int p = m-- + n-- - 1; while(m&gt;=0 &amp;&amp; n&gt;=0) { nums1[p--] = nums1[m] &gt; nums2[n] ? nums1[m--] : nums2[n--]; } while(n &gt;= 0) { nums1[p--] = nums2[n--]; } }} Question17:二叉树的中序遍历题目描述： 实现二叉树的中序遍历 分析： 这是数据结构课上的一个很简单的例子，一定要把数组创建在方法外！ 题解： 方法一：使用递归的方法 123456789101112class Solution { List&lt;Integer&gt; res= new LinkedList&lt;&gt;(); public List&lt;Integer&gt; inorderTraversal(TreeNode root) { // TreeNode cur = root; if(root != null) { inorderTraversal(root.left); res.add(root.val); inorderTraversal(root.right); } return res; }} 方法二：使用栈 主要思想就是先将当前节点压入栈内，然后遍历左边的节点并且压入栈，左侧的节点遍历完了就把栈中的数据按照顺序输出，在输出的同时还要判断这个节点有无右节点，有的话就输出。 12345678910111213141516171819class Solution { public List&lt;Integer&gt; inorderTraversal(TreeNode root) { List&lt;Integer&gt; list= new LinkedList&lt;&gt;(); Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); TreeNode cur = root; while (cur != null || !stack.isEmpty()) { if (cur != null) { stack.push(cur); cur = cur.left; } else { cur = stack.pop(); list.add(cur.val); cur = cur.right; } } return list; }} 方法三：Morris 中序遍历详解 Question18:判断两个二叉树是否完全相同题目描述： 判断两个二叉树是否完全相同（包括结构和数据） 题解： 方法一：使用递归来解决很容易的 12345678910public boolean isSameTree(TreeNode p, TreeNode q) { if(p == null &amp;&amp; q == null) { return true; } if(p != null &amp;&amp; q != null &amp;&amp; p.val == q.val) { return isSameTree(p.left,q.left) &amp;&amp; isSameTree(p.right,q.right); } else { return false; } } 方法二：广度优先算法 12345678910111213141516171819202122public boolean isSameTree(TreeNode p, TreeNode q) { // 广度优先 Queue&lt;TreeNode&gt; tmpQueue = new LinkedList&lt;TreeNode&gt;(); tmpQueue.offer(p); tmpQueue.offer(q); while(!tmpQueue.isEmpty()){ p = tmpQueue.poll(); q = tmpQueue.poll(); if(p == null &amp;&amp; q == null){ continue; } if((p == null || q == null) || p.val != q.val){ return false; } tmpQueue.offer(p.left); tmpQueue.offer(q.left); tmpQueue.offer(p.right); tmpQueue.offer(q.right); } return true; } 补充：offer()表示向队列里面添加元素，并且返回true，如果队列满了就返回false Question19:判断二叉树是否为对称二叉树题目描述： 给你一个二叉树的根节点 root ， 检查它是否轴对称。 举个例子： 题解：二叉树的定义 123456789101112131415/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */ 方法一：使用递归来求 1234567891011121314151617181920class Solution { public boolean isSymmetric(TreeNode root) { if(root == null) { return true; } return isEqual(root.left,root.right); } public boolean isEqual(TreeNode node1, TreeNode node2) { if(node1 == null &amp;&amp; node2 == null) { return true; } if(node1 == null || node2 == null || node1.val != node2.val) { return false; } return isEqual(node1.left,node2.right) &amp;&amp; isEqual(node1.right,node2.left); }} 方法二：使用迭代来做 12345678910111213141516171819202122232425262728class Solution { public boolean isSymmetric(TreeNode root) { //使用迭代法来求 if(root == null) { return true; } Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root.left); queue.offer(root.right); while(!queue.isEmpty()) { TreeNode node1 = queue.poll(); TreeNode node2 = queue.poll(); if(node1 == null &amp;&amp; node2 == null) { continue; } if(node1 == null || node2 == null || node1.val != node2.val) { return false; } queue.offer(node1.left); queue.offer(node2.right); queue.offer(node1.right); queue.offer(node2.left); } return true; } } Question20:求二叉树的最大深度题目描述： 给定一个二叉树，找出其最大深度。 二叉树的深度为根节点到最远叶子节点的最长路径上的节点数。 题解： 解法一：递归 123public int maxDepth(TreeNode root) { return root == null ? 0 : Math.max(maxDepth(root.left), maxDepth(root.right))+1; } 解法二：BFS(广度优先就是先把这一层判断之后再判断下一层) 123456789101112131415161718public int maxDepth(TreeNode root) { if (root == null) { return 0; } int level = 0; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;TreeNode&gt;(); queue.add(root); while (!queue.isEmpty()) { int size = queue.size(); level++; for (int i = 0; i &lt; size; i++) { TreeNode node = queue.remove(); if (node.left != null) queue.add(node.left); if (node.right != null) queue.add(node.right); } } return level; } 解法三：DFS(深度优先，就是先把这一个分支判断之后再判断其他分支，实时更新最大深度) 12345678910111213141516171819class Solution { int maxLevel = 0; public int maxDepth(TreeNode root) { if (root == null) { return 0; } dfs(root, 1); return maxLevel; } public void dfs(TreeNode root, int level) { if (root == null) return; if (level &gt; maxLevel) maxLevel = level; dfs(root.left, level + 1); dfs(root.right, level + 1); }} Question21:路径总和问题题目描述： 给你二叉树的根节点 root 和一个表示目标和的整数 targetSum 。判断该树中是否存在 根节点到叶子节点 的路径，这条路径上所有节点值相加等于目标和 targetSum 。如果存在，返回 true ；否则，返回 false 。 叶子节点 是指没有子节点的节点 注意，如果给定的二叉树为空并且targetNum=0，结果依旧是false 题解： 这是一个简单的递归的题目，我们采取逆向思维 先找叶子节点，如果此时判断的节点为叶子节点，那就看看目标值-叶子结点的值是否等于前面路径上的值之和 如果不是叶子节点，进行递归，将目标值减去当前节点的值 123456789101112131415161718192021222324252627/** * Definition for a binary tree node. * public class TreeNode { * int val; * TreeNode left; * TreeNode right; * TreeNode() {} * TreeNode(int val) { this.val = val; } * TreeNode(int val, TreeNode left, TreeNode right) { * this.val = val; * this.left = left; * this.right = right; * } * } */class Solution { public boolean hasPathSum(TreeNode root, int targetSum) { if(root == null) { return false; } if(root.left == null &amp;&amp; root.right == null) { return targetSum-root.val == 0; } return hasPathSum(root.left,targetSum-root.val) || hasPathSum(root.right,targetSum-root.val); }} Question22:杨辉三角题目描述： 给定一个非负整数 numRows，生成「杨辉三角」的前 numRows 行。 在「杨辉三角」中，每个数是它左上方和右上方的数的和。 题解： 本题不难，就是求出一个杨辉三角形即可，个人的难点就是使用List集合的时候不够熟练，平时都是用数组来做。 1234567891011121314151617181920class Solution { public List&lt;List&lt;Integer&gt;&gt; generate(int numRows) { List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;List&lt;Integer&gt;&gt;(); for (int i = 0; i &lt; numRows; i++) { List&lt;Integer&gt; mid = new ArrayList&lt;Integer&gt;(); for (int j = 0; j &lt;= i; j++) { if (j==0 || j==i) { mid.add(1); } else { //先获取上一行的值 List&lt;Integer&gt; up = res.get(i-1); mid.add(up.get(j-1) + up.get(j)); } } res.add(mid); } return res; }} Question23:杨辉三角Ⅱ题目描述： 给定一个非负索引 rowIndex，返回「杨辉三角」的第 rowIndex 行。 在「杨辉三角」中，每个数是它左上方和右上方的数的和。 题解： 本题和上一道题区别就在于一个返回的是全部集合，一个是返回指定行的集合。 方法一：创建出杨辉三角，然后取指定的那一行 1234567891011121314151617181920class Solution { public List&lt;Integer&gt; getRow(int rowIndex) { List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;List&lt;Integer&gt;&gt;(); for (int i = 0; i &lt;= rowIndex; i++) { List&lt;Integer&gt; mid = new ArrayList&lt;Integer&gt;(); for (int j = 0; j &lt;= i; j++) { if (j==0 || j==i) { mid.add(1); } else { //先获取上一行的值 List&lt;Integer&gt; up = res.get(i-1); mid.add(up.get(j-1) + up.get(j)); } } res.add(mid); } return res.get(rowIndex); }} 方法二：利用杨辉三角形同行之间的关系来求 1234567891011121314/** * 获取杨辉三角的指定行 * 直接使用组合公式C(n,i) = n!/(i!*(n-i)!) * 则第(i+1)项是第i项的倍数=(n-i)/(i+1); */public List&lt;Integer&gt; getRow(int rowIndex) { List&lt;Integer&gt; res = new ArrayList&lt;&gt;(rowIndex + 1); long cur = 1; for (int i = 0; i &lt;= rowIndex; i++) { res.add((int) cur); cur = cur * (rowIndex-i)/(i+1); } return res; } 复杂度更低，优先记这个 Question24:计算最大收益题目描述： 给定一个数组 prices ，它的第 i 个元素 prices[i] 表示一支给定股票第 i 天的价格。 你只能选择 某一天 买入这只股票，并选择在 未来的某一个不同的日子 卖出该股票。设计一个算法来计算你所能获取的最大利润。 返回你可以从这笔交易中获取的最大利润。如果你不能获取任何利润，返回 0 。 题解：线性规划 12345678910111213141516class Solution { public int maxProfit(int[] prices) { int maxProfit = 0; int minPrice = Integer.MAX_VALUE; for (int i = 0; i &lt; prices.length; i++) { if (prices[i] &lt; minPrice) { minPrice = prices[i]; } if (prices[i] - minPrice &gt; maxProfit) { maxProfit = prices[i] - minPrice; } } return maxProfit; }} 分析：本题最简单的思路是，采用两次循环，来求出最大的利润，这样的作法时间复杂度太高，会超出时间范围，因此在这里不做赘述。 Question25：判断回文数题目描述： 如果在将所有大写字符转换为小写字符、并移除所有非字母数字字符之后，短语正着读和反着读都一样。则可以认为该短语是一个 回文串 。 字母和数字都属于字母数字字符。 给你一个字符串 s，如果它是 回文串 ，返回 true ；否则，返回 false 。 题解： 方法一： 最简单的办法就是去除所有标点和空格之后，再进行判断，注意要将所有的字符串都转换为小写的 1234567891011121314class Solution { public boolean isPalindrome(String s) { String str1 = s.replaceAll(&quot;[^0-9a-zA-Z]&quot;,&quot;&quot;); String str = str1.toLowerCase(); boolean flag = true; for(int i = 0; i &lt; str.length()/2; i++) { if(str.charAt(i) != str.charAt(str.length() - i - 1)){ flag = false; break; } } return flag; }} 方法二： 将字符串反转之后判断和源字符串是否相同 1234567891011121314class Solution { public boolean isPalindrome(String s) { StringBuffer sgood = new StringBuffer(); int length = s.length(); for (int i = 0; i &lt; length; i++) { char ch = s.charAt(i); if (Character.isLetterOrDigit(ch)) { sgood.append(Character.toLowerCase(ch)); } } StringBuffer sgood_rev = new StringBuffer(sgood).reverse(); return sgood.toString().equals(sgood_rev.toString()); }} 方法三：双指针（性能最优） 12345678910111213141516171819202122class Solution { public boolean isPalindrome(String s) { int n = s.length(); int left = 0, right = n - 1; while (left &lt; right) { while (left &lt; right &amp;&amp; !Character.isLetterOrDigit(s.charAt(left))) { ++left; } while (left &lt; right &amp;&amp; !Character.isLetterOrDigit(s.charAt(right))) { --right; } if (left &lt; right) { if (Character.toLowerCase(s.charAt(left)) != Character.toLowerCase(s.charAt(right))) { return false; } ++left; --right; } } return true; }} Question26:只出现一次的数字题目描述： 给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现两次。找出那个只出现了一次的元素。 题解分析： 使用集合存储数字。遍历数组中的每个数字，如果集合中没有该数字，则将该数字加入集合，如果集合中已经有该数字，则将该数字从集合中删除，最后剩下的数字就是只出现一次的数字。 使用哈希表存储每个数字和该数字出现的次数。遍历数组即可得到每个数字出现的次数，并更新哈希表，最后遍历哈希表，得到只出现一次的数字。 使用集合存储数组中出现的所有数字，并计算数组中的元素之和。由于集合保证元素无重复，因此计算集合中的所有元素之和的两倍，即为每个元素出现两次的情况下的元素之和。由于数组中只有一个元素出现一次，其余元素都出现两次，因此用集合中的元素之和的两倍减去数组中的元素之和，剩下的数就是数组中只出现一次的数字。 题解： 12345678910111213141516public int singleNumber(int[] nums) { //先将数组进行排序，然后加一个减一个，减去之后，如果返回的值不是0就说明找到了 Arrays.sort(nums); int res = nums[0]; for (int i = 1; i &lt; nums.length; i++) { if (i % 2 == 0) { res += nums[i]; } else { res -= nums[i]; if (res != 0) { return nums[i-1]; } } } return 0; } 方法二：位运算，最后剩下的就是最终结果、 123456789class Solution { public int singleNumber(int[] nums) { int single = 0; for (int num : nums) { single ^= num; } return single; }} Question27:判断链表中是否含有环形题目描述： 给你一个链表的头节点 head ，判断链表中是否有环。如果链表中存在环 ，则返回 true 。 否则，返回 false 。 分析： 这道题是为了判断在链表中是否含有环，可以分为下面两种思路： 利用Set中的元素不能重复这个原则，将节点加入到set中，如果返回为false，代表有环。 使用一个快指针，一个慢指针，如果有环的话，那终会有一个时刻二者相遇。 题解： 方法一： 12345678910111213public class Solution { public boolean hasCycle(ListNode head) { //首先用哈希集合的方法来做（由于哈希集不能有重复） Set&lt;ListNode&gt; set = new HashSet&lt;ListNode&gt;(); while (head != null) { if (!set.add(head)) { return true; } head = head.next; } return false; }} 方法二： 123456789101112131415161718public class Solution { public boolean hasCycle(ListNode head) { //使用第二种方法，即龟兔赛跑 if (head == null || head.next == null) { return false; } ListNode fast = head.next; ListNode slow = head; while (fast != slow) { if (fast == null || fast.next == null) { return false; } slow = slow.next; fast = fast.next.next; } return true; }} Question28:二叉树的前序遍历题目描述： 给你二叉树的根节点 root ，返回它节点值的 前序 遍历。 题解： 123456789101112131415List&lt;Integer&gt; preOrder = new ArrayList&lt;&gt;(); public List&lt;Integer&gt; preorderTraversal(TreeNode root) { if(root == null) { return preOrder; } preOrder.add(root.val); if(root.left != null) { preorderTraversal(root.left); } if(root.right != null) { preorderTraversal(root.right); } return preOrder; } 上面是自己做出来的解法，迭代和Mirrors解法看leetcode官方解答 Question29:实现二叉树的后序遍历题目描述: 实现二叉树的后序遍历 题解： 1234567891011121314151617181920class Solution { List&lt;Integer&gt; postOrder = new ArrayList&lt;&gt;(); public List&lt;Integer&gt; postorderTraversal(TreeNode root) { if(root == null) { return postOrder; } if(root.left != null) { postorderTraversal(root.left); } if(root.right != null) { postorderTraversal(root.right); } postOrder.add(root.val); return postOrder; }} Question30:获取两个链表相交的节点题目描述： 给你两个单链表的头节点 headA 和 headB ，请你找出并返回两个单链表相交的起始节点。如果两个链表不存在相交节点，返回 null 。 题目数据 保证 整个链式结构中不存在环。 注意，函数返回结果后，链表必须 保持其原始结构 。 题解： 方法一：个人做法 1234567891011121314151617public ListNode getIntersectionNode(ListNode headA, ListNode headB) { //个人思路：先将一个链表的所有节点加入到一个Set集合之中， //再判断另一个链表中的点是否在这个集合之中即可 Set&lt;ListNode&gt; set = new HashSet&lt;&gt;(); while (headA != null) { set.add(headA); headA = headA.next; } //现在有了链表A的节点集合，判断B while (set.add(headB)) { if(headB.next == null) { return null; } headB = headB.next; } return headB; } 方法二： 首先判断两个链表是否为空，若为空，直接返回null，否则进行下一步 将一个指针指向链表A的头部，另一个指针指向链表B的头部 将两个链表向后移，如果A指针走到了最后，那么就把他再次指向链表B；同理，如果B指针指向了最后，就把它再次指向链表A；如此做来，如果有交点，那么在进行过程中总会相遇的 12345678910111213public class Solution { public ListNode getIntersectionNode(ListNode headA, ListNode headB) { if (headA == null || headB == null) { return null; } ListNode pA = headA, pB = headB; while (pA != pB) { pA = pA == null ? headB : pA.next; pB = pB == null ? headA : pB.next; } return pA; }} Question31:Excel表列名称题目描述： 题解： 这个题目坏就坏在他是从1开始的，要是从0开始就能构成26进制数，就很简单了 1234567891011121314151617181920212223class Solution { public String convertToTitle(int columnNumber) { // //记录字母的个数 // int num = 0; // for(int i = 1; i &lt; 7; i++) { // if(Math.pow(26,i)/25-26/25 &gt;= columnNumber) { // num = i-1; // break; // } // } StringBuffer sb = new StringBuffer(); //在ASCII中A对应65 while(columnNumber &gt; 0) { int mod = (columnNumber-1) % 26; char ins = (char) (mod + 65); sb.append(ins); columnNumber = (columnNumber-1) / 26; } sb.reverse(); String res = sb.toString(); return res; }} Question32:寻找数组中出现次数多的数字题目描述： 给定一个大小为 n 的数组 nums ，返回其中的多数元素。多数元素是指在数组中出现次数 大于 ⌊ n/2 ⌋ 的元素。 你可以假设数组是非空的，并且给定的数组总是存在多数元素。 题解 ： 方法一： 使用最简单的方法，将数组进行排序，将排序后的数组进行判断，当前项是否等于n/2项后的那一项，如果等于就返回。 123456789101112131415class Solution { public int majorityElement(int[] nums) { //寻找数组中出现一半以上的元素 //第一种，最简单的方法 Arrays.sort(nums); int res = 0; for (int i= 0; i &lt; nums.length; i++) { if (nums[i] == nums[(nums.length+i) / 2]){ res = nums[i]; break; } } return res; }} 将上面的方法进行进一步的简化可得： 123456class Solution { public int majorityElement(int[] nums) { Arrays.sort(nums); return nums[nums.length/2]; }} 由于算法题，不建议使用已有的api，因此使用下列解答 方法二：概率化 使用概率的思想，由于寻找的数字出现的概率很大，因此我们随机抽取一个数来判断这个数是不是我们要找的数字 12345678910111213141516171819202122232425262728class Solution { private int randRange(Random rand, int min, int max) { return rand.nextInt(max - min) + min; } private int countOccurences(int[] nums, int num) { int count = 0; for (int i = 0; i &lt; nums.length; i++) { if (nums[i] == num) { count++; } } return count; } public int majorityElement(int[] nums) { Random rand = new Random(); int majorityCount = nums.length / 2; while (true) { int candidate = nums[randRange(rand, 0, nums.length)]; if (countOccurences(nums, candidate) &gt; majorityCount) { return candidate; } } }} 方法三：使用Map 12345678910111213141516171819202122232425262728class Solution { //获取数组的map集合，也就是数字-&gt;出现次数 private Map&lt;Integer,Integer&gt; getMap(int[] nums){ Map&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;(); for (int i = 0; i &lt; nums.length; i++) { if (!map.containsKey(nums[i])) { map.put(nums[i],1); } else { map.put(nums[i],map.get(nums[i])+1); } } return map; } public int majorityElement(int[] nums) { Map&lt;Integer, Integer&gt; map = getMap(nums); Map.Entry&lt;Integer, Integer&gt; majorityEntry = null; int res = 0; for(Map.Entry&lt;Integer,Integer&gt; entry : map.entrySet()) { if (entry.getValue() &gt; nums.length / 2) { res = entry.getKey(); break; } } return res; }} 运行结果还不如第一种方法 Question33:寻找Excel的序列号题目描述： 题解： 方法一：也就是Q31的逆过程 12345678910class Solution { public int titleToNumber(String columnTitle) { int num = columnTitle.length(); int res = 0; for (int i = 0; i &lt; num; i++) { res += (int) (columnTitle.charAt(i) - 64) * Math.pow(26,num-1-i); } return res; }} Question34:寻找1的个数题目描述： 编写一个函数，输入是一个无符号整数（以二进制串的形式），返回其二进制表达式中数字位数为 ‘1’ 的个数（也被称为汉明重量）。 提示： 请注意，在某些语言（如 Java）中，没有无符号整数类型。在这种情况下，输入和输出都将被指定为有符号整数类型，并且不应影响您的实现，因为无论整数是有符号的还是无符号的，其内部的二进制表示形式都是相同的。 在 Java 中，编译器使用二进制补码记法来表示有符号整数。因此,在上面的示例 3 中，输入表示有符号整数 -3。 题解： 方法一： 思路：我们可以直接循环检查给定整数 n的二进制位的每一位是否为 1。 具体代码中，当检查第 i 位时，我们可以让 n 与 2^i 进行与运算，当且仅当 n 的第 i 位为 1 时，运算结果不为 0。 123456789101112public class Solution { // you need to treat n as an unsigned value public int hammingWeight(int n) { int count = 0; for(int i = 0; i &lt; 32; i++) { if((n &amp; (1 &lt;&lt; i)) != 0) { count++; } } return count; }} 方法二： 思路：将n与(n-1)进行运算时，会把n中的最小位置上的 1 置为 0。举例如：6 = (110) , 5 = (101).对二者进行与运算之后成为(100)，也就是把6中的第二个1置为了0。在没有变成 0 之前的计算次数就是1的个数。 1234567891011public class Solution { // you need to treat n as an unsigned value public int hammingWeight(int n) { int res = 0; while(n != 0) { n &amp;= (n-1); res++; } return res; }} 不用一个一个判断，运算速度更快。 Question35:判断一个数是不是快乐数题目描述： 编写一个算法来判断一个数 n 是不是快乐数。 快乐数定义为： 对于一个正整数，每一次将该数替换为它每个位置上的数字的平方和。然后重复这个过程直到这个数变为 1，也可能是 无限循环 但始终变不到 1。 如果这个过程 结果为 1，那么这个数就是快乐数。 如果 n 是 快乐数 就返回 true ；不是，则返回 false 。 题解： 方法一： 使用一个较大的循环次数来判断他是不是快乐数 12345678910111213141516class Solution { public boolean isHappy(int n) { for (int i = 0; i &lt; 100; i++) { int ans = 0; while (n &gt; 0) { ans += (n%10) * (n%10); n /= 10; } n = ans; if (n == 1) { return true; } } return false; }} 方法二： 对一个数字进行题目描述的过程，最终会有三种结果出现： 最终会得到 11。 最终会进入循环。 值会越来越大，最后接近无穷大 因此这里我们先采取哈希集合来存放出现过的数字，如果重复出现了，就代表它不是一个快乐数 1234567891011121314151617181920class Solution { private int getNext(int n) { int totalSum = 0; while (n &gt; 0) { int d = n % 10; n = n / 10; totalSum += d * d; } return totalSum; } public boolean isHappy(int n) { Set&lt;Integer&gt; seen = new HashSet&lt;&gt;(); while (n != 1 &amp;&amp; !seen.contains(n)) { seen.add(n); n = getNext(n); } return n == 1; }} 方法三： 之前使用过的快慢指针法（判断是否存在环形的时候使用过） 12345678910111213141516171819202122class Solution { public int getNext(int n) { int totalSum = 0; while (n &gt; 0) { int d = n % 10; n = n / 10; totalSum += d * d; } return totalSum; } public boolean isHappy(int n) { int slowRunner = n; int fastRunner = getNext(n); while (fastRunner != 1 &amp;&amp; slowRunner != fastRunner) { slowRunner = getNext(slowRunner); fastRunner = getNext(getNext(fastRunner)); } return fastRunner == 1; }} Question36:判断两个字符串是不是同构字符串题目描述： 给定两个字符串 s 和 t ，判断它们是否是同构的。 如果 s 中的字符可以按某种映射关系替换得到 t ，那么这两个字符串是同构的。 每个出现的字符都应当映射到另一个字符，同时不改变字符的顺序。不同字符不能映射到同一个字符上，相同字符只能映射到同一个字符上，字符可以映射到自己本身。 例如add和egg就是同构字符串 题解： 方法一： 创建一个HashMap，存放s的第i个字符 - t的第i个字符 加入的时候进行判断，如果map的key中存在当前字符，那么value也会存在当前字符 再判断前一个位置是不是也是这一对 123456789101112131415161718192021222324class Solution { public boolean isIsomorphic(String s, String t) { if (s.length() != t.length()) { return false; } HashMap&lt;Character, Character&gt; map = new HashMap&lt;&gt;(); //构建s-t的hashmap，再进行判断 for (int i = 0; i &lt; s.length(); i++) { if (!map.containsKey(s.charAt(i))){ if (map.containsValue(t.charAt(i))) { return false; } map.put(s.charAt(i),t.charAt(i)); } else { if (map.get(s.charAt(i)) != t.charAt(i)) { return false; } } } return true; }} Question37:对链表进行反转题目描述： 根据给定链表的头节点，对链表进行反转 题解： 方法一：迭代 创建一个新的反转链表 对原有的链表从头到尾进行遍历，对当前取出的节点加入到新的反转链表最前面，即可实现反转 12345678910111213141516171819class Solution { public ListNode reverseList(ListNode head) { if (head == null) { return null; } //创建一个新的链表，然后遍历链表，将每一次遍历到的节点 //加入到新链表的头部 ListNode reverseNode = new ListNode(-1); ListNode cur = head;//这是辅助节点，用来遍历链表 ListNode next = null;//表示下一个节点 while (cur != null) { next = cur.next; cur.next = reverseNode.next; reverseNode.next = cur; cur = next; } return reverseNode.next; }} 方法二：递归 12345678910111213141516171819202122232425262728293031323334353637383940/** * 以链表1-&gt;2-&gt;3-&gt;4-&gt;5举例 * @param head * @return */ public ListNode reverseList(ListNode head) { if (head == null || head.next == null) { /* 直到当前节点的下一个节点为空时返回当前节点 由于5没有下一个节点了，所以此处返回节点5 */ return head; } //递归传入下一个节点，目的是为了到达最后一个节点 ListNode newHead = reverseList(head.next); /* 第一轮出栈，head为5，head.next为空，返回5 第二轮出栈，head为4，head.next为5，执行head.next.next=head也就是5.next=4， 把当前节点的子节点的子节点指向当前节点 此时链表为1-&gt;2-&gt;3-&gt;4&lt;-&gt;5，由于4与5互相指向，所以此处要断开4.next=null 此时链表为1-&gt;2-&gt;3-&gt;4&lt;-5 返回节点5 第三轮出栈，head为3，head.next为4，执行head.next.next=head也就是4.next=3， 此时链表为1-&gt;2-&gt;3&lt;-&gt;4&lt;-5，由于3与4互相指向，所以此处要断开3.next=null 此时链表为1-&gt;2-&gt;3&lt;-4&lt;-5 返回节点5 第四轮出栈，head为2，head.next为3，执行head.next.next=head也就是3.next=2， 此时链表为1-&gt;2&lt;-&gt;3&lt;-4&lt;-5，由于2与3互相指向，所以此处要断开2.next=null 此时链表为1-&gt;2&lt;-3&lt;-4&lt;-5 返回节点5 第五轮出栈，head为1，head.next为2，执行head.next.next=head也就是2.next=1， 此时链表为1&lt;-&gt;2&lt;-3&lt;-4&lt;-5，由于1与2互相指向，所以此处要断开1.next=null 此时链表为1&lt;-2&lt;-3&lt;-4&lt;-5 返回节点5 出栈完成，最终头节点5-&gt;4-&gt;3-&gt;2-&gt;1 */ head.next.next = head; head.next = null; return newHead; } Question38:判断数组是否存在重复元素题目描述： 给你一个整数数组 nums 。如果任一值在数组中出现 至少两次 ，返回 true ；如果数组中每个元素互不相同，返回 false 。 题解： 方法一： 将所有的元素进行排序，然后看相邻的元素是否相等，相等就返回true，否则返回false 123456789101112class Solution { public boolean containsDuplicate(int[] nums) { Arrays.sort(nums); int n = nums.length; for (int i = 0; i &lt; n - 1; i++) { if (nums[i] == nums[i + 1]) { return true; } } return false; }} 方法二： 将元素加入到HashSet之中，然后遍历数组，如果set中已有就返回true，反之则为false 12345678910111213141516public boolean containsDuplicate(int[] nums) { if (nums.length == 0 || nums.length == 1) { return false; } //先创建一个set HashSet&lt;Integer&gt; set = new HashSet&lt;&gt;(); for (int i = 0; i &lt; nums.length; i++) { if (set.contains(nums[i])) { return true; } set.add(nums[i]); } return false; } Question39:判断存在重复元素Ⅱ题目描述： 给你一个整数数组 nums 和一个整数 k ，判断数组中是否存在两个 不同的索引 i 和 j ，满足 nums[i] == nums[j] 且 abs(i - j) &lt;= k 。如果存在，返回 true ；否则，返回 false 。 题解： 方法一： 创建一个HashMap，构建nums[i] &lt;-&gt; i 的一个map 当有重复数字出现的时候，来判断一下，二者之间的距离是否小于等于k 如果不是，那么就用现在的这个这个下标代替之前的键值对 123456789101112131415161718class Solution { public boolean containsNearbyDuplicate(int[] nums, int k) { if (nums.length == 0 || nums.length == 1 || k == 0) { return false; } //先创建一个HashMap HashMap&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;(); for (int i = 0; i &lt; nums.length; i++) { if (map.containsKey(nums[i])) { if (Math.abs(map.get(nums[i])-i) &lt;= k) { return true; } } map.put(nums[i],i); } return false; }} 方法二：使用滑动窗口 考虑数组nums 中的每个长度不超过 k + 1 的滑动窗口，同一个滑动窗口中的任意两个下标差的绝对值不超过 k。如果存在一个滑动窗口，其中有重复元素，则返回true；如果所有滑动窗口中都没有重复元素，则不存在符合要求的下标。因此，只要遍历每个滑动窗口，判断滑动窗口中是否有重复元素即可。 123456789101112131415class Solution { public boolean containsNearbyDuplicate(int[] nums, int k) { Set&lt;Integer&gt; set = new HashSet&lt;Integer&gt;(); int length = nums.length; for (int i = 0; i &lt; length; i++) { if (i &gt; k) { set.remove(nums[i - k - 1]); } if (!set.add(nums[i])) { return true; } } return false; }} Question40:使用队列完成栈题目描述： 请你仅使用两个队列实现一个后入先出（LIFO）的栈，并支持普通栈的全部四种操作（push、top、pop 和 empty）。 实现 MyStack 类： void push(int x) 将元素 x 压入栈顶。 int pop() 移除并返回栈顶元素。 int top() 返回栈顶元素。 boolean empty() 如果栈是空的，返回 true ；否则，返回 false 。 注意： 你只能使用队列的基本操作 —— 也就是 push to back、peek/pop from front、size 和 is empty 这些操作。 你所使用的语言也许不支持队列。 你可以使用 list （列表）或者 deque（双端队列）来模拟一个队列 , 只要是标准的队列操作即可。 题解： 方法一：双队列 大致思路： 创建两个队列，queue1是栈，queue2是辅助队列 在添加元素的时候，先将元素加入到queue2队列之中，再把queue1中的元素按照顺序加入到queue2中，这个时候queue2就实现了后入先出 再将queue1和queue2交换即可 其余操作均对queue1进行即可 123456789101112131415161718192021222324252627282930Queue&lt;Integer&gt; queue1; Queue&lt;Integer&gt; queue2; public MyStack() { queue1 = new LinkedList&lt;Integer&gt;(); queue2 = new LinkedList&lt;Integer&gt;(); } public void push(int x) { //采用双队列 queue2.offer(x); while(!queue1.isEmpty()){ queue2.offer(queue1.poll()); } Queue&lt;Integer&gt; temp = queue1; queue1 = queue2; queue2 = temp; } public int pop() { return queue1.poll(); } public int top() { return queue1.peek(); } public boolean empty() { return queue1.isEmpty(); } 方法二：单队列 大致思路： 创建一个队列 在添加元素的时候，先将现有元素的个数n获取到，然后将元素加入到队列中，再将前n个元素依次加到队列的尾部即可 其余操作均对queue执行即可 1234567891011121314151617181920212223242526//使用单队列完成 Queue&lt;Integer&gt; queue; public MyStack() { queue = new LinkedList&lt;Integer&gt;(); } public void push(int x) { int size = queue.size(); queue.offer(x); for(int i = 0; i &lt; size; i++) { queue.offer(queue.poll()); } } public int pop() { return queue.poll(); } public int top() { return queue.peek(); } public boolean empty() { return queue.isEmpty(); } Question41:使用栈实现队列题目描述： 请你仅使用两个栈实现先入先出队列。队列应当支持一般队列支持的所有操作（push、pop、peek、empty）： 实现 MyQueue 类： void push(int x) 将元素 x 推到队列的末尾 int pop() 从队列的开头移除并返回元素 int peek() 返回队列开头的元素 boolean empty() 如果队列为空，返回 true ；否则，返回 false 说明： 你只能使用标准的栈操作 —— 也就是只有 push to top, peek/pop from top, size, 和 is empty 操作是合法的。你所使用的语言也许不支持栈。你可以使用 list 或者 deque（双端队列）来模拟一个栈，只要是标准的栈操作即可。 题解： 注意这个题目和上一个题目的区别，上个题目是对输入操作进行处理，这个是对输出进行处理 1234567891011121314151617181920212223242526272829303132333435363738class MyQueue { //使用栈实现队列，也就是后入先出转换为先入先出 //使用双栈的方式 private Stack&lt;Integer&gt; stack1; private Stack&lt;Integer&gt; stack2; public MyQueue() { stack1 = new Stack&lt;&gt;(); stack2 = new Stack&lt;&gt;(); } public void push(int x) { stack1.push(x); } public int pop() { if(stack2.isEmpty()) { while(!stack1.isEmpty()) { stack2.push(stack1.pop()); } } return stack2.pop(); } public int peek() { if(stack2.isEmpty()) { while(!stack1.isEmpty()) { stack2.push(stack1.pop()); } } return stack2.peek(); } public boolean empty() { return stack1.isEmpty() &amp;&amp; stack2.isEmpty(); }} Question42:实现二叉树的反转题目描述： 题解： 方法一：递归 这里要注意一下，使用递归的时候，一般采用设置一个新函数，然后调用这个函数即可 12345678910111213141516171819202122232425class Solution { public TreeNode invertTree(TreeNode root) { //递归实现 if(root == null) return root; inverse(root); return root; } public void inverse(TreeNode node) { if(node == null) { return; } TreeNode temp = node.left; node.left = node.right; node.right = temp; inverse(node.left); inverse(node.right); }} Question43:给数组元素划分区间题目描述： 给定一个 无重复元素 的 有序 整数数组 nums 。 返回 恰好覆盖数组中所有数字 的 最小有序 区间范围列表 。也就是说，nums 的每个元素都恰好被某个区间范围所覆盖，并且不存在属于某个范围但不属于 nums 的数字 x 。 列表中的每个区间范围 [a,b] 应该按如下格式输出： “a-&gt;b” ，如果 a != b“a” ，如果 a == b 举例： 题解： 设置双指针，如果值相等，输出一个数字，否则输出指定形式 12345678910111213141516171819202122class Solution { public List&lt;String&gt; summaryRanges(int[] nums) { List&lt;String&gt; ret = new ArrayList&lt;String&gt;(); int i = 0; int n = nums.length; while (i &lt; n) { int low = i; i++; while (i &lt; n &amp;&amp; nums[i] == nums[i - 1] + 1) { i++; } int high = i - 1; StringBuffer temp = new StringBuffer(Integer.toString(nums[low])); if (low &lt; high) { temp.append(&quot;-&gt;&quot;); temp.append(Integer.toString(nums[high])); } ret.add(temp.toString()); } return ret; }} Question44:判断一个数是不是2的幂次题目描述： 输入一个数，判断这个数是不是2的幂次 题解： 首先要注意，负数和0都不是2的幂次 方法一： 12345class Solution { public boolean isPowerOfTwo(int n) { return n &gt; 0 &amp;&amp; (n &amp; (n - 1)) == 0; }} 根据二进制数可以知道，如果一个数为2的幂次，那么这个数的二进制一定只有一个1，因此将n和(n-1)做与运算所得结果一定是0. 方法二： 12345class Solution { public boolean isPowerOfTwo(int n) { return n &gt; 0 &amp;&amp; (n &amp; -n) == n; }} 在计算机系统之中，负数是根据补码来保存的，因此通过n和-n的与运算也可以判断这个数是不是2的幂次。 方法三：个人做法 123456789101112131415class Solution { public boolean isPowerOfTwo(int n) { if(n==0 || n &lt; 0) { return false; } while(n &gt; 1) { if(n % 2 == 1){ return false; } n /= 2; } return true; }} Question45:设计Goal解析器题目描述： 请你设计一个可以解释字符串 command 的 Goal 解析器 。command 由 “G”、”()” 和/或 “(al)” 按某种顺序组成。Goal 解析器会将 “G” 解释为字符串 “G”、”()” 解释为字符串 “o” ，”(al)” 解释为字符串 “al” 。然后，按原顺序将经解释得到的字符串连接成一个字符串。 给你字符串 command ，返回 Goal 解析器 对 command 的解释结果。 题解： 方法一： 采用判断子字符串的方法，分别讨论出现三种情况下的结果。 12345678910111213141516171819class Solution { public String interpret(String command) { StringBuffer sb = new StringBuffer(); for (int i = 0; i &lt; command.length(); i++) { if (command.substring(i,i+1).equals(&quot;G&quot;)){ sb.append(&quot;G&quot;); } else if (command.substring(i,i+2).equals(&quot;()&quot;)){ sb.append(&quot;o&quot;); i++; } else { sb.append(&quot;al&quot;); i+=3; } } String res = sb.toString(); return res; }} 方法二： 代码简洁，但是时间复杂度和空间复杂度都不好 1return command.replace(&quot;()&quot;,&quot;o&quot;).replace(&quot;(al)&quot;,&quot;al&quot;) Question46:判断回文链表题目描述： 给你一个单链表的头节点 head ，请你判断该链表是否为回文链表。如果是，返回 true ；否则，返回 false 题解： 方法一： 要实现O(n)的时间复杂度和O(1)的空间复杂度，就需要反转后半部分来做 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061class Solution { public boolean isPalindrome(ListNode head) { //要实现O(n)的时间复杂度和O(1)的空间复杂度，就需要反转后半部分来做 if(head == null || head.next == null) { return true; } ListNode fast = head; ListNode slow = head; //利用快慢指针，来找到中间节点 while(fast.next != null &amp;&amp; fast.next.next != null) { fast = fast.next.next; slow = slow.next; } //反转后半部分链表 slow = reverse(slow.next); while(slow != null) { if(head.val != slow.val) { return false; } head = head.next; slow = slow.next; } return true; } /** 反转的方法（迭代法） */ private ListNode reverse(ListNode head) { ListNode pre = null; ListNode next = null; while(head != null) { next = head.next; head.next = pre; pre = head; head = next; } return pre; } /** 反转的方式（递归） */ private ListNode reverse1(ListNode head){ // 递归到最后一个节点，返回新的新的头结点 if (head.next == null) { return head; } ListNode newHead = reverse(head.next); head.next.next = head; head.next = null; return newHead; } } 注意反转的操作 Question47:有效的字母异位词题目描述： 给定两个字符串 s 和 t ，编写一个函数来判断 t 是否是 s 的字母异位词。 注意：若 s 和 t 中每个字符出现的次数都相同，则称 s 和 t 互为字母异位词。 题解： 方法一：个人做法 把两个字符串中的字符出现的次数放入到两个map之中，然后比较这两个map是否相同即可。 1234567891011121314151617181920212223public boolean isAnagram(String s, String t) { if (s.length() != t.length()) { return false; } //使用两个map来保存两个字符串分别出现的次数 Map&lt;Character,Integer&gt; map1 = new HashMap&lt;&gt;(); Map&lt;Character,Integer&gt; map2 = new HashMap&lt;&gt;(); for (int i = 0; i &lt; s.length(); i++) { if (!map1.containsKey(s.charAt(i))) { map1.put(s.charAt(i), 1); } else{ map1.put(s.charAt(i),map1.get(s.charAt(i))+1); } if (!map2.containsKey(t.charAt(i))) { map2.put(t.charAt(i), 1); } else{ map2.put(t.charAt(i),map2.get(t.charAt(i))+1); } } return map1.equals(map2); } 方法二： 将两个字符串进行排序，比较排序之后的字符串是否相同即可 123456789101112class Solution { public boolean isAnagram(String s, String t) { if (s.length() != t.length()) { return false; } char[] str1 = s.toCharArray(); char[] str2 = t.toCharArray(); Arrays.sort(str1); Arrays.sort(str2); return Arrays.equals(str1, str2); }} 方法三：哈希表 从另一个角度考虑，t 是 s 的异位词等价于两个字符串中字符出现的种类和次数均相等。由于字符串只包含 26 个小写字母，因此我们可以维护一个长度为 26 的频次数组table，先遍历记录字符串 s 中字符出现的频次，然后遍历字符串 t，减去table 中对应的频次，如果出现table[i]&lt;0，则说明 t 包含一个不在 s 中的额外字符，返回false 。 123456789101112131415161718class Solution { public boolean isAnagram(String s, String t) { if (s.length() != t.length()) { return false; } int[] table = new int[26]; for (int i = 0; i &lt; s.length(); i++) { table[s.charAt(i) - 'a']++; } for (int i = 0; i &lt; t.length(); i++) { table[t.charAt(i) - 'a']--; if (table[t.charAt(i) - 'a'] &lt; 0) { return false; } } return true; }} Question48:各位相加题目描述： 给定一个非负整数 num，反复将各个位上的数字相加，直到结果为一位数。返回这个结果。 举个例子： 123456输入: num = 38输出: 2 解释: 各位相加的过程为：38 --&gt; 3 + 8 --&gt; 1111 --&gt; 1 + 1 --&gt; 2由于 2 是一位数，所以返回 2。 题解： 方法一： 思路最简单的方法，就是利用迭代，一直对数字进行处理，直到数字为个位数 12345678910111213class Solution { public int addDigits(int num) { while (num &gt;= 10) { int sum = 0; while (num &gt; 0) { sum += num % 10; num /= 10; } num = sum; } return num; }} 方法二： 利用数根的思想 12345class Solution { public int addDigits(int num) { return (num - 1) % 9 + 1; }} Question49:丑数题目描述： 丑数 就是只包含质因数 2、3 和 5 的正整数。 给你一个整数 n ，请你判断 n 是否为 丑数 。如果是，返回 true ；否则，返回 false 。 题解： 1234567891011121314class Solution { public boolean isUgly(int n) { if(n &lt;= 0) { return false; } int[] factors = {2,3,5}; for(int factor : factors) { while(n % factor == 0) { n /= factor; } } return n==1; }} Question50:丢失的数字题目描述： 给定一个包含 [0, n] 中 n 个数的数组 nums ，找出 [0, n] 这个范围内没有出现在数组中的那个数。 题解： 方法一： 将数组进行排序 遍历排序后的数组，看nums[i] 和 i是否相等 如果不相等，就代表i缺失 如果遍历的结果发现都相等，那么缺失的就是最后一个数字，返回n即可 123456789101112class Solution { public int missingNumber(int[] nums) { Arrays.sort(nums); int n = nums.length; for (int i = 0; i &lt; n; i++) { if (nums[i] != i) { return i; } } return n; }} 方法二：哈希表 1234567891011121314151617class Solution { public int missingNumber(int[] nums) { Set&lt;Integer&gt; set = new HashSet&lt;Integer&gt;(); int n = nums.length; for (int i = 0; i &lt; n; i++) { set.add(nums[i]); } int missing = -1; for (int i = 0; i &lt;= n; i++) { if (!set.contains(i)) { missing = i; break; } } return missing; }} 方法三：位运算 12345678910111213class Solution { public int missingNumber(int[] nums) { int xor = 0; int n = nums.length; for (int i = 0; i &lt; n; i++) { xor ^= nums[i]; } for (int i = 0; i &lt;= n; i++) { xor ^= i; } return xor; }} 方法四：数学计算 1234567891011class Solution { public int missingNumber(int[] nums) { int n = nums.length; int total = n * (n + 1) / 2; int arrSum = 0; for (int i = 0; i &lt; n; i++) { arrSum += nums[i]; } return total - arrSum; }} Question51:统计一致字符串的数目题目描述： 给你一个由不同字符组成的字符串 allowed 和一个字符串数组 words 。如果一个字符串的每一个字符都在 allowed 中，就称这个字符串是 一致字符串 。 请你返回 words 数组中 一致字符串的数目。 举例子： 题解： 方法一： 个人做法： 对allowed字符串进行遍历，取出每一个字符放到一个Set集合之中 然后对word进行遍历，只要有一个字符不在allowed之中，就返回false 否则，执行count++ 1234567891011121314151617181920212223class Solution { public int countConsistentStrings(String allowed, String[] words) { //先将allowed中的每一个字符都取出放入一个set集合之中 HashSet&lt;Character&gt; set = new HashSet&lt;&gt;(); for (int i = 0; i &lt; allowed.length(); i++) { set.add(allowed.charAt(i)); } int count = 0; for (int i = 0; i &lt; words.length; i++) { boolean flag = true; for (int j = 0; j &lt; words[i].length(); j++) { if (!set.contains(words[i].charAt(j))){ flag = false; break; } } if (flag) { count++; } } return count; } Question52:第一个错误版本题目描述： 你是产品经理，目前正在带领一个团队开发新的产品。不幸的是，你的产品的最新版本没有通过质量检测。由于每个版本都是基于之前的版本开发的，所以错误的版本之后的所有版本都是错的。 假设你有 n 个版本 [1, 2, …, n]，你想找出导致之后所有版本出错的第一个错误的版本。 你可以通过调用 bool isBadVersion(version) 接口来判断版本号 version 是否在单元测试中出错。实现一个函数来查找第一个错误的版本。你应该尽量减少对调用 API 的次数。 题解： 题目思路很简单，就是利用二分查找法就可以了，不断循环为right赋值即可 注意：二分法要采用left + (right-left)/2的方式，不然就超界限了 123456789101112131415161718192021/* The isBadVersion API is defined in the parent class VersionControl. boolean isBadVersion(int version); */public class Solution extends VersionControl { public int firstBadVersion(int n) { //简单的二分查找算法 int left = 1; int right = n; int res = 0; while(left &lt;= right) { int mid = left + (right - left) / 2; if(isBadVersion(mid)) { res = mid; right = mid - 1; }else{ left = mid + 1; } } return res; }} Question53:移动零题目描述： 给定一个数组 nums，编写一个函数将所有 0 移动到数组的末尾，同时保持非零元素的相对顺序。 请注意 ，必须在不复制数组的情况下原地对数组进行操作。 题解： 方法一：遍历 个人思路很简单 首先先遍历数组，在遇到0的时候停下来 找0后面的第一个不是0的数据 将这两个数据做交换即可 123456789101112131415161718class Solution { public void moveZeroes(int[] nums) { for (int i = 0; i &lt; nums.length; i++) { if (nums[i] == 0) { for (int j = i + 1; j &lt; nums.length; j++) { if (nums[j] != 0) { nums[i] = nums[j]; nums[j] = 0; break; } } } if (nums[i] == 0) { break; } } }} 方法二：二次遍历 比刚刚的算法要好的 12345678910111213141516171819class Solution { public void moveZeroes(int[] nums) { if(nums==null) { return; } //第一次遍历的时候，j指针记录非0的个数，只要是非0的统统都赋给nums[j] int j = 0; for(int i=0;i&lt;nums.length;++i) { if(nums[i]!=0) { nums[j++] = nums[i]; } } //非0元素统计完了，剩下的都是0了 //所以第二次遍历把末尾的元素都赋为0即可 for(int i=j;i&lt;nums.length;++i) { nums[i] = 0; } }} Question54:单词规律题目描述： 给定一种规律 pattern 和一个字符串 s ，判断 s 是否遵循相同的规律。 这里的 遵循 指完全匹配，例如， pattern 里的每个字母和字符串 s 中的每个非空单词之间存在着双向连接的对应规律。 举例： 题解： 方法一： 个人解法： 首先将整个字符串分割成一个一个的单词 创建一个hashmap，里面存储character-string键值对 有两种情况会出现false 一是不含key，但是含有value；一种是不匹配 1234567891011121314151617181920212223class Solution { public boolean wordPattern(String pattern, String s) { //个人思路是利用HashMap来进行判断 String[] strings = s.split(&quot; &quot;); if (pattern.length() != strings.length) { return false; } HashMap&lt;Character, String&gt; map = new HashMap&lt;&gt;(); for (int i = 0; i &lt; pattern.length(); i++) { if (!map.containsKey(pattern.charAt(i))) { if (map.containsValue(strings[i])) { return false; } } else if(map.containsKey(pattern.charAt(i))) { if (!map.get(pattern.charAt(i)).equals(strings[i])) { return false; } } map.put(pattern.charAt(i),strings[i]); } return true; }} 方法二：双表 思路是创建两个hashmap来判断对应关系 降低了时间复杂度，运行性能更好 1234567891011121314151617181920212223242526272829class Solution { public boolean wordPattern(String pattern, String str) { Map&lt;String, Character&gt; str2ch = new HashMap&lt;String, Character&gt;(); Map&lt;Character, String&gt; ch2str = new HashMap&lt;Character, String&gt;(); int m = str.length(); int i = 0; for (int p = 0; p &lt; pattern.length(); ++p) { char ch = pattern.charAt(p); if (i &gt;= m) { return false; } int j = i; while (j &lt; m &amp;&amp; str.charAt(j) != ' ') { j++; } String tmp = str.substring(i, j); if (str2ch.containsKey(tmp) &amp;&amp; str2ch.get(tmp) != ch) { return false; } if (ch2str.containsKey(ch) &amp;&amp; !tmp.equals(ch2str.get(ch))) { return false; } str2ch.put(tmp, ch); ch2str.put(ch, tmp); i = j + 1; } return i &gt;= m; }} Question55:Nim游戏题目描述： 题解： 分析：这个题目涉及到数学问题，如果场上只有四个的话，那么你拿多少个对方都会赢；如果大于四个的话，你就可以拿走n个，使得场上始终是4的倍数，这样的话你就总是会赢。 12345class Solution { public boolean canWinNim(int n) { return n % 4 != 0; }} Question56:区域和检索–数组不可变题目描述： 给定一个整数数组 nums，处理以下类型的多个查询: 计算索引 left 和 right （包含 left 和 right）之间的 nums 元素的 和 ，其中 left &lt;= right实现 NumArray 类： NumArray(int[] nums) 使用数组 nums 初始化对象 int sumRange(int i, int j) 返回数组 nums 中索引 left 和 right 之间的元素的 总和 ，包含 left 和 right 两点（也就是 nums[left] + nums[left + 1] + … + nums[right] ) 题解： 方法一：前缀法 避免了每一次都要循环计算的笨蛋方法 123456789101112131415161718192021222324252627282930class NumArray { private int[] sums; public NumArray(int[] nums) { sums = new int[nums.length]; if(nums.length == 0) { return; } sums[0] = nums[0]; for(int i = 1; i &lt; nums.length; i++) { sums[i] = sums[i-1] + nums[i]; } } public int sumRange(int left, int right) { if(left == 0) { return sums[right]; }else { return sums[right] - sums[left-1]; } }}/** * Your NumArray object will be instantiated and called as such: * NumArray obj = new NumArray(nums); * int param_1 = obj.sumRange(left,right); */ Question57:判断数字是否为3的幂次题目描述： 给定一个整数，写一个函数来判断它是否是 3 的幂次方。如果是，返回 true ；否则，返回 false 。 题解： 方法一： 整体思路就是最简单的判断，一直取模，结果为0的话就一直除以3 12345678class Solution { public boolean isPowerOfThree(int n) { while (n != 0 &amp;&amp; n % 3 == 0) { n /= 3; } return n == 1; }} 方法二： 奇技淫巧：用整数范围内的最大整数对这个数取模，如果结果为0，就代表这个数为3的幂次。 12345class Solution { public boolean isPowerOfThree(int n) { return n &gt; 0 &amp;&amp; 1162261467 % n == 0; }} Question58:比特位计数题目描述： 给你一个整数 n ，对于 0 &lt;= i &lt;= n 中的每个 i ，计算其二进制表示中 1 的个数 ，返回一个长度为 n + 1 的数组 ans 作为答案。 题解： 方法一： 直接计算其中的每一个数字的1的位数，然后进行返回 123456789101112131415161718192021class Solution { private int[] nums; public int[] countBits(int n) { nums = new int[n+1]; for (int i = 0; i &lt;= n; i++) { nums[i] = countOnes(i); } return nums; } public int countOnes(int x) { int count = 0; while (x &gt; 0) { x &amp;= x-1; count++; } return count; }} 方法二：最高有效位 举个例子就是，如果当前要判断的数字是7，7的二进制为111，他比(7-4)=3的二进制11只多了一个1，所以3的1的个数+1就是7的二进制中的1的个数。 12345678910111213class Solution { public int[] countBits(int n) { int[] bits = new int[n + 1]; int highBit = 0; for (int i = 1; i &lt;= n; i++) { if ((i &amp; (i - 1)) == 0) { highBit = i; } bits[i] = bits[i - highBit] + 1; } return bits; }} 方法三：最低有效位 123456789class Solution { public int[] countBits(int n) { int[] bits = new int[n + 1]; for (int i = 1; i &lt;= n; i++) { bits[i] = bits[i &gt;&gt; 1] + (i &amp; 1); } return bits; }} 方法四：最低设置位 123456789class Solution { public int[] countBits(int n) { int[] bits = new int[n + 1]; for (int i = 1; i &lt;= n; i++) { bits[i] = bits[i &amp; (i - 1)] + 1; } return bits; }} Question59:判断数字是否为4的幂次题目描述： 判断一个数字是不是4的幂次。 题解： 方法一：迭代法 1234567891011121314class Solution { public boolean isPowerOfFour(int n) { while(n&gt;1) { if(n % 4 != 0) { return false; } n /= 4; } if(n == 1) { return true; } return false; }} 方法二：数学法 一个数如果是4的幂次，那么n%3的值为1；并且一定是2的幂次 如果一个数是2的幂次而不是4的幂次，那么n%3的值为2，因此根据上述的两个条件就可以判断这个数是否为4的幂次 123456class Solution {public: bool isPowerOfFour(int n) { return n &gt; 0 &amp;&amp; (n &amp; (n - 1)) == 0 &amp;&amp; n % 3 == 1; }}; Question60:反转字符串题目描述： 编写一个函数，其作用是将输入的字符串反转过来。输入字符串以字符数组 s 的形式给出。 不要给另外的数组分配额外的空间，你必须原地修改输入数组、使用 O(1) 的额外空间解决这一问题。 举例： 题解： 方法一：单指针 个人做法 123456789class Solution { public void reverseString(char[] s) { int n = s.length; for(int i = 0; i &lt; n/2; i++) { char temp = s[i]; s[i] = s[n-1-i]; s[n-1-i] = temp; } } 方法二：双指针 12345678910class Solution { public void reverseString(char[] s) { int n = s.length; for (int left = 0, right = n - 1; left &lt; right; ++left, --right) { char tmp = s[left]; s[left] = s[right]; s[right] = tmp; } }} 没啥可说的，很简单的题目 Question61:判断字符串的两半是否相似题目描述： 给你一个偶数长度的字符串 s 。将其拆分成长度相同的两半，前一半为 a ，后一半为 b 。 两个字符串 相似 的前提是它们都含有相同数目的元音（’a’，’e’，’i’，’o’，’u’，’A’，’E’，’I’，’O’，’U’）。注意，s 可能同时含有大写和小写字母。 如果 a 和 b 相似，返回 true ；否则，返回 false 。 题解： 方法一： 123456789101112131415161718192021222324252627282930313233343536373839class Solution { public boolean halvesAreAlike(String s) { int left = 0; int right = s.length() - 1; int count = 0; while(left &lt; right) { if(s.charAt(left) == 'a' || s.charAt(left) == 'e' || s.charAt(left) == 'i' || s.charAt(left) == 'o' || s.charAt(left) == 'u' || s.charAt(left) == 'A' || s.charAt(left) == 'E' || s.charAt(left) == 'I' || s.charAt(left) == 'O' || s.charAt(left) == 'U' ){ count++; } if(s.charAt(right) == 'a' || s.charAt(right) == 'e' || s.charAt(right) == 'i' || s.charAt(right) == 'o' || s.charAt(right) == 'u' || s.charAt(right) == 'A' || s.charAt(right) == 'E' || s.charAt(right) == 'I' || s.charAt(right) == 'O' || s.charAt(right) == 'U' ){ count--; } left++; right--; } if(count == 0) { return true; } return false; }} 这样写代码的可读性容易，但是运行性能也很差 方法二：官方解答 12345678910111213141516171819class Solution { public boolean halvesAreAlike(String s) { String a = s.substring(0, s.length() / 2); String b = s.substring(s.length() / 2); String h = &quot;aeiouAEIOU&quot;; int sum1 = 0, sum2 = 0; for (int i = 0; i &lt; a.length(); i++) { if (h.indexOf(a.charAt(i)) &gt;= 0) { sum1++; } } for (int i = 0; i &lt; b.length(); i++) { if (h.indexOf(b.charAt(i)) &gt;= 0) { sum2++; } } return sum1 == sum2; }} 代码易理解并且运行性能好于第一种方法 方法三： 12345678910111213141516171819202122class Solution { public boolean halvesAreAlike(String s) { int left = 0; int right = s.length() - 1; int count = 0; String h = &quot;aeiouAEIOU&quot;; while(left &lt; right) { if(h.indexOf(s.charAt(left)) &gt;= 0){ count++; } if(h.indexOf(s.charAt(right)) &gt;= 0){ count--; } left++; right--; } if(count == 0) { return true; } return false; }} 借鉴官方答案之后修改的方法一，运行性能最优 Question62:反转字符串中的元音字母题目描述： 给你一个字符串 s ，仅反转字符串中的所有元音字母，并返回结果字符串。 元音字母包括 'a'、'e'、'i'、'o'、'u'，且可能以大小写两种形式出现。 题解： 方法一： 123456789101112131415161718192021222324252627class Solution { public String reverseVowels(String s) { int left = 0; int right = s.length() - 1; char temp; String h = &quot;aeiouAEIOU&quot;; char[] str = s.toCharArray(); while(left &lt; right) { if(h.indexOf(s.charAt(left)) &gt;= 0 &amp;&amp; h.indexOf(s.charAt(right)) &gt;= 0) { temp = str[left]; str[left] = str[right]; str[right] = temp; left++; right--; }else if(h.indexOf(s.charAt(left)) &gt;= 0) { right--; }else if(h.indexOf(s.charAt(right)) &gt;= 0) { left++; }else { left++; right--; } } return new String(str); }} Question63:求两个数组的交集题目描述： 给定两个数组 nums1 和 nums2 ，返回 它们的交集 。输出结果中的每个元素一定是 唯一 的。我们可以 不考虑输出结果的顺序 题解： 方法一： 12345678910111213141516171819202122232425262728293031class Solution { public int[] intersection(int[] nums1, int[] nums2) { Set&lt;Integer&gt; set1 = new HashSet&lt;Integer&gt;(); Set&lt;Integer&gt; set2 = new HashSet&lt;Integer&gt;(); for (int num : nums1) { set1.add(num); } for (int num : nums2) { set2.add(num); } return getIntersection(set1, set2); } public int[] getIntersection(Set&lt;Integer&gt; set1, Set&lt;Integer&gt; set2) { if (set1.size() &gt; set2.size()) { return getIntersection(set2, set1); } Set&lt;Integer&gt; intersectionSet = new HashSet&lt;Integer&gt;(); for (int num : set1) { if (set2.contains(num)) { intersectionSet.add(num); } } int[] intersection = new int[intersectionSet.size()]; int index = 0; for (int num : intersectionSet) { intersection[index++] = num; } return intersection; }} 性能一般 方法二： 对数组进行排序之后再进行判断 1234567891011121314151617181920212223242526class Solution { public int[] intersection(int[] nums1, int[] nums2) { Arrays.sort(nums1); Arrays.sort(nums2); int length1 = nums1.length, length2 = nums2.length; int[] intersection = new int[length1 + length2]; int index = 0, index1 = 0, index2 = 0; while (index1 &lt; length1 &amp;&amp; index2 &lt; length2) { int num1 = nums1[index1], num2 = nums2[index2]; if (num1 == num2) { // 保证加入元素的唯一性 if (index == 0 || num1 != intersection[index - 1]) { intersection[index++] = num1; } index1++; index2++; } else if (num1 &lt; num2) { index1++; } else { index2++; } } return Arrays.copyOfRange(intersection, 0, index); }} Question64:将有序数组转化为二叉平衡树题目描述： 给你一个整数数组 nums ，其中元素已经按 升序 排列，请你将其转换为一棵 高度平衡 二叉搜索树。 高度平衡二叉树是一棵满足每个节点的左右两个子树的高度差的绝对值不超过 1 的二叉树。 题解： 方法一： 12345678910111213141516class Solution { public TreeNode sortedArrayToBST(int[] nums) { return nums == null ? null : buildTree(nums,0,nums.length-1); } private TreeNode buildTree(int[] nums, int left, int right) { if(left &gt; right) { return null; } int mid = left + (right - left) / 2; TreeNode root = new TreeNode(nums[mid]); root.left = buildTree(nums,left,mid-1); root.right = buildTree(nums,mid+1,right); return root; }} Question65:判断二叉树是否为平衡二叉树题目描述： 给定一个二叉树，判断它是否是高度平衡的二叉树。 本题中，高度平衡二叉树定义为：一个二叉树每个节点 的左右两个子树的高度差的绝对值不超过 1 题解： 方法一：由上到下递归判断 思路：就是从根节点开始向下递归判断当前节点的左子树和右子树是否满足平衡树的条件 1234567891011121314151617class Solution { public boolean isBalanced(TreeNode root) { if (root == null) { return true; } else { return Math.abs(height(root.left) - height(root.right)) &lt;= 1 &amp;&amp; isBalanced(root.left) &amp;&amp; isBalanced(root.right); } } public int height(TreeNode root) { if (root == null) { return 0; } else { return Math.max(height(root.left), height(root.right)) + 1; } }} 方法二：从下到上的判断 123456789101112131415161718class Solution { public boolean isBalanced(TreeNode root) { return height(root) &gt;= 0; } public int height(TreeNode root) { if (root == null) { return 0; } int leftHeight = height(root.left); int rightHeight = height(root.right); if (leftHeight == -1 || rightHeight == -1 || Math.abs(leftHeight - rightHeight) &gt; 1) { return -1; } else { return Math.max(leftHeight, rightHeight) + 1; } }} 如果子树为不平衡的，那么整个树也一定是不平衡的 空间复杂度不变的情况下，将时间复杂度减少了。从O(n*n)–&gt;O(n) Question66:求二叉树的最小深度题目描述： 求一个二叉树的最小深度 题解： 方法一： 和之前求最大深度一样（Q20），只不过把max改成min即可 123456789101112131415161718 /** 执行用时：12 ms, 在所有 Java 提交中击败了10.41%的用户内存消耗：61.5 MB, 在所有 Java 提交中击败了17.58%的用户 */class Solution { public int minDepth(TreeNode root) { if(root == null) { return 0; } if(root.left != null &amp;&amp; root.right == null) { return 1 + minDepth(root.left); } if(root.left == null &amp;&amp; root.right != null) { return 1 + minDepth(root.right); } return 1+Math.min(minDepth(root.left),minDepth(root.right)); }} 方法二：深度优先算法 12345678910111213141516171819202122232425/**执行用时：6 ms, 在所有 Java 提交中击败了67.72%的用户内存消耗：61 MB, 在所有 Java 提交中击败了56.08%的用户 */ class Solution { public int minDepth(TreeNode root) { if (root == null) { return 0; } if (root.left == null &amp;&amp; root.right == null) { return 1; } int min_depth = Integer.MAX_VALUE; if (root.left != null) { min_depth = Math.min(minDepth(root.left), min_depth); } if (root.right != null) { min_depth = Math.min(minDepth(root.right), min_depth); } return min_depth + 1; }} 方法三：广度优先算法 思想就是，我们在找到一个叶子结点的时候，就把这个节点的深度返回，这样就保证了最先搜索到的叶子结点的深度最小。 12345678910111213141516171819202122232425262728293031323334353637383940/** 执行用时：1 ms, 在所有 Java 提交中击败了92.98%的用户内存消耗：60.3 MB, 在所有 Java 提交中击败了89.46%的用户*/class Solution { class QueueNode { TreeNode node; int depth; public QueueNode(TreeNode node, int depth) { this.node = node; this.depth = depth; } } public int minDepth(TreeNode root) { if (root == null) { return 0; } Queue&lt;QueueNode&gt; queue = new LinkedList&lt;QueueNode&gt;(); queue.offer(new QueueNode(root, 1)); while (!queue.isEmpty()) { QueueNode nodeDepth = queue.poll(); TreeNode node = nodeDepth.node; int depth = nodeDepth.depth; if (node.left == null &amp;&amp; node.right == null) { return depth; } if (node.left != null) { queue.offer(new QueueNode(node.left, depth + 1)); } if (node.right != null) { queue.offer(new QueueNode(node.right, depth + 1)); } } return 0; }} Question67:二叉树的所有路径题目描述： 题解： 方法一：深度优先算法 123456789101112131415161718192021222324252627/**执行用时：8 ms, 在所有 Java 提交中击败了32.05%的用户内存消耗：41.9 MB, 在所有 Java 提交中击败了23.43%的用户*/public List&lt;String&gt; binaryTreePaths(TreeNode root) { List&lt;String&gt; res = new ArrayList&lt;&gt;(); if (root == null) { return res; } addList(root,&quot;&quot;,res); return res; } public void addList(TreeNode root, String str, List&lt;String&gt; list) { if (root == null) { return; } str += root.val; //遍历到叶子节点的时候 if (root.left == null &amp;&amp; root.right == null) { list.add(str); } else { str += &quot;-&gt;&quot;; addList(root.left, str , list); addList(root.right, str , list); } } 方法二：广度优先算法 123456789101112131415161718192021222324252627282930313233class Solution { public List&lt;String&gt; binaryTreePaths(TreeNode root) { List&lt;String&gt; paths = new ArrayList&lt;String&gt;(); if (root == null) { return paths; } Queue&lt;TreeNode&gt; nodeQueue = new LinkedList&lt;TreeNode&gt;(); Queue&lt;String&gt; pathQueue = new LinkedList&lt;String&gt;(); nodeQueue.offer(root); pathQueue.offer(Integer.toString(root.val)); while (!nodeQueue.isEmpty()) { TreeNode node = nodeQueue.poll(); String path = pathQueue.poll(); if (node.left == null &amp;&amp; node.right == null) { paths.add(path); } else { if (node.left != null) { nodeQueue.offer(node.left); pathQueue.offer(new StringBuffer(path).append(&quot;-&gt;&quot;).append(node.left.val).toString()); } if (node.right != null) { nodeQueue.offer(node.right); pathQueue.offer(new StringBuffer(path).append(&quot;-&gt;&quot;).append(node.right.val).toString()); } } } return paths; }} Question68:两个数组的交集题目描述： 给你两个整数数组 nums1 和 nums2 ，请你以数组形式返回两数组的交集。返回结果中每个元素出现的次数，应与元素在两个数组中都出现的次数一致（如果出现次数不一致，则考虑取较小值）。可以不考虑输出结果的顺序。 题解： 一共有三种方法放在一起介绍了 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687/** * 使用集合来实现 * 执行用时：10 ms, 在所有 Java 提交中击败了5.09%的用户 * 内存消耗：41.3 MB, 在所有 Java 提交中击败了85.25%的用户 */ public int[] intersect_1(int[] nums1, int[] nums2) { List&lt;Integer&gt; list1 = new ArrayList&lt;&gt;(); for (int num1 : nums1) { list1.add(num1); } List&lt;Integer&gt; list2 = new ArrayList&lt;&gt;(); for (int num2 : nums2) { if (list1.contains(num2)) { list2.add(num2); list1.remove(Integer.valueOf(num2)); } } int[] res = new int[list2.size()]; int i = 0; for (int value : list2) { res[i++] = value; } return res; } /** * 使用map实现 * 执行用时：3 ms, 在所有 Java 提交中击败了40.89%的用户 * 内存消耗：41.7 MB, 在所有 Java 提交中击败了32.18%的用户 */ public int[] intersect_2(int[] nums1, int[] nums2) { Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); //将nums1的元素放入到map之中 for (int value : nums1) { if (map.containsKey(value)) { map.put(value, map.get(value)+1); } else { map.put(value,1); } } //逐个取出nums2之中的元素，来判断是否位于map中，如果位于map之中， // 那么就将他加到list之中，并且要将这个值的次数减一 List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); for (int value : nums2) { if (map.containsKey(value)) { list.add(value); map.put(value,map.get(value)-1); } } int[] res = new int[list.size()]; int i = 0; for (int value : list) { res[i++] = value; } return res; } /** * 使用预排序的方法 * 执行用时：2 ms, 在所有 Java 提交中击败了95.48%的用户 * 内存消耗：41.5 MB, 在所有 Java 提交中击败了55.10%的用户 */ public int[] intersect_3(int[] nums1, int[] nums2) { //首先对两个数组进行排序 Arrays.sort(nums1); Arrays.sort(nums2); List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); for (int i = 0, j = 0;i &lt; nums1.length &amp;&amp; j &lt; nums2.length;) { if (nums1[i] &gt; nums2[j]) { j++; } else if (nums1[i] &lt; nums2[j]) { i++; } else { list.add(nums1[i]); i++; j++; } } int[] res = new int[list.size()]; int i = 0; for (int value : list) { res[i++] = value; } return res; } Question69:判断一个数字是否为完全平方数题目描述： 给定一个 正整数 num ，编写一个函数，如果 num 是一个完全平方数，则返回 true ，否则返回 false 。 进阶：不要 使用任何内置的库函数，如 sqrt 。 题解： 方法一： 利用二分法 12345678910111213141516171819202122232425class Solution { public boolean isPerfectSquare(int num) { if(num == 1) { return true; } int low = 0; int high = num; while (low &lt;= high) { int mid = low + (high - low) / 2; //num == mid * mid 越界了 int t = num / mid; if (t == mid) { if(num % mid == 0) { return true; } low = mid + 1; } else if (t &gt; mid) { low = mid + 1; } else { high = mid - 1; } } return false; }} Question70:猜数字的大小题目描述： 猜数字游戏的规则如下： 每轮游戏，我都会从 1 到 n 随机选择一个数字。 请你猜选出的是哪个数字。如果你猜错了，我会告诉你，你猜测的数字比我选出的数字是大了还是小了。你可以通过调用一个预先定义好的接口 int guess(int num) 来获取猜测结果，返回值一共有 3 种可能的情况（-1，1 或 0）： -1：我选出的数字比你猜的数字小 pick &lt; num 1：我选出的数字比你猜的数字大 pick &gt; num 0：我选出的数字和你猜的数字一样。恭喜！你猜对了！pick == num 返回我选出的数字。 题解： 方法一：二分法 12345678910111213141516171819202122232425262728293031/** * Forward declaration of guess API. * @param num your guess * @return -1 if num is higher than the picked number * 1 if num is lower than the picked number * otherwise return 0 * int guess(int num); *//**执行用时：0 ms, 在所有 Java 提交中击败了100.00%的用户内存消耗：37.9 MB, 在所有 Java 提交中击败了97.94%的用户 */public class Solution extends GuessGame { public int guessNumber(int n) { int left = 0; int right = n; while (left &lt;= right) { int mid = left + (right - left) / 2; int guess = guess(mid); if (guess == 0){ return mid; } else if (guess == 1) { left = mid + 1; } else { right = mid - 1; } } return 0; }} Question71:卡车上的最大单元数题目描述： 请你将一些箱子装在 一辆卡车 上。给你一个二维数组 boxTypes ，其中 boxTypes[i] = [numberOfBoxes, numberOfUnitsPerBox] ： numberOfBoxes 是类型 i 的箱子的数量。 numberOfUnitsPerBox 是类型 i 每个箱子可以装载的单元数量。 整数 truckSize 表示卡车上可以装载 箱子 的 最大数量 。只要箱子数量不超过 truckSize ，你就可以选择任意箱子装到卡车上。 返回卡车可以装载 单元 的 最大 总数。 题解： 分析： 先理解题目的意思：就是说要往卡车上装箱子，卡车可以容纳的箱子数量是一定的，但是每个箱子可以装的东西数目不一样，如何可以往卡车中装入最多的东西 思路就是把能装最多东西的箱子放上去，以此类推。 方法一： 12345678910111213141516171819202122232425262728293031323334/**执行用时：22 ms, 在所有 Java 提交中击败了15.88%的用户内存消耗：41.6 MB, 在所有 Java 提交中击败了81.10%的用户*/class Solution { public int maximumUnits(int[][] boxTypes, int truckSize) { int res = 0; while (truckSize &gt; 0) { int maxBox = 0;//寻找最大储货量 int numBox = 0;//存放出货量最大的箱子的数目 int index = 0; for (int i = 0; i &lt; boxTypes.length; i++) { if (boxTypes[i][1] &gt; maxBox) { index = i; numBox = boxTypes[i][0]; maxBox = boxTypes[i][1]; } } if (maxBox == 0) { break; } if (truckSize &gt; numBox) { res += (numBox * maxBox); truckSize -= numBox; boxTypes[index][1] = 0; } else { res += truckSize * maxBox; break; } } return res; }} 贪心算法： 123456789101112131415161718class Solution { public int maximumUnits(int[][] boxTypes, int truckSize) { Arrays.sort(boxTypes, (a, b) -&gt; b[1] - a[1]); int res = 0; for (int[] boxType : boxTypes) { int numberOfBoxes = boxType[0]; int numberOfUnitsPerBox = boxType[1]; if (numberOfBoxes &lt; truckSize) { res += numberOfBoxes * numberOfUnitsPerBox; truckSize -= numberOfBoxes; } else { res += truckSize * numberOfUnitsPerBox; break; } } return res; }} Question72:找到最高海拔题目描述： 有一个自行车手打算进行一场公路骑行，这条路线总共由 n + 1 个不同海拔的点组成。自行车手从海拔为 0 的点 0 开始骑行。 给你一个长度为 n 的整数数组 gain ，其中 gain[i] 是点 i 和点 i + 1 的净海拔高度差（0 &lt;= i &lt; n）。请你返回最高点的海拔 。 就是说在骑行过程中，自行车手有可能在上坡也有可能在下坡，找到他途径的最高的地方的海拔。 题解： 方法一： 创建一个数组，将所有途经的海拔都放进去 对数组进行排序，取出最大的数字 123456789public int largestAltitude(int[] gain) { int[] res = new int[gain.length + 1]; res[0] = 0; for(int i = 1; i &lt;= gain.length; i++) { res[i] = res[i-1] + gain[i-1]; } Arrays.sort(res); return res[gain.length]; } 复杂度过高，不予考虑 方法二： 对方法一的优化，不再创建数组来求 12345678910111213141516class Solution { /** 执行用时：0 ms, 在所有 Java 提交中击败了100.00%的用户 内存消耗：39.2 MB, 在所有 Java 提交中击败了45.39%的用户 */ public int largestAltitude(int[] gain) { int ans = 0, h = 0; for(int i = 0; i &lt; gain.length; i++) { h += gain[i]; ans = Math.max(ans,h); } return ans; }} Question73:找到所有数组中消失的数字题目描述： 给你一个含 n 个整数的数组 nums ，其中 nums[i] 在区间 [1, n] 内。请你找出所有在 [1, n] 范围内但没有出现在 nums 中的数字，并以数组的形式返回结果。 题解： 个人思路当然是暴力法进行求解，不出所料会超时 官方解答： 首先，先取出现在的这个数字，减去1得到这个数字对应的下标 对这个下标对应的数字进行加n的操作 然后再遍历这个数组，其中数字小于n的就代表没有被操作过 这个下标+1即为未出现的数字 1234567891011121314151617181920212223/*执行用时：3 ms, 在所有 Java 提交中击败了99.63%的用户内存消耗：49.3 MB, 在所有 Java 提交中击败了66.35%的用户*/class Solution { public List&lt;Integer&gt; findDisappearedNumbers(int[] nums) { List&lt;Integer&gt; res = new ArrayList&lt;&gt;(); int n = nums.length; //首先，先将出现的数字所对应的下标的数字加上n //为了防止当前数字已经实现了+n操作，下标溢出，因此进行取模操作 for(int num : nums) { int index = (num - 1) % n; nums[index] += n; } //将所有小于n的数字的下标+1加入到结果集之中即可 for(int i = 0; i &lt; n; i++) { if(nums[i] &lt;= n) { res.add(i+1); } } return res; }} Question74:汉明距离题目描述： 两个整数之间的 汉明距离 指的是这两个数字对应二进制位不同的位置的数目。 给你两个整数 x 和 y，计算并返回它们之间的汉明距离。 题解： 方法一： 12345678910111213141516171819202122class Solution { /** 执行用时：0 ms, 在所有 Java 提交中击败了100.00%的用户 内存消耗：38.9 MB, 在所有 Java 提交中击败了5.15%的用户 */ public int hammingDistance(int x, int y) { //个人思路：可以先求两个数字&amp;之后的1的个数， //再求两个数字|之后的1的个数，用后者减去前者即可 int res1 = x &amp; y; int res2 = x | y; int count1 = 0; int count2 = 0; while(res1 != 0) { res1 &amp;= res1-1; count1++; } while(res2 != 0) { res2 &amp;= res2-1; count2++; } return count2 - count1; }} 方法二：内置函数法 12345class Solution { public int hammingDistance(int x, int y) { return Integer.bitCount(x ^ y); }} 方法三：改进的方法一 123456789101112131415/**执行用时：0 ms, 在所有 Java 提交中击败了100.00%的用户内存消耗：38.4 MB, 在所有 Java 提交中击败了49.04%的用户*/class Solution { public int hammingDistance(int x, int y) { int s = x ^ y, res = 0; while(s!=0) { s &amp;= s-1; res++; } return res; }} Charpter2-MidiumQuestion1:两数相加题目描述： 给你两个 非空 的链表，表示两个非负的整数。它们每位数字都是按照 逆序 的方式存储的，并且每个节点只能存储 一位 数字。 请你将两个数相加，并以相同形式返回一个表示和的链表。 你可以假设除了数字 0 之外，这两个数都不会以 0 开头。 举例： 题解： 本题中等题目里面较容易地吧，就将两数相加来判断是否产生进位，产生进位的话就把进位的数字也加到下一次相加之中，最后判断是否产生进位，从而再创建一个新节点。最后返回头节点即可。 思路： 首先先判断当前节点是否为空，空则赋值为0 将当前两个链表对应的节点以及上一个链表节点的进位相加 如果最后一个节点也有进位产生，则再创建一个值为1的节点 123456789101112131415161718192021222324252627282930313233343536373839/** * Definition for singly-linked list. * public class ListNode { * int val; * ListNode next; * ListNode() {} * ListNode(int val) { this.val = val; } * ListNode(int val, ListNode next) { this.val = val; this.next = next; } * } */class Solution { public ListNode addTwoNumbers(ListNode l1, ListNode l2) { ListNode head = null; ListNode tail = null; int carry = 0; while (l1 != null || l2 != null) { int num1 = l1 != null ? l1.val : 0; int num2 = l2 != null ? l2.val : 0; int sum = num1 + num2 + carry; if (head == null) { head = tail = new ListNode(sum % 10); } else { tail.next = new ListNode(sum % 10); tail = tail.next; } carry = sum / 10; if (l1 != null) { l1 = l1.next; } if (l2 != null) { l2 = l2.next; } } if (carry == 1) { tail.next = new ListNode(1); } return head; }} 分析：这种题一定不要转换为整数，然后相加之后在转换为链表。因为这样的题目一般long型都不够用的。 Question2:找无重复字母的最长子串题目描述： 给定一个字符串 s ，请你找出其中不含有重复字符的 最长子串 的长度。 题解： 方法一： 个人认为最简单的就是，采用双指针，不断更新长度即可。 先用一个set集合来存储已经出现的字符，并且大小作为最后的返回。 左指针不动，将右指针向右移，遇到重复的数字停下来，然后比较得到子串长度和现有的最长的做对比。 将左指针右移，并且将最左边的字符从set集合中取出。 12345678910111213141516171819class Solution { public int lengthOfLongestSubstring(String s) { Set&lt;Character&gt; set = new HashSet&lt;&gt;(); int start = 0; int end = 0; int max = 0; while (end&lt;s.length()){ if (!set.contains(s.charAt(end))) { set.add(s.charAt(end)); end++; } else{ set.remove(s.charAt(start)); start++; } max = Math.max(set.size(),max); } return max; }} 方法二：（暂时还未理解） 1234567891011121314151617181920212223class Solution { public int lengthOfLongestSubstring(String s) { // 哈希集合，记录每个字符是否出现过 Set&lt;Character&gt; occ = new HashSet&lt;Character&gt;(); int n = s.length(); // 右指针，初始值为 -1，相当于我们在字符串的左边界的左侧，还没有开始移动 int rk = -1, ans = 0; for (int i = 0; i &lt; n; ++i) { if (i != 0) { // 左指针向右移动一格，移除一个字符 occ.remove(s.charAt(i - 1)); } while (rk + 1 &lt; n &amp;&amp; !occ.contains(s.charAt(rk + 1))) { // 不断地移动右指针 occ.add(s.charAt(rk + 1)); ++rk; } // 第 i 到 rk 个字符是一个极长的无重复字符子串 ans = Math.max(ans, rk - i + 1); } return ans; }} Question3:全局倒置与局部倒置题目描述： 给你一个长度为 n 的整数数组 nums，表示由范围 [0, n - 1] 内所有整数组成的一个排列。 全局倒置的数目等于满足下述条件不同下标对 (i, j) 的数目： 0 &lt;= i &lt; j &lt; n nums[i] &gt; nums[j] 局部倒置的数目等于满足下述条件的下标 i 的数目： 0 &lt;= i &lt; n - 1 nums[i] &gt; nums[i + 1] 当数组 nums 中全局倒置的数量等于局部倒置的数量时，返回 true；否则，返回 false 。 题解： 本题采用暴力解决的话会超出时间限制，哪怕只判断这个数组是否有非局部倒置 方法一： 1234567891011121314151617181920class Solution { /** 执行用时：1 ms, 在所有 Java 提交中击败了99.46%的用户 内存消耗：50.4 MB, 在所有 Java 提交中击败了79.89%的用户 */ public boolean isIdealPermutation(int[] nums) { int n = nums.length; int min = nums[n-1]; for (int i = n - 3; i &gt;= 0; i--) { if (nums[i] &gt; min) { return false; } min = Math.min(min,nums[i+1]); } return true; }} 方法二： 通过找规律可以发现，当前值要和下标相差小于等于1，不然一定会存在非局部倒置 12345678910class Solution { public boolean isIdealPermutation(int[] nums) { for (int i = 0; i &lt; nums.length; i++) { if (Math.abs(nums[i] - i) &gt; 1) { return false; } } return true; }} Question4:匹配子序列的单词数题目描述： 给定字符串 s 和字符串数组 words, 返回 words[i] 中是s的子序列的单词个数 。 字符串的 子序列 是从原始字符串中生成的新字符串，可以从中删去一些字符(可以是none)，而不改变其余字符的相对顺序。 例如， “ace” 是 “abcde” 的子序列，但是“aec”就不是“abcde”的子序列 题解： 方法一： 创建一个List数组，里面存储26个数组，分别表示字符串s中每个字母在字符串中的位置 利用二分法来寻找字母在字母在字符串中的位置，如果这个字母不存在，或者它的位置比上一个字母的位置下标小，那么就会去掉这个。 123456789101112131415161718192021222324252627282930313233343536373839404142434445/**执行用时：169 ms, 在所有 Java 提交中击败了20.79%的用户内存消耗：48.9 MB, 在所有 Java 提交中击败了45.95%的用户 */class Solution { public int numMatchingSubseq(String s, String[] words) { List&lt;Integer&gt;[] pos = new List[26]; for (int i = 0; i &lt; 26; ++i) { pos[i] = new ArrayList&lt;Integer&gt;(); } for (int i = 0; i &lt; s.length(); ++i) { pos[s.charAt(i) - 'a'].add(i); } int res = words.length; for (String w : words) { if (w.length() &gt; s.length()) { --res; continue; } int p = -1; for (int i = 0; i &lt; w.length(); ++i) { char c = w.charAt(i); if (pos[c - 'a'].isEmpty() || pos[c - 'a'].get(pos[c - 'a'].size() - 1) &lt;= p) { --res; break; } p = binarySearch(pos[c - 'a'], p); } } return res; } public int binarySearch(List&lt;Integer&gt; list, int target) { int left = 0, right = list.size() - 1; while (left &lt; right) { int mid = left + (right - left) / 2; if (list.get(mid) &gt; target) { right = mid; } else { left = mid + 1; } } return list.get(left); }} 方法二： ​ 在上述方法基础上进行优化，因为方法一中是每一个单词分别和字符串 s 进行匹配，这样对于每一次匹配都需要从头开始遍历字符串 s，这增加了额外的时间开销。所以我们考虑将字符串数组 words 中的全部字符串和字符串 s 同时进行匹配——同样对于每一个需要匹配的字符串我们用一个指针来指向它需要匹配的字符，那么在遍历字符串 s 的过程中，对于当前遍历到的字符如果有可以匹配的字符串，那么将对应的字符串指针往后移动一单位即可。那么当字符串 s 遍历结束时，字符串数组中全部字符串的匹配情况也就全部知道了。 123456789101112131415161718192021222324252627class Solution { public int numMatchingSubseq(String s, String[] words) { Queue&lt;int[]&gt;[] p = new Queue[26]; for (int i = 0; i &lt; 26; ++i) { p[i] = new ArrayDeque&lt;int[]&gt;(); } for (int i = 0; i &lt; words.length; ++i) { p[words[i].charAt(0) - 'a'].offer(new int[]{i, 0}); } int res = 0; for (int i = 0; i &lt; s.length(); ++i) { char c = s.charAt(i); int len = p[c - 'a'].size(); while (len &gt; 0) { int[] t = p[c - 'a'].poll(); if (t[1] == words[t[0]].length() - 1) { ++res; } else { ++t[1]; p[words[t[0]].charAt(t[1]) - 'a'].offer(t); } --len; } } return res; }} Question5:香槟塔题目描述： 我们把玻璃杯摆成金字塔的形状，其中 第一层 有 1 个玻璃杯， 第二层 有 2 个，依次类推到第 100 层，每个玻璃杯 (250ml) 将盛有香槟。 从顶层的第一个玻璃杯开始倾倒一些香槟，当顶层的杯子满了，任何溢出的香槟都会立刻等流量的流向左右两侧的玻璃杯。当左右两边的杯子也满了，就会等流量的流向它们左右两边的杯子，依次类推。（当最底层的玻璃杯满了，香槟会流到地板上） 例如，在倾倒一杯香槟后，最顶层的玻璃杯满了。倾倒了两杯香槟后，第二层的两个玻璃杯各自盛放一半的香槟。在倒三杯香槟后，第二层的香槟满了 - 此时总共有三个满的玻璃杯。在倒第四杯后，第三层中间的玻璃杯盛放了一半的香槟，他两边的玻璃杯各自盛放了四分之一的香槟，如下图所示。 题解： 错误解答： 自己的想法是，我把这一层倒满之后，剩下的所有的去倒入下一层，所以我只需要考虑每一层的各个杯子所占的比重就可以了 错误原因：不是说这一层全满之后才会流向下一层，中间的杯子肯定先满，然后流向下一层，所以不能计算权重来求解 12345678910111213141516171819202122232425262728class Solution { public double champagneTower(int poured, int query_row, int query_glass) { //首先，如果上面的香槟没有满的话是不会继续向下流的 if((query_row+1)*query_row/2 &gt;= poured) { return 0.0; } int res = poured - (query_row+1)*query_row/2; double ans = curWeight(query_row,query_glass) * res; if(ans &gt; 1) { return 1.0; } return ans; } //写一个方法返回当前杯子的权重 public double curWeight(int row, int col) { double[][] weight = new double[row+1][row+1]; for (int i = 0; i &lt;= row; i++) { weight[i][0] = weight[i][i] = Math.pow(0.5,i); } for (int i = 2; i &lt;= row; i++){ for (int j = 1; j &lt; row; j++) { weight[i][j] = (weight[i-1][j-1]+weight[i-1][j])/2; } } return weight[row][col]; }} 正确解答： 实时更新每一层 123456789101112131415class Solution { public double champagneTower(int poured, int query_row, int query_glass) { double count[] = new double[]{(double)poured}; for(int i = 1; i &lt;= query_row; i++) { double arr[] = new double[i+1]; arr[0] = Math.max(0,count[0]-1)/2; arr[i] = Math.max(0,count[i-1]-1)/2; for(int j = 1; j &lt; i; j++) { arr[j] = (Math.max(0,count[j-1]-1) + Math.max(0,count[j]-1))/2; } count = arr; } return Math.min(1,count[query_glass]); }} Question6:分汤题目描述： 有 A 和 B 两种类型的汤。一开始每种类型的汤各有 n 毫升。有四种分配操作： 提供 100ml 的汤A 和 0ml 的汤B 。 提供 75ml 的汤A 和 25ml 的汤B 。 提供 50ml 的汤A 和 50ml 的汤B 。 提供 25ml 的汤A 和 75ml 的汤B 。 当我们把汤分配给某人之后，汤就没有了。每个回合，我们将从四种概率同为 0.25 的操作中进行分配选择。如果汤的剩余量不足以完成某次操作，我们将尽可能分配。当两种类型的汤都分配完时，停止操作。 注意不存在先分配 100 ml 汤B 的操作。 需要返回的值： 汤A 先分配完的概率 + 汤A和汤B 同时分配完的概率 / 2。返回值在正确答案 10-5 的范围内将被认为是正确的。 题解： 个人没什么思路，感觉要用递归来做，其实这个问题不是一个递归问题 由于分配的汤都是25的倍数，因此首先先除以25然后来进行后续的判断 当n&gt;179*25的时候，基本上都是A先分完，此时，让结果等于1即可 方法一： 12345678910111213141516171819class Solution { public double soupServings(int n) { n = (int) Math.ceil((double) n / 25); if (n &gt;= 179) { return 1.0; } double[][] dp = new double[n + 1][n + 1]; dp[0][0] = 0.5; for (int i = 1; i &lt;= n; i++) { dp[0][i] = 1.0; } for (int i = 1; i &lt;= n; i++) { for (int j = 1; j &lt;= n; j++) { dp[i][j] = (dp[Math.max(0, i - 4)][j] + dp[Math.max(0, i - 3)][Math.max(0, j - 1)] + dp[Math.max(0, i - 2)][Math.max(0, j - 2)] + dp[Math.max(0, i - 1)][Math.max(0, j - 3)]) / 4.0; } } return dp[n][n]; }} 方法一的思想是动态规划，也就是自底向上，逐步进行求解 方法二： 由于方法一自底向上的方法，有着很多的资源浪费，因此，我们可以采取自顶向下的记忆化搜索方式来进行求解 123456789101112131415161718192021222324252627282930/**执行用时：0 ms, 在所有 Java 提交中击败了100.00%的用户内存消耗：38.4 MB, 在所有 Java 提交中击败了88.99%的用户*/class Solution { private double[][] memo; public double soupServings(int n) { n = (int) Math.ceil((double) n / 25); if (n &gt;= 179) { return 1.0; } memo = new double[n + 1][n + 1]; return dfs(n, n); } public double dfs(int a, int b) { if (a &lt;= 0 &amp;&amp; b &lt;= 0) { return 0.5; } else if (a &lt;= 0) { return 1; } else if (b &lt;= 0) { return 0; } if (memo[a][b] == 0) { memo[a][b] = 0.25 * (dfs(a - 4, b) + dfs(a - 3, b - 1) + dfs(a - 2, b - 2) + dfs(a - 1, b - 3)); } return memo[a][b]; }} Question7:最长回文子串题目描述： 给定一个字符串s，求字符串中的最长回文子串。 题解： 个人解法：（超时） 最简单的思路：遍历 123456789101112131415161718192021class Solution { public String longestPalindrome(String s) { int res = 0; String resStr = &quot;&quot;; for (int i = 0; i &lt; s.length(); i++) { for (int j = s.length(); j &gt;= i; j--) { String str1 = s.substring(i,j); StringBuilder sb1 = new StringBuilder(str1); StringBuilder sb2 = sb1.reverse(); if (str1.equals(String.valueOf(sb2))) { if (str1.length() &gt; res) { res = str1.length(); resStr = str1; } break; } } } return resStr; }} 超出时间限制啦！得想别的优化算法 方法一： 整体思路：动态规划 首先先判断长度小于等于2的字符串的回文子串情况 然后将长度从2开始递增，如果当前字符串首i尾j一致，那么它的情况就和i+1到j-1的子串的回文情况一致 最后记录最长字串和起始位置即可 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/**执行用时：115 ms, 在所有 Java 提交中击败了41.14%的用户内存消耗：44.5 MB, 在所有 Java 提交中击败了19.71%的用户 */public class Solution { public String longestPalindrome(String s) { int len = s.length(); if (len &lt; 2) { return s; } int maxLen = 1; int begin = 0; // dp[i][j] 表示 s[i..j] 是否是回文串 boolean[][] dp = new boolean[len][len]; // 初始化：所有长度为 1 的子串都是回文串 for (int i = 0; i &lt; len; i++) { dp[i][i] = true; } char[] charArray = s.toCharArray(); // 递推开始 // 先枚举子串长度 for (int L = 2; L &lt;= len; L++) { // 枚举左边界，左边界的上限设置可以宽松一些 for (int i = 0; i &lt; len; i++) { // 由 L 和 i 可以确定右边界，即 j - i + 1 = L 得 int j = L + i - 1; // 如果右边界越界，就可以退出当前循环 if (j &gt;= len) { break; } if (charArray[i] != charArray[j]) { dp[i][j] = false; } else { if (j - i &lt; 3) { dp[i][j] = true; } else { dp[i][j] = dp[i + 1][j - 1]; } } // 只要 dp[i][L] == true 成立，就表示子串 s[i..L] 是回文，此时记录回文长度和起始位置 if (dp[i][j] &amp;&amp; j - i + 1 &gt; maxLen) { maxLen = j - i + 1; begin = i; } } } return s.substring(begin, begin + maxLen); }} 方法二：中心扩散算法 基于方法一的优化，我们可以找一个最小字串，让他从中心向两边扩散 1234567891011121314151617181920212223242526272829303132/**执行用时：16 ms, 在所有 Java 提交中击败了86.20%的用户内存消耗：41.5 MB, 在所有 Java 提交中击败了68.28%的用户 */public class Solution { public String longestPalindrome(String s) { if(s.length() &lt; 2) { return s; } int start = 0, end = 0; for(int i = 0; i &lt; s.length(); i++) { //分别代表奇数子串和偶数字串 int len1 = maxLength(s, i, i); int len2 = maxLength(s, i, i+1); int len = Math.max(len1,len2); if(len &gt; end-start) { end = i+len/2; start = i-(len-1)/2; } } return s.substring(start,end+1); } public int maxLength(String s, int left, int right){ while(left &gt;=0 &amp;&amp; right &lt; s.length() &amp;&amp; s.charAt(left) == s.charAt(right)) { --left; ++right; } return right - left - 1; }} 方法三：Manacher算法 暂未理解 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253class Solution { /** 执行用时：15 ms, 在所有 Java 提交中击败了88.65%的用户 内存消耗：41.6 MB, 在所有 Java 提交中击败了62.46%的用户 */ public String longestPalindrome(String s) { int start = 0, end = -1; StringBuffer t = new StringBuffer(&quot;#&quot;); for (int i = 0; i &lt; s.length(); ++i) { t.append(s.charAt(i)); t.append('#'); } t.append('#'); s = t.toString(); List&lt;Integer&gt; arm_len = new ArrayList&lt;Integer&gt;(); int right = -1, j = -1; for (int i = 0; i &lt; s.length(); ++i) { int cur_arm_len; if (right &gt;= i) { int i_sym = j * 2 - i; int min_arm_len = Math.min(arm_len.get(i_sym), right - i); cur_arm_len = expand(s, i - min_arm_len, i + min_arm_len); } else { cur_arm_len = expand(s, i, i); } arm_len.add(cur_arm_len); if (i + cur_arm_len &gt; right) { j = i; right = i + cur_arm_len; } if (cur_arm_len * 2 + 1 &gt; end - start) { start = i - cur_arm_len; end = i + cur_arm_len; } } StringBuffer ans = new StringBuffer(); for (int i = start; i &lt;= end; ++i) { if (s.charAt(i) != '#') { ans.append(s.charAt(i)); } } return ans.toString(); } public int expand(String s, int left, int right) { while (left &gt;= 0 &amp;&amp; right &lt; s.length() &amp;&amp; s.charAt(left) == s.charAt(right)) { --left; ++right; } return (right - left - 2) / 2; }} Question8:区间子数组的个数题目描述： 给你一个整数数组 nums 和两个整数：left 及 right 。找出 nums 中连续、非空且其中最大元素在范围 [left, right] 内的子数组，并返回满足条件的子数组的个数。 题解： 1234567891011121314151617181920212223class Solution { /** 执行用时：3 ms, 在所有 Java 提交中击败了90.06%的用户 内存消耗：49.1 MB, 在所有 Java 提交中击败了28.62%的用户 */ public int numSubarrayBoundedMax(int[] nums, int left, int right) { return subarrayBoundedMax(nums,right) - subarrayBoundedMax(nums,left-1); } private int subarrayBoundedMax(int[] num, int MAX) { int res = 0; int resBounded = 0; for(int i = 0; i &lt; num.length; i++) { if(num[i] &lt;= MAX) { resBounded++; res+=resBounded; } else { resBounded = 0; } } return res; }} Question9:情感丰富的单词题目描述： 有时候人们会用重复写一些字母来表示额外的感受，比如 “hello” -&gt; “heeellooo”, “hi” -&gt; “hiii”。我们将相邻字母都相同的一串字符定义为相同字母组，例如：”h”, “eee”, “ll”, “ooo”。 对于一个给定的字符串 S ，如果另一个单词能够通过将一些字母组扩张从而使其和 S 相同，我们将这个单词定义为可扩张的（stretchy）。扩张操作定义如下：选择一个字母组（包含字母 c ），然后往其中添加相同的字母 c 使其长度达到 3 或以上。 例如，以 “hello” 为例，我们可以对字母组 “o” 扩张得到 “hellooo”，但是无法以同样的方法得到 “helloo” 因为字母组 “oo” 长度小于 3。此外，我们可以进行另一种扩张 “ll” -&gt; “lllll” 以获得 “helllllooo”。如果 S = “helllllooo”，那么查询词 “hello” 是可扩张的，因为可以对它执行这两种扩张操作使得 query = “hello” -&gt; “hellooo” -&gt; “helllllooo” = S。 输入一组查询单词，输出其中可扩张的单词数量。 题意解析： 就是说，首先给定一个字符串数组words，然后给定一个字符串s，然后逐一判断words中的字符串是否可以通过扩展变成s；返回可以变成s的字符串的个数。 扩展规则：扩展之后这个字母的次数必须大于等于3 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748class Solution { /** 执行用时：1 ms, 在所有 Java 提交中击败了97.85%的用户 内存消耗：39.4 MB, 在所有 Java 提交中击败了98.39%的用户 */ public int expressiveWords(String s, String[] words) { int res = 0; for(String word : words) { if(isExpressiveWord(word,s)) { res++; } } return res; } /** * 先写一个函数用来判断是否为这类字符串 * @param s 扩展前的字符串 * @param t 扩展后的字符串 * @return 如果t是s扩展后的字符串，返回true */ private boolean isExpressiveWord(String s, String t) { int i = 0, j = 0;//创建两个指针，分别用来遍历s和t while (i &lt; s.length() &amp;&amp; j &lt; t.length()) { if (s.charAt(i) != t.charAt(j)) { return false; } int cnti = 0, cntj = 0; char ch = s.charAt(i); while (i &lt; s.length() &amp;&amp; s.charAt(i) == ch) { ++i; ++cnti; } while (j &lt; t.length() &amp;&amp; t.charAt(j) == ch) { ++j; ++cntj; } if (cntj &lt; cnti) { return false; } if (cnti != cntj &amp;&amp; cntj &lt; 3) { return false; } } return i==s.length() &amp;&amp; j==t.length(); }} Question10:寻找盛水最多的容器题目描述： 给定一个长度为 n 的整数数组 height 。有 n 条垂线，第 i 条线的两个端点是 (i, 0) 和 (i, height[i]) 。 找出其中的两条线，使得它们与 x 轴共同构成的容器可以容纳最多的水。 返回容器可以储存的最大水量。 说明：你不能倾斜容器。 题解： 方法一： 思路是创建一个双指针 一个指针指向最左边，一个指针指向最右边 哪边的高度比较低，就把哪边的向中心移动，以求获取最大的高度，从而获得最大的容积 12345678910111213141516171819class Solution { /** 执行用时：4 ms, 在所有 Java 提交中击败了59.85%的用户 内存消耗：51.2 MB, 在所有 Java 提交中击败了89.00%的用户 */ public int maxArea(int[] height) { int res = 0; int left = 0; int right = height.length-1; while(left &lt; right) { res = Math.max(res,(right-left)*Math.min(height[left],height[right])); if(height[left] &lt; height[right]){ left++; } else { right--; } } return res; }} Question11:三数之和题目描述： 给你一个整数数组 nums ，判断是否存在三元组 [nums[i], nums[j], nums[k]] 满足 i != j、i != k 且 j != k ，同时还满足 nums[i] + nums[j] + nums[k] == 0 。请你返回所有和为 0 且不重复的三元组。 注意：答案中不可以包含重复的三元组。 题解： 首先，本题第一反应还是使用循环来做暴力求解，这样的话所有的数字都要遍历三遍，复杂度为O(N3)，复杂度较高，影响性能。 想要降低复杂度到O(N2)，需要使用双指针；先将数组进行排序，然后一个指针指向头部，一个指针指向尾部，对中间的数字进行遍历，相关注释加到代码里 1234567891011121314151617181920212223242526272829303132333435363738394041424344class Solution { /** 执行用时：20 ms, 在所有 Java 提交中击败了76.56%的用户 内存消耗：45.8 MB, 在所有 Java 提交中击败了31.97%的用户 */ public List&lt;List&lt;Integer&gt;&gt; threeSum(int[] nums) { //创建最终的返回集合 List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;(); //先对数组进行排序 Arrays.sort(nums); int n = nums.length; for (int first = 0; first &lt; n; first++) { //保证下一个数字和上一个数字不一样 if (first &gt; 0 &amp;&amp; nums[first] == nums[first-1]) { continue; } int third = n - 1; int target = -nums[first]; for (int second = first+1; second &lt; n; second++) { //保证数字和上一个不一样 if (second &gt; first+1 &amp;&amp; nums[second] == nums[second-1]){ continue; } //如果二者加和大于了目标值，就需要将最后一个数字向左移动 while (second &lt; third &amp;&amp; nums[second] + nums[third] &gt; target) { third--; } //当两个指针重合，就不需要再继续了，直接break if (second == third) { break; } //满足要求的添加到数组之中 if (nums[second] + nums[third] == target) { List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); list.add(nums[first]); list.add(nums[second]); list.add(nums[third]); res.add(list); } } } return res; }} Question12:电话号码中的字母组合题目描述： 给定一个仅包含数字 2-9 的字符串，返回所有它能表示的字母组合。答案可以按 任意顺序 返回。 给出数字到字母的映射如下（与电话按键相同）。注意 1 不对应任何字母。 题解： 分析一下，对于这道题，我们肯定是想要先看有几个数字，如果是两个数字，比如23，那么就利用双层循环就可以获取到所有的值。如果是三个数字234，那么就使用三层循环获取所有的排列组合。 但是在写的时候就会发现，根据数字的个数写几层循环代码上不可实现。 因此本题我们需要用回溯算法 回溯算法 回溯算法其实说白了就是平时所说的试试看的想法，先试试，可以的话就返回，不可以的话就回来再试。第一次接触应该是在数据结构课上的八皇后问题。先将一个皇后放在这个位置，然后放下一个皇后，直到下一个皇后没法放的时候，进行回溯，来改变上一个皇后的位置；如果还是无解，就再向上回溯，直到第一个皇后。其思想类似于枚举法，就是将所有的情况都做枚举。 使用回溯法解决问题的过程，实际上是建立一棵“状态树”的过程。例如，在解决列举集合{1,2,3}所有子集的问题中，对于每个元素，都有两种状态，取还是舍，所以构建的状态树为： 回溯算法的求解过程实质上是先序遍历“状态树”的过程。树中每一个叶子结点，都有可能是问题的答案。图 1 中的状态树是满二叉树，得到的叶子结点全部都是问题的解。 123456789101112131415161718192021222324252627282930313233343536373839class Solution { /** 执行用时：0 ms, 在所有 Java 提交中击败了100.00%的用户 内存消耗：39.9 MB, 在所有 Java 提交中击败了72.58%的用户 */ public List&lt;String&gt; letterCombinations(String digits) { List&lt;String&gt; combinations = new ArrayList&lt;&gt;(); if (digits.length() == 0) { return combinations; } Map&lt;Character,String&gt; map = new HashMap&lt;&gt;(); map.put('2',&quot;abc&quot;); map.put('3',&quot;def&quot;); map.put('4',&quot;ghi&quot;); map.put('5',&quot;jkl&quot;); map.put('6',&quot;mno&quot;); map.put('7',&quot;pqrs&quot;); map.put('8',&quot;tuv&quot;); map.put('9',&quot;wxyz&quot;); //回溯算法 backTrack(combinations,new StringBuffer(),0,digits,map); return combinations; } public void backTrack(List&lt;String&gt; combinations, StringBuffer combination, int index, String digits, Map&lt;Character, String&gt; map){ if (index == digits.length()) { combinations.add(combination.toString()); } else { char str = digits.charAt(index); String letters = map.get(str); int len = letters.length(); for (int i = 0; i &lt; len; i++) { combination.append(letters.charAt(i)); backTrack(combinations,combination,index+1,digits,map); combination.deleteCharAt(index); } } }} Question13:删除链表中倒数第N个节点题目描述： 给你一个链表，删除链表的倒数第 n 个结点，并且返回链表的头结点。 题解： 方法一：普通方法 先找到链表中节点的个数 然后进行遍历，到正数第sum-n的地方进行操作即可 12345678910111213141516171819202122232425262728293031323334class Solution { /** 执行用时：0 ms, 在所有 Java 提交中击败了100.00%的用户 内存消耗：40.1 MB, 在所有 Java 提交中击败了5.11%的用户 */ public ListNode removeNthFromEnd(ListNode head, int n) { //删除链表中的倒数第n个节点 //先统计一共有几个节点 int sum = 0; ListNode cur = head; while (cur != null) { sum++; cur = cur.next; } //如果n大于个数，就return null if (n &gt; sum || sum==1) { return null; } //如果第一个节点是要删除的节点 if(sum == n) { return head.next; } ListNode temp = head; int count = 0; while (temp != null) { count++; if (count == sum-n) { temp.next = temp.next.next; break; } temp = temp.next; } return head; }} 方法二：使用栈 将所有的链表节点加入到栈中 将栈中的数据取出n-1个 返回栈顶元素，也就是要删除节点的前一个节点 进行删除操作即可 12345678910111213141516public ListNode removeNthFromEnd(ListNode head, int n) { ListNode dummy = new ListNode(0, head); Deque&lt;ListNode&gt; stack = new LinkedList&lt;ListNode&gt;(); ListNode cur = dummy; while (cur != null) { stack.push(cur); cur = cur.next; } for (int i = 0; i &lt; n; i++) { stack.pop(); } ListNode prev = stack.peek(); prev.next = prev.next.next; ListNode ans = dummy.next; return ans;} 方法三：双指针 我们也可以在不预处理出链表的长度，以及使用常数空间的前提下解决本题。 由于我们需要找到倒数第 n 个节点，因此我们可以使用两个指针first 和 second 同时对链表进行遍历，并且first 比 second 超前 n 个节点。当 first 遍历到链表的末尾时，second 就恰好处于倒数第 n 个节点。 具体地，初始时 first 和 second 均指向头节点。我们首先使用 first 对链表进行遍历，遍历的次数为 n。此时，first 和 second 之间间隔了 n-1 个节点，即 first 比 second 超前了 n 个节点。 在这之后，我们同时使用 first 和 second 对链表进行遍历。当 first 遍历到链表的末尾（即 first 为空指针）时，second 恰好指向倒数第 n 个节点。 根据方法一和方法二，如果我们能够得到的是倒数第 n 个节点的前驱节点而不是倒数第 n 个节点的话，删除操作会更加方便。因此我们可以考虑在初始时将 second 指向哑节点，其余的操作步骤不变。这样一来，当 first 遍历到链表的末尾时，second 的下一个节点就是我们需要删除的节点。 1234567891011121314151617class Solution { public ListNode removeNthFromEnd(ListNode head, int n) { ListNode dummy = new ListNode(0, head); ListNode first = head; ListNode second = dummy; for (int i = 0; i &lt; n; ++i) { first = first.next; } while (first != null) { first = first.next; second = second.next; } second.next = second.next.next; ListNode ans = dummy.next; return ans; }} Question14:括号的生成题目描述： 数字 n 代表生成括号的对数，请你设计一个函数，用于能够生成所有可能的并且 有效的 括号组合。 注意不可以产生交叉的括号 题解： 方法一：暴力求解 123456789101112131415161718192021222324252627282930313233343536373839404142434445class Solution { public List&lt;String&gt; generateParenthesis(int n) { //方法一：暴力法求解 /** 整体思路就是，将所有的可能的情况列举出来，然后再进行判断是否可行 执行用时：2 ms, 在所有 Java 提交中击败了25.13%的用户 内存消耗：41.6 MB, 在所有 Java 提交中击败了34.94%的用户 */ List&lt;String&gt; res = new ArrayList&lt;&gt;(); generateAll(new char[2*n],0,res); return res; } //生成最后返回的序列 public void generateAll(char[] current, int pos, List&lt;String&gt; result){ //在遍历到最后的位置的时候进行判断并添加到结果集 if(pos == current.length) { if(isValid(current)){ result.add(new String(current)); } } else { //进行递归遍历 current[pos] = '('; generateAll(current,pos+1,result); current[pos] = ')'; generateAll(current,pos+1,result); } } //判断是否有效的函数 public boolean isValid(char[] current){ int balance = 0; for(char c : current) { if(c == '(') { balance += 1; } else { balance -= 1; } if(balance &lt; 0) { return false; } } return balance == 0; }} 方法二：回溯法 相当于方法一的拓展，只有在序列还有效的时候进行加左括号或者右括号的操作 如果左括号数量不大于 n，我们可以放一个左括号。如果右括号数量小于左括号的数量，我们可以放一个右括号。 123456789101112131415161718192021222324class Solution { public List&lt;String&gt; generateParenthesis(int n) { List&lt;String&gt; ans = new ArrayList&lt;String&gt;(); backtrack(ans, new StringBuilder(), 0, 0, n); return ans; } public void backtrack(List&lt;String&gt; ans, StringBuilder cur, int open, int close, int max) { if (cur.length() == max * 2) { ans.add(cur.toString()); return; } if (open &lt; max) { cur.append('('); backtrack(ans, cur, open + 1, close, max); cur.deleteCharAt(cur.length() - 1); } if (close &lt; open) { cur.append(')'); backtrack(ans, cur, open, close + 1, max); cur.deleteCharAt(cur.length() - 1); } }} 方法三：递归法 剩余左括号总数要小于等于右括号，递归把所有符合要求的加上去就行了 1234567891011121314151617181920212223242526272829303132333435class Solution { /** 执行用时：1 ms, 在所有 Java 提交中击败了76.13%的用户 内存消耗：41.3 MB, 在所有 Java 提交中击败了78.55%的用户 */ List&lt;String&gt; res = new ArrayList&lt;&gt;(); public List&lt;String&gt; generateParenthesis(int n) { if(n &lt;= 0) { return res; } generateAll(&quot;&quot;,n,n); return res; } /** 生成最后返回的序列 left:左括号剩余的数量 right:右括号剩余的数量 */ public void generateAll(String str, int left, int right){ if(left == 0 &amp;&amp; right == 0) { res.add(str); return; } if(left == right) { //数量相等的时候，只能加入左括号 generateAll(str+&quot;(&quot; , left-1,right); } else if (left &lt; right) { //剩余左括号小于右括号的时候，下一个既可以是左括号也可以是右括号 if(left &gt; 0) { generateAll(str+&quot;(&quot;,left-1,right); } generateAll(str+&quot;)&quot;,left,right-1); } }} Question15:下一个排列题目描述： 例如，arr = [1,2,3] ，以下这些都可以视作 arr 的排列：[1,2,3]、[1,3,2]、[3,1,2]、[2,3,1] 。 下一个排列就是指的按照排列所得的大小进行排序，然后取出本个组合的下一个序列。 题解： 思路： 以[4,5,2,6,3,1] 为例 先找到要反转的位置，也就是找到前一位小于后一位这个位置也就是nums[i]=2 设置另一个指针，从后面的数中找出略大于上面位置的数字nums[j]=3 将nums[i]和nums[j]进行调换位置，之后再对nums[i]后面的位置进行反转即可(从最大反转到最小) 12345678910111213141516171819202122232425262728293031323334class Solution { /** 执行用时：0 ms, 在所有 Java 提交中击败了100.00%的用户 内存消耗：41.9 MB, 在所有 Java 提交中击败了35.21%的用户 */ public void nextPermutation(int[] nums) { int i = nums.length - 2; while (i &gt;= 0 &amp;&amp; nums[i] &gt;= nums[i + 1]) { i--; } if (i &gt;= 0) { int j = nums.length - 1; while (j &gt;= 0 &amp;&amp; nums[i] &gt;= nums[j]) { j--; } swap(nums, i, j); } reverse(nums, i + 1); } public void swap(int[] nums, int i, int j) { int temp = nums[i]; nums[i] = nums[j]; nums[j] = temp; } public void reverse(int[] nums, int start) { int left = start, right = nums.length - 1; while (left &lt; right) { swap(nums, left, right); left++; right--; } }} Question16:搜索旋转排序数组题目描述： 整数数组 nums 按升序排列，数组中的值 互不相同 。 在传递给函数之前，nums 在预先未知的某个下标 k（0 &lt;= k &lt; nums.length）上进行了 旋转，使数组变为 [nums[k], nums[k+1], …, nums[n-1], nums[0], nums[1], …, nums[k-1]]（下标 从 0 开始 计数）。例如， [0,1,2,4,5,6,7] 在下标 3 处经旋转后可能变为 [4,5,6,7,0,1,2] 。 给你旋转后的数组 nums 和一个整数 target ，如果 nums 中存在这个目标值 target ，则返回它的下标，否则返回 -1 。 你必须设计一个时间复杂度为 O(log n) 的算法解决此问题。 题解： 本题主要是在非完全有序数组中利用二分法的思想。 分析：首先二分法是针对有序数组的一种查找条件，就是从数组中间一分为二进行查找。但是本体在将数组进行一分为二的时候，，分开的左右数组必有一个是有序数组，另一个是部分有序数组，因此采取以下思路 算法设计： 利用二分法将数组一分为二，并且判断左右哪一段为有序数组，判断方法：如果nums[mid] &lt; nums[right]那么右边的数组有序；如果nums[mid] &gt; nums[left]那么左边的数组有序； 如果左边的数组有序，那么判断target是否位于左边数组中，位于则right=mid-1，否则left=mid+1 若未找到数字，返回-1 12345678910111213141516171819202122232425262728293031class Solution { /** 执行用时：0 ms, 在所有 Java 提交中击败了100.00%的用户 内存消耗：40.9 MB, 在所有 Java 提交中击败了69.04%的用户 */ public int search(int[] nums, int target) { int len = nums.length;; int left = 0; int right = len - 1; while (left &lt;= right) { int mid = (left + right) / 2; if (nums[mid] == target) { return mid; } if (nums[mid] &gt;= nums[left]) { if (target &gt;= nums[left] &amp;&amp; target &lt; nums[mid]) { right = mid - 1; } else { left = mid + 1; } } else { if (target &gt;= nums[mid] &amp;&amp; target &lt;= nums[right]) { left = mid + 1; } else { right = mid - 1; } } } return -1; }} Question17：有序数组中查找元素的第一和最后位置题目描述： 给你一个按照非递减顺序排列的整数数组 nums，和一个目标值 target。请你找出给定目标值在数组中的开始位置和结束位置。 如果数组中不存在目标值 target，返回 [-1, -1]。 你必须设计并实现时间复杂度为 O(log n) 的算法解决此问题。 题解： 解题思路： 本题使用二分法，最好是将查找左边界与查找右边界分开，这样不容易出错。 以查找右边界为例： 首先按照二分法获取当前区间的中间(left+right) / 2，判断下标对应的数字是否大于目标数字 如果大于目标数，则right = middle - 1 否则left = middle + 1；rightBorder = left 循环执行，最终得到右边界+1的位置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051class Solution { public int[] searchRange(int[] nums, int target) { int leftBorder = getLeftBorder(nums,target); int rightBorder = getRightBorder(nums,target); if (leftBorder == -2 || rightBorder == -2) { return new int[]{-1,-1}; } if (rightBorder - leftBorder &gt; 1) { return new int[]{leftBorder+1,rightBorder-1}; } return new int[]{-1,-1}; } /** 用来获取数组的右边界 */ public int getRightBorder(int[] nums, int target) { int left = 0; int right = nums.length - 1; int rightBorder = -2; while(left &lt;= right) { int middle = left + (right - left) / 2; if(nums[middle] &gt; target) { right = middle - 1; } else { left = middle + 1; rightBorder = left; } } return rightBorder; } /** 用来获取数组的左边界 */ public int getLeftBorder(int[] nums, int target) { int left = 0; int right = nums.length - 1; int leftBorder = -2; while(left &lt;= right) { int middle = left + (right - left) / 2; if(nums[middle] &lt; target) { left = middle + 1; } else { right = middle - 1; leftBorder = right; } } return leftBorder; }} Chapter3:HardQuestion1:子序列宽度之和题目描述： 一个序列的宽度 定义为该序列中最大元素和最小元素的差值。 给你一个整数数组 nums ，返回 nums 的所有非空子序列的宽度之和。由于答案可能非常大，请返回对 1000000007 取余后的结果。 子序列定义为从一个数组里删除一些（或者不删除）元素，但不改变剩下元素的顺序得到的数组。例如，[3,6,2,7] 就是数组 [0,3,1,6,2,2,7] 的一个子序列。 题解： 数学法： 1234567891011121314151617/**执行用时：34 ms, 在所有 Java 提交中击败了94.74%的用户内存消耗：48.7 MB, 在所有 Java 提交中击败了98.68%的用户 */class Solution { public int sumSubseqWidths(int[] nums) { final int MOD = 1000000007; Arrays.sort(nums); long res = 0; long x = nums[0], y=2; for(int j = 1; j &lt; nums.length; j++) { res = (res + nums[j]*(y-1) - x) % MOD; x = (2*x+nums[j]) % MOD; y = (2 * y) % MOD; } return (int)res; }} Question2:第N个神奇数字题目描述： 一个正整数如果能被 a 或 b 整除，那么它是神奇的。 给定三个整数 n , a , b ，返回第 n 个神奇的数字。因为答案可能很大，所以返回答案 对 109 + 7 取模 后的值。 我再来解读一下题目想要表达的意思：就是除a或者除b能除开的数字就是神奇的数，我们现在要寻找第N个能除开他们的数 题解： 思路：其实本题很简单，就是取一个并集再减去交集即可；也就是说。除以a可以除开的数和除以b可以除开的数，必有重复，把重复的数字去除即可。 首先寻找到a和b的最小公倍数 利用公式$$f(x)=[x/a]+[x/b]+[x/c]$$ x即为第x个数 12345678910111213141516171819202122class Solution { static final int mod=1000000007; public int nthMagicalNumber(int n, int a, int b) { long l=Math.min(a,b),r=(long)n*Math.min(a,b);//这样的话一定至少有n个数 int c = a * b / gcd(a,b);//c即为最小公倍数 while (l &lt;= r) { long mid = (r+l) / 2; long count = mid / a + mid / b - mid / c;//分析中的公式 if (count &gt;= n) {//包含等于n的情况，多减了1，因此返回时加上1 r = mid - 1; } else { l = mid + 1; } } return (int) ((r+1) % mod); } //首先写一个方法寻找两个数中的最小公约数 public int gcd(int a, int b) { return a&lt;b ? gcd(b,a) : ((a%b==0)?b : gcd(b,a%b)); }} 找规律的方法见力扣官方解答","link":"/2022/11/14/LeetCode/"}],"tags":[{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"Web","slug":"Web","link":"/tags/Web/"},{"name":"Interview preparation","slug":"Interview-preparation","link":"/tags/Interview-preparation/"},{"name":"Data Structure","slug":"Data-Structure","link":"/tags/Data-Structure/"},{"name":"Algorithm","slug":"Algorithm","link":"/tags/Algorithm/"},{"name":"Java_Project","slug":"Java-Project","link":"/tags/Java-Project/"},{"name":"web","slug":"web","link":"/tags/web/"},{"name":"SQL","slug":"SQL","link":"/tags/SQL/"},{"name":"MySQL","slug":"MySQL","link":"/tags/MySQL/"},{"name":"Computer Basics","slug":"Computer-Basics","link":"/tags/Computer-Basics/"}],"categories":[{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"MySQL","slug":"MySQL","link":"/categories/MySQL/"},{"name":"Algorithm","slug":"Algorithm","link":"/categories/Algorithm/"}],"pages":[{"title":"About me","text":"This is a detailed self-introduction about the blogger.","link":"/about/index.html"},{"title":"Write down what you want to say","text":"","link":"/guestbook/index.html"},{"title":"tags","text":"","link":"/tags/index.html"},{"title":"categories","text":"","link":"/categories/index.html"}]}